2022-06-10-17_32_57  Epoch: 0, Training Step: 0, Loss: 17.375476837158203, Learning Rate: 5e-05
2022-06-10-17_33_25  Epoch: 0, Training Step: 100, Loss: 2.4180526733398438, Learning Rate: 5e-05
2022-06-10-17_33_53  Epoch: 0, Training Step: 200, Loss: -3.204782009124756, Learning Rate: 5e-05
2022-06-10-17_34_20  Epoch: 0, Training Step: 300, Loss: -5.4085540771484375, Learning Rate: 5e-05
2022-06-10-17_34_47  Epoch: 0, Training Step: 400, Loss: -6.885143280029297, Learning Rate: 5e-05
2022-06-10-17_37_17  Epoch: 0, Training Step: 0, Loss: 17.49605941772461, Learning Rate: 5e-05
2022-06-10-17_37_44  Epoch: 0, Training Step: 100, Loss: 8.899879455566406, Learning Rate: 5e-05
2022-06-10-17_38_11  Epoch: 0, Training Step: 200, Loss: 5.376532554626465, Learning Rate: 5e-05
2022-06-10-17_38_38  Epoch: 0, Training Step: 300, Loss: 3.359516143798828, Learning Rate: 5e-05
2022-06-10-17_39_25  Epoch: 0, Training Step: 0, Loss: 17.49605941772461, Learning Rate: 5e-05
2022-06-10-17_39_52  Epoch: 0, Training Step: 100, Loss: 8.899879455566406, Learning Rate: 5e-05
2022-06-10-17_40_19  Epoch: 0, Training Step: 200, Loss: 5.376532554626465, Learning Rate: 5e-05
2022-06-10-17_40_46  Epoch: 0, Training Step: 300, Loss: 3.359516143798828, Learning Rate: 5e-05
2022-06-10-17_41_13  Epoch: 0, Training Step: 400, Loss: 2.517655849456787, Learning Rate: 5e-05
2022-06-10-17_41_41  Epoch: 0, Training Step: 500, Loss: 2.2725577354431152, Learning Rate: 5e-05
2022-06-10-17_42_08  Epoch: 0, Training Step: 600, Loss: 2.2789177894592285, Learning Rate: 5e-05
2022-06-10-17_42_35  Epoch: 0, Training Step: 700, Loss: 2.7416131496429443, Learning Rate: 5e-05
2022-06-10-17_43_02  Epoch: 0, Training Step: 800, Loss: 2.2239246368408203, Learning Rate: 5e-05
2022-06-10-17_43_30  Epoch: 0, Training Step: 900, Loss: 2.350379228591919, Learning Rate: 5e-05
2022-06-10-17_43_57  Epoch: 0, Training Step: 1000, Loss: 2.0456981658935547, Learning Rate: 5e-05
2022-06-10-17_44_24  Epoch: 0, Training Step: 1100, Loss: 2.147315502166748, Learning Rate: 5e-05
2022-06-10-17_44_52  Epoch: 0, Training Step: 1200, Loss: 2.2443723678588867, Learning Rate: 5e-05
2022-06-10-17_45_19  Epoch: 0, Training Step: 1300, Loss: 2.4370617866516113, Learning Rate: 5e-05
2022-06-10-17_45_46  Epoch: 0, Training Step: 1400, Loss: 1.8475733995437622, Learning Rate: 5e-05
2022-06-10-17_46_14  Epoch: 0, Training Step: 1500, Loss: 1.845304012298584, Learning Rate: 5e-05
2022-06-10-17_46_41  Epoch: 0, Training Step: 1600, Loss: 1.713587760925293, Learning Rate: 5e-05
2022-06-10-17_47_08  Epoch: 0, Training Step: 1700, Loss: 2.001312494277954, Learning Rate: 5e-05
2022-06-10-17_47_35  Epoch: 0, Training Step: 1800, Loss: 1.9231762886047363, Learning Rate: 5e-05
2022-06-10-17_48_02  Epoch: 0, Training Step: 1900, Loss: 2.1615655422210693, Learning Rate: 5e-05
2022-06-10-17_48_30  Epoch: 0, Training Step: 2000, Loss: 1.9640910625457764, Learning Rate: 5e-05
2022-06-10-17_48_56  Epoch: 0, Training Step: 2100, Loss: 2.0786972045898438, Learning Rate: 5e-05
2022-06-10-17_49_24  Epoch: 0, Training Step: 2200, Loss: 2.267159938812256, Learning Rate: 5e-05
2022-06-10-17_49_51  Epoch: 0, Training Step: 2300, Loss: 1.8620786666870117, Learning Rate: 5e-05
2022-06-10-17_50_18  Epoch: 0, Training Step: 2400, Loss: 1.9619579315185547, Learning Rate: 5e-05
2022-06-10-17_50_46  Epoch: 0, Training Step: 2500, Loss: 1.5789618492126465, Learning Rate: 5e-05
2022-06-10-17_51_13  Epoch: 0, Training Step: 2600, Loss: 1.635886549949646, Learning Rate: 5e-05
2022-06-10-17_51_40  Epoch: 0, Training Step: 2700, Loss: 2.0694165229797363, Learning Rate: 5e-05
2022-06-10-17_52_07  Epoch: 0, Training Step: 2800, Loss: 1.5057637691497803, Learning Rate: 5e-05
2022-06-10-17_52_34  Epoch: 0, Training Step: 2900, Loss: 1.6686789989471436, Learning Rate: 5e-05
2022-06-10-17_53_01  Epoch: 0, Training Step: 3000, Loss: 1.728550672531128, Learning Rate: 5e-05
2022-06-10-17_53_28  Epoch: 0, Training Step: 3100, Loss: 1.592294692993164, Learning Rate: 5e-05
2022-06-10-17_53_55  Epoch: 0, Training Step: 3200, Loss: 1.4820566177368164, Learning Rate: 5e-05
2022-06-11-11_42_00  Epoch: 0, Training Step: 0, Loss: 17.49605941772461, Learning Rate: 5e-05
2022-06-11-11_42_27  Epoch: 0, Training Step: 100, Loss: 8.899879455566406, Learning Rate: 5e-05
2022-06-11-11_42_55  Epoch: 0, Training Step: 200, Loss: 5.376532554626465, Learning Rate: 5e-05
2022-06-11-11_43_22  Epoch: 0, Training Step: 300, Loss: 3.359516143798828, Learning Rate: 5e-05
2022-06-11-11_43_50  Epoch: 0, Training Step: 400, Loss: 2.517655849456787, Learning Rate: 5e-05
2022-06-11-11_44_17  Epoch: 0, Training Step: 500, Loss: 2.2725577354431152, Learning Rate: 5e-05
2022-06-11-11_44_44  Epoch: 0, Training Step: 600, Loss: 2.2789177894592285, Learning Rate: 5e-05
2022-06-11-11_45_11  Epoch: 0, Training Step: 700, Loss: 2.7416131496429443, Learning Rate: 5e-05
2022-06-11-11_45_38  Epoch: 0, Training Step: 800, Loss: 2.2239246368408203, Learning Rate: 5e-05
2022-06-11-11_46_06  Epoch: 0, Training Step: 900, Loss: 2.350379228591919, Learning Rate: 5e-05
2022-06-11-11_46_33  Epoch: 0, Training Step: 1000, Loss: 2.0456981658935547, Learning Rate: 5e-05
2022-06-11-11_47_00  Epoch: 0, Training Step: 1100, Loss: 2.147315502166748, Learning Rate: 5e-05
2022-06-11-11_47_28  Epoch: 0, Training Step: 1200, Loss: 2.2443723678588867, Learning Rate: 5e-05
2022-06-11-11_47_56  Epoch: 0, Training Step: 1300, Loss: 2.4370617866516113, Learning Rate: 5e-05
2022-06-11-11_48_23  Epoch: 0, Training Step: 1400, Loss: 1.8475733995437622, Learning Rate: 5e-05
2022-06-11-11_48_51  Epoch: 0, Training Step: 1500, Loss: 1.845304012298584, Learning Rate: 5e-05
2022-06-11-11_49_18  Epoch: 0, Training Step: 1600, Loss: 1.713587760925293, Learning Rate: 5e-05
2022-06-11-11_49_46  Epoch: 0, Training Step: 1700, Loss: 2.001312494277954, Learning Rate: 5e-05
2022-06-11-11_50_13  Epoch: 0, Training Step: 1800, Loss: 1.9231762886047363, Learning Rate: 5e-05
2022-06-11-11_50_41  Epoch: 0, Training Step: 1900, Loss: 2.1615655422210693, Learning Rate: 5e-05
2022-06-11-11_51_08  Epoch: 0, Training Step: 2000, Loss: 1.9640910625457764, Learning Rate: 5e-05
2022-06-11-11_51_34  Epoch: 0, Training Step: 2100, Loss: 2.0786972045898438, Learning Rate: 5e-05
2022-06-11-11_52_02  Epoch: 0, Training Step: 2200, Loss: 2.267159938812256, Learning Rate: 5e-05
2022-06-11-11_52_30  Epoch: 0, Training Step: 2300, Loss: 1.8620786666870117, Learning Rate: 5e-05
2022-06-11-11_52_57  Epoch: 0, Training Step: 2400, Loss: 1.9619579315185547, Learning Rate: 5e-05
2022-06-11-11_53_25  Epoch: 0, Training Step: 2500, Loss: 1.5789618492126465, Learning Rate: 5e-05
2022-06-11-11_53_52  Epoch: 0, Training Step: 2600, Loss: 1.635886549949646, Learning Rate: 5e-05
2022-06-11-11_54_20  Epoch: 0, Training Step: 2700, Loss: 2.0694165229797363, Learning Rate: 5e-05
2022-06-11-11_54_48  Epoch: 0, Training Step: 2800, Loss: 1.5057637691497803, Learning Rate: 5e-05
2022-06-11-11_55_15  Epoch: 0, Training Step: 2900, Loss: 1.6686789989471436, Learning Rate: 5e-05
2022-06-11-11_55_42  Epoch: 0, Training Step: 3000, Loss: 1.728550672531128, Learning Rate: 5e-05
2022-06-11-11_56_09  Epoch: 0, Training Step: 3100, Loss: 1.592294692993164, Learning Rate: 5e-05
2022-06-11-11_56_37  Epoch: 0, Training Step: 3200, Loss: 1.4820566177368164, Learning Rate: 5e-05
2022-06-11-11_59_47  Epoch: 1, Training Step: 0, Loss: 1.563405990600586, Learning Rate: 0.0001
2022-06-11-12_00_17  Epoch: 1, Training Step: 100, Loss: 2.138972282409668, Learning Rate: 0.0001
2022-06-11-12_00_45  Epoch: 1, Training Step: 200, Loss: 1.5118497610092163, Learning Rate: 0.0001
2022-06-11-12_01_12  Epoch: 1, Training Step: 300, Loss: 1.660187840461731, Learning Rate: 0.0001
2022-06-11-12_01_41  Epoch: 1, Training Step: 400, Loss: 1.5825915336608887, Learning Rate: 0.0001
2022-06-11-12_02_08  Epoch: 1, Training Step: 500, Loss: 2.129084587097168, Learning Rate: 0.0001
2022-06-11-12_02_35  Epoch: 1, Training Step: 600, Loss: 1.8198530673980713, Learning Rate: 0.0001
2022-06-11-12_03_02  Epoch: 1, Training Step: 700, Loss: 1.5904145240783691, Learning Rate: 0.0001
2022-06-11-12_03_30  Epoch: 1, Training Step: 800, Loss: 1.4638415575027466, Learning Rate: 0.0001
2022-06-11-12_03_57  Epoch: 1, Training Step: 900, Loss: 1.445012092590332, Learning Rate: 0.0001
2022-06-11-12_04_24  Epoch: 1, Training Step: 1000, Loss: 1.6029548645019531, Learning Rate: 0.0001
2022-06-11-12_04_51  Epoch: 1, Training Step: 1100, Loss: 1.6601231098175049, Learning Rate: 0.0001
2022-06-11-12_05_18  Epoch: 1, Training Step: 1200, Loss: 2.2573230266571045, Learning Rate: 0.0001
2022-06-11-12_05_46  Epoch: 1, Training Step: 1300, Loss: 1.7622294425964355, Learning Rate: 0.0001
2022-06-11-12_06_14  Epoch: 1, Training Step: 1400, Loss: 1.571897268295288, Learning Rate: 0.0001
2022-06-11-12_06_42  Epoch: 1, Training Step: 1500, Loss: 1.4407463073730469, Learning Rate: 0.0001
2022-06-11-12_07_10  Epoch: 1, Training Step: 1600, Loss: 1.9216281175613403, Learning Rate: 0.0001
2022-06-11-12_07_37  Epoch: 1, Training Step: 1700, Loss: 1.7592658996582031, Learning Rate: 0.0001
2022-06-11-12_08_05  Epoch: 1, Training Step: 1800, Loss: 1.4358102083206177, Learning Rate: 0.0001
2022-06-11-12_08_32  Epoch: 1, Training Step: 1900, Loss: 1.4762636423110962, Learning Rate: 0.0001
2022-06-11-12_08_59  Epoch: 1, Training Step: 2000, Loss: 1.7416456937789917, Learning Rate: 0.0001
2022-06-11-12_09_26  Epoch: 1, Training Step: 2100, Loss: 1.6327917575836182, Learning Rate: 0.0001
2022-06-11-12_09_54  Epoch: 1, Training Step: 2200, Loss: 1.4788007736206055, Learning Rate: 0.0001
2022-06-11-12_10_22  Epoch: 1, Training Step: 2300, Loss: 2.0142948627471924, Learning Rate: 0.0001
2022-06-11-12_10_49  Epoch: 1, Training Step: 2400, Loss: 1.505729079246521, Learning Rate: 0.0001
2022-06-11-12_11_16  Epoch: 1, Training Step: 2500, Loss: 1.4451625347137451, Learning Rate: 0.0001
2022-06-11-12_11_44  Epoch: 1, Training Step: 2600, Loss: 1.301711082458496, Learning Rate: 0.0001
2022-06-11-12_12_12  Epoch: 1, Training Step: 2700, Loss: 1.338800311088562, Learning Rate: 0.0001
2022-06-11-12_12_39  Epoch: 1, Training Step: 2800, Loss: 1.7383654117584229, Learning Rate: 0.0001
2022-06-11-12_13_06  Epoch: 1, Training Step: 2900, Loss: 1.356081247329712, Learning Rate: 0.0001
2022-06-11-12_13_33  Epoch: 1, Training Step: 3000, Loss: 1.3769468069076538, Learning Rate: 0.0001
2022-06-11-12_14_00  Epoch: 1, Training Step: 3100, Loss: 1.399871826171875, Learning Rate: 0.0001
2022-06-11-12_14_27  Epoch: 1, Training Step: 3200, Loss: 1.3820405006408691, Learning Rate: 0.0001
2022-06-11-12_17_32  Epoch: 2, Training Step: 0, Loss: 1.369309663772583, Learning Rate: 0.00015
2022-06-11-12_17_59  Epoch: 2, Training Step: 100, Loss: 1.4025557041168213, Learning Rate: 0.00015
2022-06-11-12_18_26  Epoch: 2, Training Step: 200, Loss: 1.6210895776748657, Learning Rate: 0.00015
2022-06-11-12_18_54  Epoch: 2, Training Step: 300, Loss: 1.4994145631790161, Learning Rate: 0.00015
2022-06-11-12_19_21  Epoch: 2, Training Step: 400, Loss: 1.251399040222168, Learning Rate: 0.00015
2022-06-11-12_19_49  Epoch: 2, Training Step: 500, Loss: 1.500283122062683, Learning Rate: 0.00015
2022-06-11-12_20_17  Epoch: 2, Training Step: 600, Loss: 1.3312723636627197, Learning Rate: 0.00015
2022-06-11-12_20_44  Epoch: 2, Training Step: 700, Loss: 1.9982914924621582, Learning Rate: 0.00015
2022-06-11-12_21_11  Epoch: 2, Training Step: 800, Loss: 1.6953750848770142, Learning Rate: 0.00015
2022-06-11-12_21_38  Epoch: 2, Training Step: 900, Loss: 1.2499778270721436, Learning Rate: 0.00015
2022-06-11-12_22_06  Epoch: 2, Training Step: 1000, Loss: 1.484778642654419, Learning Rate: 0.00015
2022-06-11-12_22_33  Epoch: 2, Training Step: 1100, Loss: 1.4515132904052734, Learning Rate: 0.00015
2022-06-11-12_23_00  Epoch: 2, Training Step: 1200, Loss: 1.5408399105072021, Learning Rate: 0.00015
2022-06-11-12_23_27  Epoch: 2, Training Step: 1300, Loss: 1.5548210144042969, Learning Rate: 0.00015
2022-06-11-12_23_55  Epoch: 2, Training Step: 1400, Loss: 1.5566282272338867, Learning Rate: 0.00015
2022-06-11-12_24_22  Epoch: 2, Training Step: 1500, Loss: 1.6242951154708862, Learning Rate: 0.00015
2022-06-11-12_24_50  Epoch: 2, Training Step: 1600, Loss: 1.3654769659042358, Learning Rate: 0.00015
2022-06-11-12_25_17  Epoch: 2, Training Step: 1700, Loss: 1.3643156290054321, Learning Rate: 0.00015
2022-06-11-12_25_45  Epoch: 2, Training Step: 1800, Loss: 1.5401997566223145, Learning Rate: 0.00015
2022-06-11-12_26_12  Epoch: 2, Training Step: 1900, Loss: 1.1806933879852295, Learning Rate: 0.00015
2022-06-11-12_26_40  Epoch: 2, Training Step: 2000, Loss: 1.2355445623397827, Learning Rate: 0.00015
2022-06-11-12_27_08  Epoch: 2, Training Step: 2100, Loss: 1.3188427686691284, Learning Rate: 0.00015
2022-06-11-12_27_36  Epoch: 2, Training Step: 2200, Loss: 1.5470094680786133, Learning Rate: 0.00015
2022-06-11-12_28_03  Epoch: 2, Training Step: 2300, Loss: 1.5056257247924805, Learning Rate: 0.00015
2022-06-11-12_28_30  Epoch: 2, Training Step: 2400, Loss: 1.4038136005401611, Learning Rate: 0.00015
2022-06-11-12_28_58  Epoch: 2, Training Step: 2500, Loss: 1.4067106246948242, Learning Rate: 0.00015
2022-06-11-12_29_25  Epoch: 2, Training Step: 2600, Loss: 1.2295746803283691, Learning Rate: 0.00015
2022-06-11-12_29_53  Epoch: 2, Training Step: 2700, Loss: 1.2182962894439697, Learning Rate: 0.00015
2022-06-11-12_30_20  Epoch: 2, Training Step: 2800, Loss: 1.11684250831604, Learning Rate: 0.00015
2022-06-11-12_30_48  Epoch: 2, Training Step: 2900, Loss: 1.1326743364334106, Learning Rate: 0.00015
2022-06-11-12_31_16  Epoch: 2, Training Step: 3000, Loss: 1.4750583171844482, Learning Rate: 0.00015
2022-06-11-12_31_44  Epoch: 2, Training Step: 3100, Loss: 1.7023701667785645, Learning Rate: 0.00015
2022-06-11-12_32_11  Epoch: 2, Training Step: 3200, Loss: 1.3836721181869507, Learning Rate: 0.00015
2022-06-11-12_35_18  Epoch: 3, Training Step: 0, Loss: 1.2931995391845703, Learning Rate: 0.0002
2022-06-11-12_35_46  Epoch: 3, Training Step: 100, Loss: 1.3748300075531006, Learning Rate: 0.0002
2022-06-11-12_36_14  Epoch: 3, Training Step: 200, Loss: 1.512730360031128, Learning Rate: 0.0002
2022-06-11-12_36_41  Epoch: 3, Training Step: 300, Loss: 1.3289780616760254, Learning Rate: 0.0002
2022-06-11-12_37_09  Epoch: 3, Training Step: 400, Loss: 1.2702617645263672, Learning Rate: 0.0002
2022-06-11-12_37_37  Epoch: 3, Training Step: 500, Loss: 1.43678617477417, Learning Rate: 0.0002
2022-06-11-12_38_04  Epoch: 3, Training Step: 600, Loss: 1.3074826002120972, Learning Rate: 0.0002
2022-06-11-12_38_32  Epoch: 3, Training Step: 700, Loss: 1.5475263595581055, Learning Rate: 0.0002
2022-06-11-12_38_59  Epoch: 3, Training Step: 800, Loss: 1.5182324647903442, Learning Rate: 0.0002
2022-06-11-12_39_27  Epoch: 3, Training Step: 900, Loss: 1.5379102230072021, Learning Rate: 0.0002
2022-06-11-12_39_54  Epoch: 3, Training Step: 1000, Loss: 1.5346758365631104, Learning Rate: 0.0002
2022-06-11-12_40_22  Epoch: 3, Training Step: 1100, Loss: 1.3415204286575317, Learning Rate: 0.0002
2022-06-11-12_40_49  Epoch: 3, Training Step: 1200, Loss: 1.2881686687469482, Learning Rate: 0.0002
2022-06-11-12_41_16  Epoch: 3, Training Step: 1300, Loss: 1.1888377666473389, Learning Rate: 0.0002
2022-06-11-12_41_43  Epoch: 3, Training Step: 1400, Loss: 1.1320421695709229, Learning Rate: 0.0002
2022-06-11-12_42_11  Epoch: 3, Training Step: 1500, Loss: 1.2711187601089478, Learning Rate: 0.0002
2022-06-11-12_42_39  Epoch: 3, Training Step: 1600, Loss: 1.0699111223220825, Learning Rate: 0.0002
2022-06-11-12_43_08  Epoch: 3, Training Step: 1700, Loss: 1.3245879411697388, Learning Rate: 0.0002
2022-06-11-12_43_36  Epoch: 3, Training Step: 1800, Loss: 1.070056676864624, Learning Rate: 0.0002
2022-06-11-12_44_04  Epoch: 3, Training Step: 1900, Loss: 1.485565423965454, Learning Rate: 0.0002
2022-06-11-12_44_32  Epoch: 3, Training Step: 2000, Loss: 1.350935697555542, Learning Rate: 0.0002
2022-06-11-12_45_00  Epoch: 3, Training Step: 2100, Loss: 1.1604838371276855, Learning Rate: 0.0002
2022-06-11-12_45_27  Epoch: 3, Training Step: 2200, Loss: 1.339226484298706, Learning Rate: 0.0002
2022-06-11-12_45_55  Epoch: 3, Training Step: 2300, Loss: 1.1859300136566162, Learning Rate: 0.0002
2022-06-11-12_46_22  Epoch: 3, Training Step: 2400, Loss: 1.1641674041748047, Learning Rate: 0.0002
2022-06-11-12_46_50  Epoch: 3, Training Step: 2500, Loss: 1.1983636617660522, Learning Rate: 0.0002
2022-06-11-12_47_17  Epoch: 3, Training Step: 2600, Loss: 1.1984580755233765, Learning Rate: 0.0002
2022-06-11-12_47_45  Epoch: 3, Training Step: 2700, Loss: 1.7770887613296509, Learning Rate: 0.0002
2022-06-11-12_48_12  Epoch: 3, Training Step: 2800, Loss: 1.333418607711792, Learning Rate: 0.0002
2022-06-11-12_48_40  Epoch: 3, Training Step: 2900, Loss: 1.4444074630737305, Learning Rate: 0.0002
2022-06-11-12_49_07  Epoch: 3, Training Step: 3000, Loss: 1.0152561664581299, Learning Rate: 0.0002
2022-06-11-12_49_34  Epoch: 3, Training Step: 3100, Loss: 1.1741453409194946, Learning Rate: 0.0002
2022-06-11-12_50_02  Epoch: 3, Training Step: 3200, Loss: 1.2872257232666016, Learning Rate: 0.0002
2022-06-11-12_53_06  Epoch: 4, Training Step: 0, Loss: 1.2486701011657715, Learning Rate: 0.00025
2022-06-11-12_53_34  Epoch: 4, Training Step: 100, Loss: 1.233814001083374, Learning Rate: 0.00025
2022-06-11-12_54_02  Epoch: 4, Training Step: 200, Loss: 1.4724290370941162, Learning Rate: 0.00025
2022-06-11-12_54_29  Epoch: 4, Training Step: 300, Loss: 1.1308504343032837, Learning Rate: 0.00025
2022-06-11-12_54_57  Epoch: 4, Training Step: 400, Loss: 1.1953063011169434, Learning Rate: 0.00025
2022-06-11-12_55_24  Epoch: 4, Training Step: 500, Loss: 1.2143512964248657, Learning Rate: 0.00025
2022-06-11-12_55_52  Epoch: 4, Training Step: 600, Loss: 1.132663607597351, Learning Rate: 0.00025
2022-06-11-12_56_19  Epoch: 4, Training Step: 700, Loss: 1.0440679788589478, Learning Rate: 0.00025
2022-06-11-12_56_47  Epoch: 4, Training Step: 800, Loss: 1.140317440032959, Learning Rate: 0.00025
2022-06-11-12_57_14  Epoch: 4, Training Step: 900, Loss: 1.3181407451629639, Learning Rate: 0.00025
2022-06-11-12_57_41  Epoch: 4, Training Step: 1000, Loss: 1.0133658647537231, Learning Rate: 0.00025
2022-06-11-12_58_09  Epoch: 4, Training Step: 1100, Loss: 1.112811803817749, Learning Rate: 0.00025
2022-06-11-12_58_36  Epoch: 4, Training Step: 1200, Loss: 1.1662142276763916, Learning Rate: 0.00025
2022-06-11-12_59_04  Epoch: 4, Training Step: 1300, Loss: 1.058680772781372, Learning Rate: 0.00025
2022-06-11-12_59_31  Epoch: 4, Training Step: 1400, Loss: 1.6132274866104126, Learning Rate: 0.00025
2022-06-11-12_59_59  Epoch: 4, Training Step: 1500, Loss: 1.2477986812591553, Learning Rate: 0.00025
2022-06-11-13_00_26  Epoch: 4, Training Step: 1600, Loss: 1.254329800605774, Learning Rate: 0.00025
2022-06-11-13_00_53  Epoch: 4, Training Step: 1700, Loss: 1.3380126953125, Learning Rate: 0.00025
2022-06-11-13_01_21  Epoch: 4, Training Step: 1800, Loss: 1.3011564016342163, Learning Rate: 0.00025
2022-06-11-13_01_49  Epoch: 4, Training Step: 1900, Loss: 1.3862926959991455, Learning Rate: 0.00025
2022-06-11-13_02_16  Epoch: 4, Training Step: 2000, Loss: 1.1241185665130615, Learning Rate: 0.00025
2022-06-11-13_02_44  Epoch: 4, Training Step: 2100, Loss: 1.2854669094085693, Learning Rate: 0.00025
2022-06-11-13_03_12  Epoch: 4, Training Step: 2200, Loss: 1.01438307762146, Learning Rate: 0.00025
2022-06-11-13_03_40  Epoch: 4, Training Step: 2300, Loss: 1.1859476566314697, Learning Rate: 0.00025
2022-06-11-13_04_08  Epoch: 4, Training Step: 2400, Loss: 1.2599585056304932, Learning Rate: 0.00025
2022-06-11-13_04_36  Epoch: 4, Training Step: 2500, Loss: 1.0368614196777344, Learning Rate: 0.00025
2022-06-11-13_05_03  Epoch: 4, Training Step: 2600, Loss: 1.2865976095199585, Learning Rate: 0.00025
2022-06-11-13_05_31  Epoch: 4, Training Step: 2700, Loss: 1.1913588047027588, Learning Rate: 0.00025
2022-06-11-13_05_59  Epoch: 4, Training Step: 2800, Loss: 1.5468909740447998, Learning Rate: 0.00025
2022-06-11-13_06_26  Epoch: 4, Training Step: 2900, Loss: 1.1341500282287598, Learning Rate: 0.00025
2022-06-11-13_06_54  Epoch: 4, Training Step: 3000, Loss: 1.0187833309173584, Learning Rate: 0.00025
2022-06-11-13_07_21  Epoch: 4, Training Step: 3100, Loss: 1.0177489519119263, Learning Rate: 0.00025
2022-06-11-13_07_49  Epoch: 4, Training Step: 3200, Loss: 1.3136570453643799, Learning Rate: 0.00025
2022-06-11-13_10_58  Epoch: 5, Training Step: 0, Loss: 1.2260642051696777, Learning Rate: 0.0003
2022-06-11-13_11_25  Epoch: 5, Training Step: 100, Loss: 1.764318585395813, Learning Rate: 0.0003
2022-06-11-13_11_53  Epoch: 5, Training Step: 200, Loss: 1.230154275894165, Learning Rate: 0.0003
2022-06-11-13_12_21  Epoch: 5, Training Step: 300, Loss: 1.243345856666565, Learning Rate: 0.0003
2022-06-11-13_12_49  Epoch: 5, Training Step: 400, Loss: 1.098784327507019, Learning Rate: 0.0003
2022-06-11-13_13_16  Epoch: 5, Training Step: 500, Loss: 1.0747947692871094, Learning Rate: 0.0003
2022-06-11-13_13_43  Epoch: 5, Training Step: 600, Loss: 0.9679040908813477, Learning Rate: 0.0003
2022-06-11-13_14_10  Epoch: 5, Training Step: 700, Loss: 1.4122613668441772, Learning Rate: 0.0003
2022-06-11-13_14_38  Epoch: 5, Training Step: 800, Loss: 1.4818135499954224, Learning Rate: 0.0003
2022-06-11-13_15_05  Epoch: 5, Training Step: 900, Loss: 1.0976574420928955, Learning Rate: 0.0003
2022-06-11-13_15_33  Epoch: 5, Training Step: 1000, Loss: 1.1062144041061401, Learning Rate: 0.0003
2022-06-11-13_16_01  Epoch: 5, Training Step: 1100, Loss: 1.0697957277297974, Learning Rate: 0.0003
2022-06-11-13_16_29  Epoch: 5, Training Step: 1200, Loss: 1.3933970928192139, Learning Rate: 0.0003
2022-06-11-13_16_57  Epoch: 5, Training Step: 1300, Loss: 1.2538539171218872, Learning Rate: 0.0003
2022-06-11-13_17_25  Epoch: 5, Training Step: 1400, Loss: 1.4188052415847778, Learning Rate: 0.0003
2022-06-11-13_17_53  Epoch: 5, Training Step: 1500, Loss: 1.0769087076187134, Learning Rate: 0.0003
2022-06-11-13_18_20  Epoch: 5, Training Step: 1600, Loss: 1.1437594890594482, Learning Rate: 0.0003
2022-06-11-13_18_48  Epoch: 5, Training Step: 1700, Loss: 1.2437891960144043, Learning Rate: 0.0003
2022-06-11-13_19_16  Epoch: 5, Training Step: 1800, Loss: 1.155635118484497, Learning Rate: 0.0003
2022-06-11-13_19_44  Epoch: 5, Training Step: 1900, Loss: 1.0020657777786255, Learning Rate: 0.0003
2022-06-11-13_20_12  Epoch: 5, Training Step: 2000, Loss: 1.5709660053253174, Learning Rate: 0.0003
2022-06-11-13_20_40  Epoch: 5, Training Step: 2100, Loss: 1.0665712356567383, Learning Rate: 0.0003
2022-06-11-13_21_08  Epoch: 5, Training Step: 2200, Loss: 1.200963020324707, Learning Rate: 0.0003
2022-06-11-13_21_36  Epoch: 5, Training Step: 2300, Loss: 1.2151967287063599, Learning Rate: 0.0003
2022-06-11-13_22_04  Epoch: 5, Training Step: 2400, Loss: 1.3598206043243408, Learning Rate: 0.0003
2022-06-11-13_22_32  Epoch: 5, Training Step: 2500, Loss: 1.1381700038909912, Learning Rate: 0.0003
2022-06-11-13_22_59  Epoch: 5, Training Step: 2600, Loss: 1.1006369590759277, Learning Rate: 0.0003
2022-06-11-13_23_26  Epoch: 5, Training Step: 2700, Loss: 1.4639432430267334, Learning Rate: 0.0003
2022-06-11-13_23_53  Epoch: 5, Training Step: 2800, Loss: 1.1078903675079346, Learning Rate: 0.0003
2022-06-11-13_24_20  Epoch: 5, Training Step: 2900, Loss: 1.1551339626312256, Learning Rate: 0.0003
2022-06-11-13_24_48  Epoch: 5, Training Step: 3000, Loss: 1.4615283012390137, Learning Rate: 0.0003
2022-06-11-13_25_17  Epoch: 5, Training Step: 3100, Loss: 1.6741094589233398, Learning Rate: 0.0003
2022-06-11-13_25_44  Epoch: 5, Training Step: 3200, Loss: 1.0621137619018555, Learning Rate: 0.0003
2022-06-11-13_28_50  Epoch: 6, Training Step: 0, Loss: 1.0064990520477295, Learning Rate: 0.00035
2022-06-11-13_29_17  Epoch: 6, Training Step: 100, Loss: 1.0588434934616089, Learning Rate: 0.00035
2022-06-11-13_29_45  Epoch: 6, Training Step: 200, Loss: 1.1358036994934082, Learning Rate: 0.00035
2022-06-11-13_30_13  Epoch: 6, Training Step: 300, Loss: 1.1019551753997803, Learning Rate: 0.00035
2022-06-11-13_30_41  Epoch: 6, Training Step: 400, Loss: 1.0230567455291748, Learning Rate: 0.00035
2022-06-11-13_31_08  Epoch: 6, Training Step: 500, Loss: 1.3357229232788086, Learning Rate: 0.00035
2022-06-11-13_31_36  Epoch: 6, Training Step: 600, Loss: 0.9353790283203125, Learning Rate: 0.00035
2022-06-11-13_32_03  Epoch: 6, Training Step: 700, Loss: 1.4727423191070557, Learning Rate: 0.00035
2022-06-11-13_32_31  Epoch: 6, Training Step: 800, Loss: 1.4170174598693848, Learning Rate: 0.00035
2022-06-11-13_32_59  Epoch: 6, Training Step: 900, Loss: 1.037494421005249, Learning Rate: 0.00035
2022-06-11-13_33_27  Epoch: 6, Training Step: 1000, Loss: 1.1875569820404053, Learning Rate: 0.00035
2022-06-11-13_33_55  Epoch: 6, Training Step: 1100, Loss: 1.0720798969268799, Learning Rate: 0.00035
2022-06-11-13_34_23  Epoch: 6, Training Step: 1200, Loss: 1.0661567449569702, Learning Rate: 0.00035
2022-06-11-13_34_50  Epoch: 6, Training Step: 1300, Loss: 1.126110553741455, Learning Rate: 0.00035
2022-06-11-13_35_18  Epoch: 6, Training Step: 1400, Loss: 1.357131004333496, Learning Rate: 0.00035
2022-06-11-13_35_45  Epoch: 6, Training Step: 1500, Loss: 1.1948051452636719, Learning Rate: 0.00035
2022-06-11-13_36_13  Epoch: 6, Training Step: 1600, Loss: 1.3552286624908447, Learning Rate: 0.00035
2022-06-11-13_36_40  Epoch: 6, Training Step: 1700, Loss: 1.3456103801727295, Learning Rate: 0.00035
2022-06-11-13_37_08  Epoch: 6, Training Step: 1800, Loss: 1.0772680044174194, Learning Rate: 0.00035
2022-06-11-13_37_35  Epoch: 6, Training Step: 1900, Loss: 1.2531764507293701, Learning Rate: 0.00035
2022-06-11-13_38_03  Epoch: 6, Training Step: 2000, Loss: 1.0692301988601685, Learning Rate: 0.00035
2022-06-11-13_38_30  Epoch: 6, Training Step: 2100, Loss: 1.3422119617462158, Learning Rate: 0.00035
2022-06-11-13_38_58  Epoch: 6, Training Step: 2200, Loss: 1.1861398220062256, Learning Rate: 0.00035
2022-06-11-13_39_26  Epoch: 6, Training Step: 2300, Loss: 1.042284369468689, Learning Rate: 0.00035
2022-06-11-13_39_53  Epoch: 6, Training Step: 2400, Loss: 1.111310601234436, Learning Rate: 0.00035
2022-06-11-13_40_21  Epoch: 6, Training Step: 2500, Loss: 1.802709698677063, Learning Rate: 0.00035
2022-06-11-13_40_49  Epoch: 6, Training Step: 2600, Loss: 1.2518553733825684, Learning Rate: 0.00035
2022-06-11-13_41_16  Epoch: 6, Training Step: 2700, Loss: 1.239771842956543, Learning Rate: 0.00035
2022-06-11-13_41_44  Epoch: 6, Training Step: 2800, Loss: 1.2735905647277832, Learning Rate: 0.00035
2022-06-11-13_42_12  Epoch: 6, Training Step: 2900, Loss: 1.3084803819656372, Learning Rate: 0.00035
2022-06-11-13_42_40  Epoch: 6, Training Step: 3000, Loss: 1.4846621751785278, Learning Rate: 0.00035
2022-06-11-13_43_08  Epoch: 6, Training Step: 3100, Loss: 1.0163202285766602, Learning Rate: 0.00035
2022-06-11-13_43_35  Epoch: 6, Training Step: 3200, Loss: 1.037039041519165, Learning Rate: 0.00035
2022-06-11-13_46_43  Epoch: 7, Training Step: 0, Loss: 1.3855664730072021, Learning Rate: 0.0004
2022-06-11-13_47_10  Epoch: 7, Training Step: 100, Loss: 1.5946290493011475, Learning Rate: 0.0004
2022-06-11-13_47_38  Epoch: 7, Training Step: 200, Loss: 1.3825047016143799, Learning Rate: 0.0004
2022-06-11-13_48_06  Epoch: 7, Training Step: 300, Loss: 0.8986911773681641, Learning Rate: 0.0004
2022-06-11-13_48_34  Epoch: 7, Training Step: 400, Loss: 1.39369535446167, Learning Rate: 0.0004
2022-06-11-13_49_00  Epoch: 7, Training Step: 500, Loss: 1.4859979152679443, Learning Rate: 0.0004
2022-06-11-13_49_28  Epoch: 7, Training Step: 600, Loss: 1.0018385648727417, Learning Rate: 0.0004
2022-06-11-13_49_55  Epoch: 7, Training Step: 700, Loss: 1.6864069700241089, Learning Rate: 0.0004
2022-06-11-13_50_23  Epoch: 7, Training Step: 800, Loss: 1.038094162940979, Learning Rate: 0.0004
2022-06-11-13_50_50  Epoch: 7, Training Step: 900, Loss: 1.1386032104492188, Learning Rate: 0.0004
2022-06-11-13_51_17  Epoch: 7, Training Step: 1000, Loss: 1.3485599756240845, Learning Rate: 0.0004
2022-06-11-13_51_45  Epoch: 7, Training Step: 1100, Loss: 1.0029008388519287, Learning Rate: 0.0004
2022-06-11-13_52_12  Epoch: 7, Training Step: 1200, Loss: 1.3013041019439697, Learning Rate: 0.0004
2022-06-11-13_52_39  Epoch: 7, Training Step: 1300, Loss: 1.0833067893981934, Learning Rate: 0.0004
2022-06-11-13_53_07  Epoch: 7, Training Step: 1400, Loss: 1.3950163125991821, Learning Rate: 0.0004
2022-06-11-13_53_35  Epoch: 7, Training Step: 1500, Loss: 0.9153417348861694, Learning Rate: 0.0004
2022-06-11-13_54_02  Epoch: 7, Training Step: 1600, Loss: 1.213122010231018, Learning Rate: 0.0004
2022-06-11-13_54_30  Epoch: 7, Training Step: 1700, Loss: 1.1022135019302368, Learning Rate: 0.0004
2022-06-11-13_54_56  Epoch: 7, Training Step: 1800, Loss: 1.0772194862365723, Learning Rate: 0.0004
2022-06-11-13_55_23  Epoch: 7, Training Step: 1900, Loss: 1.1866562366485596, Learning Rate: 0.0004
2022-06-11-13_55_50  Epoch: 7, Training Step: 2000, Loss: 1.2047383785247803, Learning Rate: 0.0004
2022-06-11-13_56_17  Epoch: 7, Training Step: 2100, Loss: 1.0140974521636963, Learning Rate: 0.0004
2022-06-11-13_56_44  Epoch: 7, Training Step: 2200, Loss: 0.9656492471694946, Learning Rate: 0.0004
2022-06-11-13_57_11  Epoch: 7, Training Step: 2300, Loss: 1.0244011878967285, Learning Rate: 0.0004
2022-06-11-13_57_39  Epoch: 7, Training Step: 2400, Loss: 1.0184969902038574, Learning Rate: 0.0004
2022-06-11-13_58_07  Epoch: 7, Training Step: 2500, Loss: 1.1382331848144531, Learning Rate: 0.0004
2022-06-11-13_58_34  Epoch: 7, Training Step: 2600, Loss: 1.0481122732162476, Learning Rate: 0.0004
2022-06-11-13_59_01  Epoch: 7, Training Step: 2700, Loss: 1.0263935327529907, Learning Rate: 0.0004
2022-06-11-13_59_28  Epoch: 7, Training Step: 2800, Loss: 1.0635827779769897, Learning Rate: 0.0004
2022-06-11-13_59_54  Epoch: 7, Training Step: 2900, Loss: 1.1210696697235107, Learning Rate: 0.0004
2022-06-11-14_00_21  Epoch: 7, Training Step: 3000, Loss: 1.1647608280181885, Learning Rate: 0.0004
2022-06-11-14_00_49  Epoch: 7, Training Step: 3100, Loss: 1.3309098482131958, Learning Rate: 0.0004
2022-06-11-14_01_16  Epoch: 7, Training Step: 3200, Loss: 0.9748032093048096, Learning Rate: 0.0004
2022-06-11-14_04_15  Epoch: 8, Training Step: 0, Loss: 0.9149909019470215, Learning Rate: 0.00045000000000000004
2022-06-11-14_04_41  Epoch: 8, Training Step: 100, Loss: 1.409179449081421, Learning Rate: 0.00045000000000000004
2022-06-11-14_05_08  Epoch: 8, Training Step: 200, Loss: 1.3012025356292725, Learning Rate: 0.00045000000000000004
2022-06-11-14_05_36  Epoch: 8, Training Step: 300, Loss: 1.2830326557159424, Learning Rate: 0.00045000000000000004
2022-06-11-14_06_02  Epoch: 8, Training Step: 400, Loss: 1.313869595527649, Learning Rate: 0.00045000000000000004
2022-06-11-14_06_30  Epoch: 8, Training Step: 500, Loss: 1.1312514543533325, Learning Rate: 0.00045000000000000004
2022-06-11-14_06_57  Epoch: 8, Training Step: 600, Loss: 1.2286280393600464, Learning Rate: 0.00045000000000000004
2022-06-11-14_07_24  Epoch: 8, Training Step: 700, Loss: 1.3863115310668945, Learning Rate: 0.00045000000000000004
2022-06-11-14_07_51  Epoch: 8, Training Step: 800, Loss: 1.1890146732330322, Learning Rate: 0.00045000000000000004
2022-06-11-14_08_18  Epoch: 8, Training Step: 900, Loss: 1.1510255336761475, Learning Rate: 0.00045000000000000004
2022-06-11-14_08_45  Epoch: 8, Training Step: 1000, Loss: 1.138659954071045, Learning Rate: 0.00045000000000000004
2022-06-11-14_09_11  Epoch: 8, Training Step: 1100, Loss: 1.281912922859192, Learning Rate: 0.00045000000000000004
2022-06-11-14_09_38  Epoch: 8, Training Step: 1200, Loss: 1.2291438579559326, Learning Rate: 0.00045000000000000004
2022-06-11-14_10_06  Epoch: 8, Training Step: 1300, Loss: 1.2642347812652588, Learning Rate: 0.00045000000000000004
2022-06-11-14_10_34  Epoch: 8, Training Step: 1400, Loss: 0.9430609345436096, Learning Rate: 0.00045000000000000004
2022-06-11-14_11_01  Epoch: 8, Training Step: 1500, Loss: 1.4440820217132568, Learning Rate: 0.00045000000000000004
2022-06-11-14_11_29  Epoch: 8, Training Step: 1600, Loss: 1.0245962142944336, Learning Rate: 0.00045000000000000004
2022-06-11-14_11_56  Epoch: 8, Training Step: 1700, Loss: 1.3519287109375, Learning Rate: 0.00045000000000000004
2022-06-11-14_12_23  Epoch: 8, Training Step: 1800, Loss: 1.3297290802001953, Learning Rate: 0.00045000000000000004
2022-06-11-14_12_52  Epoch: 8, Training Step: 1900, Loss: 1.3400092124938965, Learning Rate: 0.00045000000000000004
2022-06-11-14_13_20  Epoch: 8, Training Step: 2000, Loss: 1.182666301727295, Learning Rate: 0.00045000000000000004
2022-06-11-14_13_47  Epoch: 8, Training Step: 2100, Loss: 0.964227557182312, Learning Rate: 0.00045000000000000004
2022-06-11-14_14_15  Epoch: 8, Training Step: 2200, Loss: 1.1502212285995483, Learning Rate: 0.00045000000000000004
2022-06-11-14_14_43  Epoch: 8, Training Step: 2300, Loss: 1.0983155965805054, Learning Rate: 0.00045000000000000004
2022-06-11-14_15_10  Epoch: 8, Training Step: 2400, Loss: 1.0632553100585938, Learning Rate: 0.00045000000000000004
2022-06-11-14_15_38  Epoch: 8, Training Step: 2500, Loss: 0.9456197619438171, Learning Rate: 0.00045000000000000004
2022-06-11-14_16_06  Epoch: 8, Training Step: 2600, Loss: 0.991564154624939, Learning Rate: 0.00045000000000000004
2022-06-11-14_16_34  Epoch: 8, Training Step: 2700, Loss: 1.3260589838027954, Learning Rate: 0.00045000000000000004
2022-06-11-14_17_02  Epoch: 8, Training Step: 2800, Loss: 1.1133217811584473, Learning Rate: 0.00045000000000000004
2022-06-11-14_17_29  Epoch: 8, Training Step: 2900, Loss: 1.1359496116638184, Learning Rate: 0.00045000000000000004
2022-06-11-14_17_57  Epoch: 8, Training Step: 3000, Loss: 1.1168791055679321, Learning Rate: 0.00045000000000000004
2022-06-11-14_18_24  Epoch: 8, Training Step: 3100, Loss: 1.3818886280059814, Learning Rate: 0.00045000000000000004
2022-06-11-14_18_51  Epoch: 8, Training Step: 3200, Loss: 1.0562827587127686, Learning Rate: 0.00045000000000000004
2022-06-11-14_22_03  Epoch: 9, Training Step: 0, Loss: 0.9902658462524414, Learning Rate: 0.0005
2022-06-11-14_22_30  Epoch: 9, Training Step: 100, Loss: 1.183828353881836, Learning Rate: 0.0005
2022-06-11-14_22_58  Epoch: 9, Training Step: 200, Loss: 1.1116377115249634, Learning Rate: 0.0005
2022-06-11-14_23_25  Epoch: 9, Training Step: 300, Loss: 1.108275055885315, Learning Rate: 0.0005
2022-06-11-14_23_53  Epoch: 9, Training Step: 400, Loss: 1.0705249309539795, Learning Rate: 0.0005
2022-06-11-14_24_20  Epoch: 9, Training Step: 500, Loss: 1.120948314666748, Learning Rate: 0.0005
2022-06-11-14_24_47  Epoch: 9, Training Step: 600, Loss: 1.0905559062957764, Learning Rate: 0.0005
2022-06-11-14_25_14  Epoch: 9, Training Step: 700, Loss: 1.2499806880950928, Learning Rate: 0.0005
2022-06-11-14_25_40  Epoch: 9, Training Step: 800, Loss: 1.3981449604034424, Learning Rate: 0.0005
2022-06-11-14_26_08  Epoch: 9, Training Step: 900, Loss: 1.5239129066467285, Learning Rate: 0.0005
2022-06-11-14_26_35  Epoch: 9, Training Step: 1000, Loss: 1.0433130264282227, Learning Rate: 0.0005
2022-06-11-14_27_02  Epoch: 9, Training Step: 1100, Loss: 1.1036278009414673, Learning Rate: 0.0005
2022-06-11-14_27_30  Epoch: 9, Training Step: 1200, Loss: 1.1156412363052368, Learning Rate: 0.0005
2022-06-11-14_27_57  Epoch: 9, Training Step: 1300, Loss: 1.0830191373825073, Learning Rate: 0.0005
2022-06-11-14_28_24  Epoch: 9, Training Step: 1400, Loss: 1.0014327764511108, Learning Rate: 0.0005
2022-06-11-14_28_50  Epoch: 9, Training Step: 1500, Loss: 1.358188509941101, Learning Rate: 0.0005
2022-06-11-14_29_17  Epoch: 9, Training Step: 1600, Loss: 1.2356834411621094, Learning Rate: 0.0005
2022-06-11-14_29_43  Epoch: 9, Training Step: 1700, Loss: 1.4130058288574219, Learning Rate: 0.0005
2022-06-11-14_30_10  Epoch: 9, Training Step: 1800, Loss: 1.1047834157943726, Learning Rate: 0.0005
2022-06-11-14_30_38  Epoch: 9, Training Step: 1900, Loss: 1.1856482028961182, Learning Rate: 0.0005
2022-06-11-14_31_05  Epoch: 9, Training Step: 2000, Loss: 1.2781274318695068, Learning Rate: 0.0005
2022-06-11-14_31_33  Epoch: 9, Training Step: 2100, Loss: 1.1273794174194336, Learning Rate: 0.0005
2022-06-11-14_32_01  Epoch: 9, Training Step: 2200, Loss: 1.1355388164520264, Learning Rate: 0.0005
2022-06-11-14_32_28  Epoch: 9, Training Step: 2300, Loss: 1.1275804042816162, Learning Rate: 0.0005
2022-06-11-14_32_56  Epoch: 9, Training Step: 2400, Loss: 1.031104564666748, Learning Rate: 0.0005
2022-06-11-14_33_23  Epoch: 9, Training Step: 2500, Loss: 1.2776771783828735, Learning Rate: 0.0005
2022-06-11-14_33_51  Epoch: 9, Training Step: 2600, Loss: 1.3258519172668457, Learning Rate: 0.0005
2022-06-11-14_34_19  Epoch: 9, Training Step: 2700, Loss: 1.35652756690979, Learning Rate: 0.0005
2022-06-11-14_34_47  Epoch: 9, Training Step: 2800, Loss: 1.0597026348114014, Learning Rate: 0.0005
2022-06-11-14_35_14  Epoch: 9, Training Step: 2900, Loss: 1.2198596000671387, Learning Rate: 0.0005
2022-06-11-14_35_42  Epoch: 9, Training Step: 3000, Loss: 1.0671765804290771, Learning Rate: 0.0005
2022-06-11-14_36_10  Epoch: 9, Training Step: 3100, Loss: 1.1187958717346191, Learning Rate: 0.0005
2022-06-11-14_36_37  Epoch: 9, Training Step: 3200, Loss: 1.1006778478622437, Learning Rate: 0.0005
2022-06-11-14_39_36  Epoch: 10, Training Step: 0, Loss: 0.9996727705001831, Learning Rate: 0.0005
2022-06-11-14_40_03  Epoch: 10, Training Step: 100, Loss: 1.1263630390167236, Learning Rate: 0.0005
2022-06-11-14_40_29  Epoch: 10, Training Step: 200, Loss: 1.1443307399749756, Learning Rate: 0.0005
2022-06-11-14_40_57  Epoch: 10, Training Step: 300, Loss: 1.2719006538391113, Learning Rate: 0.0005
2022-06-11-14_41_24  Epoch: 10, Training Step: 400, Loss: 1.2678359746932983, Learning Rate: 0.0005
2022-06-11-14_41_51  Epoch: 10, Training Step: 500, Loss: 1.153489112854004, Learning Rate: 0.0005
2022-06-11-14_42_18  Epoch: 10, Training Step: 600, Loss: 1.36156165599823, Learning Rate: 0.0005
2022-06-11-14_42_46  Epoch: 10, Training Step: 700, Loss: 0.9508424401283264, Learning Rate: 0.0005
2022-06-11-14_43_13  Epoch: 10, Training Step: 800, Loss: 1.1882107257843018, Learning Rate: 0.0005
2022-06-11-14_43_40  Epoch: 10, Training Step: 900, Loss: 1.1808500289916992, Learning Rate: 0.0005
2022-06-11-14_44_07  Epoch: 10, Training Step: 1000, Loss: 1.114772081375122, Learning Rate: 0.0005
2022-06-11-14_44_35  Epoch: 10, Training Step: 1100, Loss: 1.1571708917617798, Learning Rate: 0.0005
2022-06-11-14_45_03  Epoch: 10, Training Step: 1200, Loss: 1.4107723236083984, Learning Rate: 0.0005
2022-06-11-14_45_30  Epoch: 10, Training Step: 1300, Loss: 1.2008265256881714, Learning Rate: 0.0005
2022-06-11-14_45_57  Epoch: 10, Training Step: 1400, Loss: 1.2796823978424072, Learning Rate: 0.0005
2022-06-11-14_46_24  Epoch: 10, Training Step: 1500, Loss: 1.285259485244751, Learning Rate: 0.0005
2022-06-11-14_46_52  Epoch: 10, Training Step: 1600, Loss: 1.3658130168914795, Learning Rate: 0.0005
2022-06-11-14_47_19  Epoch: 10, Training Step: 1700, Loss: 1.312244176864624, Learning Rate: 0.0005
2022-06-11-14_47_46  Epoch: 10, Training Step: 1800, Loss: 1.03875732421875, Learning Rate: 0.0005
2022-06-11-14_48_14  Epoch: 10, Training Step: 1900, Loss: 1.181962013244629, Learning Rate: 0.0005
2022-06-11-14_48_40  Epoch: 10, Training Step: 2000, Loss: 0.9745832681655884, Learning Rate: 0.0005
2022-06-11-14_49_07  Epoch: 10, Training Step: 2100, Loss: 1.1343988180160522, Learning Rate: 0.0005
2022-06-11-14_49_34  Epoch: 10, Training Step: 2200, Loss: 1.0955536365509033, Learning Rate: 0.0005
2022-06-11-14_50_01  Epoch: 10, Training Step: 2300, Loss: 1.281184434890747, Learning Rate: 0.0005
2022-06-11-14_50_28  Epoch: 10, Training Step: 2400, Loss: 1.2055569887161255, Learning Rate: 0.0005
2022-06-11-14_50_56  Epoch: 10, Training Step: 2500, Loss: 1.1488051414489746, Learning Rate: 0.0005
2022-06-11-14_51_22  Epoch: 10, Training Step: 2600, Loss: 1.2556524276733398, Learning Rate: 0.0005
2022-06-11-14_51_49  Epoch: 10, Training Step: 2700, Loss: 1.0205440521240234, Learning Rate: 0.0005
2022-06-11-14_52_16  Epoch: 10, Training Step: 2800, Loss: 1.1983362436294556, Learning Rate: 0.0005
2022-06-11-14_52_43  Epoch: 10, Training Step: 2900, Loss: 1.1329777240753174, Learning Rate: 0.0005
2022-06-11-14_53_10  Epoch: 10, Training Step: 3000, Loss: 1.3220471143722534, Learning Rate: 0.0005
2022-06-11-14_53_36  Epoch: 10, Training Step: 3100, Loss: 1.0393285751342773, Learning Rate: 0.0005
2022-06-11-14_54_03  Epoch: 10, Training Step: 3200, Loss: 1.1064226627349854, Learning Rate: 0.0005
2022-06-11-14_57_05  Epoch: 11, Training Step: 0, Loss: 1.1901800632476807, Learning Rate: 0.0005
2022-06-11-14_57_32  Epoch: 11, Training Step: 100, Loss: 1.6696114540100098, Learning Rate: 0.0005
2022-06-11-14_57_59  Epoch: 11, Training Step: 200, Loss: 1.1316685676574707, Learning Rate: 0.0005
2022-06-11-14_58_26  Epoch: 11, Training Step: 300, Loss: 1.1940906047821045, Learning Rate: 0.0005
2022-06-11-14_58_53  Epoch: 11, Training Step: 400, Loss: 1.1272897720336914, Learning Rate: 0.0005
2022-06-11-14_59_20  Epoch: 11, Training Step: 500, Loss: 1.3596811294555664, Learning Rate: 0.0005
2022-06-11-14_59_46  Epoch: 11, Training Step: 600, Loss: 0.9961151480674744, Learning Rate: 0.0005
2022-06-11-15_00_12  Epoch: 11, Training Step: 700, Loss: 1.0223907232284546, Learning Rate: 0.0005
2022-06-11-15_00_39  Epoch: 11, Training Step: 800, Loss: 0.9883766174316406, Learning Rate: 0.0005
2022-06-11-15_01_06  Epoch: 11, Training Step: 900, Loss: 1.1456298828125, Learning Rate: 0.0005
2022-06-11-15_01_33  Epoch: 11, Training Step: 1000, Loss: 1.2345452308654785, Learning Rate: 0.0005
2022-06-11-15_02_01  Epoch: 11, Training Step: 1100, Loss: 1.0621891021728516, Learning Rate: 0.0005
2022-06-11-15_02_27  Epoch: 11, Training Step: 1200, Loss: 0.8950831890106201, Learning Rate: 0.0005
2022-06-11-15_02_54  Epoch: 11, Training Step: 1300, Loss: 1.0551722049713135, Learning Rate: 0.0005
2022-06-11-15_03_22  Epoch: 11, Training Step: 1400, Loss: 1.202894687652588, Learning Rate: 0.0005
2022-06-11-15_03_50  Epoch: 11, Training Step: 1500, Loss: 1.5691550970077515, Learning Rate: 0.0005
2022-06-11-15_04_16  Epoch: 11, Training Step: 1600, Loss: 1.421728253364563, Learning Rate: 0.0005
2022-06-11-15_04_43  Epoch: 11, Training Step: 1700, Loss: 1.0121712684631348, Learning Rate: 0.0005
2022-06-11-15_05_10  Epoch: 11, Training Step: 1800, Loss: 1.1454973220825195, Learning Rate: 0.0005
2022-06-11-15_05_37  Epoch: 11, Training Step: 1900, Loss: 1.2093228101730347, Learning Rate: 0.0005
2022-06-11-15_06_04  Epoch: 11, Training Step: 2000, Loss: 1.7152690887451172, Learning Rate: 0.0005
2022-06-11-15_06_31  Epoch: 11, Training Step: 2100, Loss: 1.2261251211166382, Learning Rate: 0.0005
2022-06-11-15_06_58  Epoch: 11, Training Step: 2200, Loss: 1.501816987991333, Learning Rate: 0.0005
2022-06-11-15_07_26  Epoch: 11, Training Step: 2300, Loss: 1.1405303478240967, Learning Rate: 0.0005
2022-06-11-15_07_53  Epoch: 11, Training Step: 2400, Loss: 1.0025050640106201, Learning Rate: 0.0005
2022-06-11-15_08_20  Epoch: 11, Training Step: 2500, Loss: 1.3903204202651978, Learning Rate: 0.0005
2022-06-11-15_08_47  Epoch: 11, Training Step: 2600, Loss: 1.3612912893295288, Learning Rate: 0.0005
2022-06-11-15_09_14  Epoch: 11, Training Step: 2700, Loss: 1.6703052520751953, Learning Rate: 0.0005
2022-06-11-15_09_41  Epoch: 11, Training Step: 2800, Loss: 0.9084339141845703, Learning Rate: 0.0005
2022-06-11-15_10_08  Epoch: 11, Training Step: 2900, Loss: 1.1855659484863281, Learning Rate: 0.0005
2022-06-11-15_10_35  Epoch: 11, Training Step: 3000, Loss: 1.1086900234222412, Learning Rate: 0.0005
2022-06-11-15_11_02  Epoch: 11, Training Step: 3100, Loss: 1.2183837890625, Learning Rate: 0.0005
2022-06-11-15_11_28  Epoch: 11, Training Step: 3200, Loss: 1.1203413009643555, Learning Rate: 0.0005
2022-06-11-15_14_24  Epoch: 12, Training Step: 0, Loss: 1.247032880783081, Learning Rate: 0.0005
2022-06-11-15_14_51  Epoch: 12, Training Step: 100, Loss: 1.3148447275161743, Learning Rate: 0.0005
2022-06-11-15_15_19  Epoch: 12, Training Step: 200, Loss: 0.9925093650817871, Learning Rate: 0.0005
2022-06-11-15_15_46  Epoch: 12, Training Step: 300, Loss: 1.2307937145233154, Learning Rate: 0.0005
2022-06-11-15_16_13  Epoch: 12, Training Step: 400, Loss: 1.0787451267242432, Learning Rate: 0.0005
2022-06-11-15_16_39  Epoch: 12, Training Step: 500, Loss: 1.148329496383667, Learning Rate: 0.0005
2022-06-11-15_17_06  Epoch: 12, Training Step: 600, Loss: 1.2293014526367188, Learning Rate: 0.0005
2022-06-11-15_17_32  Epoch: 12, Training Step: 700, Loss: 1.6161813735961914, Learning Rate: 0.0005
2022-06-11-15_17_59  Epoch: 12, Training Step: 800, Loss: 1.1759748458862305, Learning Rate: 0.0005
2022-06-11-15_18_26  Epoch: 12, Training Step: 900, Loss: 1.171034812927246, Learning Rate: 0.0005
2022-06-11-15_18_53  Epoch: 12, Training Step: 1000, Loss: 1.54184091091156, Learning Rate: 0.0005
2022-06-11-15_19_20  Epoch: 12, Training Step: 1100, Loss: 1.0231256484985352, Learning Rate: 0.0005
2022-06-11-15_19_47  Epoch: 12, Training Step: 1200, Loss: 1.3027042150497437, Learning Rate: 0.0005
2022-06-11-15_20_14  Epoch: 12, Training Step: 1300, Loss: 1.6192095279693604, Learning Rate: 0.0005
2022-06-11-15_20_41  Epoch: 12, Training Step: 1400, Loss: 1.2209234237670898, Learning Rate: 0.0005
2022-06-11-15_21_08  Epoch: 12, Training Step: 1500, Loss: 1.1268280744552612, Learning Rate: 0.0005
2022-06-11-15_21_35  Epoch: 12, Training Step: 1600, Loss: 1.3641183376312256, Learning Rate: 0.0005
2022-06-11-15_22_02  Epoch: 12, Training Step: 1700, Loss: 1.0034339427947998, Learning Rate: 0.0005
2022-06-11-15_22_30  Epoch: 12, Training Step: 1800, Loss: 1.2322852611541748, Learning Rate: 0.0005
2022-06-11-15_22_57  Epoch: 12, Training Step: 1900, Loss: 1.0932643413543701, Learning Rate: 0.0005
2022-06-11-15_23_24  Epoch: 12, Training Step: 2000, Loss: 1.0546668767929077, Learning Rate: 0.0005
2022-06-11-15_23_50  Epoch: 12, Training Step: 2100, Loss: 1.1934847831726074, Learning Rate: 0.0005
2022-06-11-15_24_17  Epoch: 12, Training Step: 2200, Loss: 1.127625584602356, Learning Rate: 0.0005
2022-06-11-15_24_45  Epoch: 12, Training Step: 2300, Loss: 1.1649556159973145, Learning Rate: 0.0005
2022-06-11-15_25_11  Epoch: 12, Training Step: 2400, Loss: 0.9201022982597351, Learning Rate: 0.0005
2022-06-11-15_25_38  Epoch: 12, Training Step: 2500, Loss: 0.8510209918022156, Learning Rate: 0.0005
2022-06-11-15_26_05  Epoch: 12, Training Step: 2600, Loss: 1.1358871459960938, Learning Rate: 0.0005
2022-06-11-15_26_32  Epoch: 12, Training Step: 2700, Loss: 0.9210004806518555, Learning Rate: 0.0005
2022-06-11-15_26_59  Epoch: 12, Training Step: 2800, Loss: 1.39278244972229, Learning Rate: 0.0005
2022-06-11-15_27_26  Epoch: 12, Training Step: 2900, Loss: 1.1780405044555664, Learning Rate: 0.0005
2022-06-11-15_27_54  Epoch: 12, Training Step: 3000, Loss: 1.3243083953857422, Learning Rate: 0.0005
2022-06-11-15_28_20  Epoch: 12, Training Step: 3100, Loss: 1.1136507987976074, Learning Rate: 0.0005
2022-06-11-15_28_48  Epoch: 12, Training Step: 3200, Loss: 1.3352274894714355, Learning Rate: 0.0005
2022-06-11-15_31_50  Epoch: 13, Training Step: 0, Loss: 0.9028431177139282, Learning Rate: 0.0005
2022-06-11-15_32_17  Epoch: 13, Training Step: 100, Loss: 1.1464051008224487, Learning Rate: 0.0005
2022-06-11-15_32_44  Epoch: 13, Training Step: 200, Loss: 1.477353811264038, Learning Rate: 0.0005
2022-06-11-15_33_10  Epoch: 13, Training Step: 300, Loss: 1.0724283456802368, Learning Rate: 0.0005
2022-06-11-15_33_38  Epoch: 13, Training Step: 400, Loss: 0.9507344961166382, Learning Rate: 0.0005
2022-06-11-15_34_05  Epoch: 13, Training Step: 500, Loss: 1.3820812702178955, Learning Rate: 0.0005
2022-06-11-15_34_32  Epoch: 13, Training Step: 600, Loss: 1.2908458709716797, Learning Rate: 0.0005
2022-06-11-15_34_59  Epoch: 13, Training Step: 700, Loss: 0.9248936772346497, Learning Rate: 0.0005
2022-06-11-15_35_26  Epoch: 13, Training Step: 800, Loss: 1.052206039428711, Learning Rate: 0.0005
2022-06-11-15_35_53  Epoch: 13, Training Step: 900, Loss: 1.0187962055206299, Learning Rate: 0.0005
2022-06-11-15_36_20  Epoch: 13, Training Step: 1000, Loss: 1.3140195608139038, Learning Rate: 0.0005
2022-06-11-15_36_46  Epoch: 13, Training Step: 1100, Loss: 1.019210696220398, Learning Rate: 0.0005
2022-06-11-15_37_14  Epoch: 13, Training Step: 1200, Loss: 0.9946263432502747, Learning Rate: 0.0005
2022-06-11-15_37_41  Epoch: 13, Training Step: 1300, Loss: 1.049408197402954, Learning Rate: 0.0005
2022-06-11-15_38_08  Epoch: 13, Training Step: 1400, Loss: 0.9419963359832764, Learning Rate: 0.0005
2022-06-11-15_38_35  Epoch: 13, Training Step: 1500, Loss: 1.2726343870162964, Learning Rate: 0.0005
2022-06-11-15_39_03  Epoch: 13, Training Step: 1600, Loss: 1.130798101425171, Learning Rate: 0.0005
2022-06-11-15_39_29  Epoch: 13, Training Step: 1700, Loss: 1.1172599792480469, Learning Rate: 0.0005
2022-06-11-15_39_57  Epoch: 13, Training Step: 1800, Loss: 1.1094441413879395, Learning Rate: 0.0005
2022-06-11-15_40_24  Epoch: 13, Training Step: 1900, Loss: 1.0479435920715332, Learning Rate: 0.0005
2022-06-11-15_40_51  Epoch: 13, Training Step: 2000, Loss: 1.0668646097183228, Learning Rate: 0.0005
2022-06-11-15_41_18  Epoch: 13, Training Step: 2100, Loss: 0.9458680152893066, Learning Rate: 0.0005
2022-06-11-15_41_45  Epoch: 13, Training Step: 2200, Loss: 1.4360355138778687, Learning Rate: 0.0005
2022-06-11-15_42_12  Epoch: 13, Training Step: 2300, Loss: 1.1126048564910889, Learning Rate: 0.0005
2022-06-11-15_42_39  Epoch: 13, Training Step: 2400, Loss: 1.1711640357971191, Learning Rate: 0.0005
2022-06-11-15_43_06  Epoch: 13, Training Step: 2500, Loss: 1.2428536415100098, Learning Rate: 0.0005
2022-06-11-15_43_32  Epoch: 13, Training Step: 2600, Loss: 0.8954789638519287, Learning Rate: 0.0005
2022-06-11-15_43_59  Epoch: 13, Training Step: 2700, Loss: 1.2194499969482422, Learning Rate: 0.0005
2022-06-11-15_44_26  Epoch: 13, Training Step: 2800, Loss: 1.0274384021759033, Learning Rate: 0.0005
2022-06-11-15_44_53  Epoch: 13, Training Step: 2900, Loss: 1.2400600910186768, Learning Rate: 0.0005
2022-06-11-15_45_21  Epoch: 13, Training Step: 3000, Loss: 1.0701520442962646, Learning Rate: 0.0005
2022-06-11-15_45_48  Epoch: 13, Training Step: 3100, Loss: 1.0338224172592163, Learning Rate: 0.0005
2022-06-11-15_46_14  Epoch: 13, Training Step: 3200, Loss: 0.9902729988098145, Learning Rate: 0.0005
2022-06-11-15_49_14  Epoch: 14, Training Step: 0, Loss: 1.1310327053070068, Learning Rate: 0.0005
2022-06-11-15_49_41  Epoch: 14, Training Step: 100, Loss: 1.5012273788452148, Learning Rate: 0.0005
2022-06-11-15_50_08  Epoch: 14, Training Step: 200, Loss: 1.2326529026031494, Learning Rate: 0.0005
2022-06-11-15_50_35  Epoch: 14, Training Step: 300, Loss: 1.1318047046661377, Learning Rate: 0.0005
2022-06-11-15_51_02  Epoch: 14, Training Step: 400, Loss: 1.1948401927947998, Learning Rate: 0.0005
2022-06-11-15_51_29  Epoch: 14, Training Step: 500, Loss: 1.1573883295059204, Learning Rate: 0.0005
2022-06-11-15_51_56  Epoch: 14, Training Step: 600, Loss: 0.9739535450935364, Learning Rate: 0.0005
2022-06-11-15_52_24  Epoch: 14, Training Step: 700, Loss: 1.0699394941329956, Learning Rate: 0.0005
2022-06-11-15_52_51  Epoch: 14, Training Step: 800, Loss: 0.8729660511016846, Learning Rate: 0.0005
2022-06-11-15_53_17  Epoch: 14, Training Step: 900, Loss: 1.305024266242981, Learning Rate: 0.0005
2022-06-11-15_53_44  Epoch: 14, Training Step: 1000, Loss: 1.118597149848938, Learning Rate: 0.0005
2022-06-11-15_54_11  Epoch: 14, Training Step: 1100, Loss: 1.1220839023590088, Learning Rate: 0.0005
2022-06-11-15_54_38  Epoch: 14, Training Step: 1200, Loss: 1.3891503810882568, Learning Rate: 0.0005
2022-06-11-15_55_04  Epoch: 14, Training Step: 1300, Loss: 1.1790591478347778, Learning Rate: 0.0005
2022-06-11-15_55_32  Epoch: 14, Training Step: 1400, Loss: 0.8465138077735901, Learning Rate: 0.0005
2022-06-11-15_55_59  Epoch: 14, Training Step: 1500, Loss: 1.193110704421997, Learning Rate: 0.0005
2022-06-11-15_56_26  Epoch: 14, Training Step: 1600, Loss: 0.826556384563446, Learning Rate: 0.0005
2022-06-11-15_56_53  Epoch: 14, Training Step: 1700, Loss: 1.0117931365966797, Learning Rate: 0.0005
2022-06-11-15_57_20  Epoch: 14, Training Step: 1800, Loss: 1.0087568759918213, Learning Rate: 0.0005
2022-06-11-15_57_47  Epoch: 14, Training Step: 1900, Loss: 1.1526219844818115, Learning Rate: 0.0005
2022-06-11-15_58_14  Epoch: 14, Training Step: 2000, Loss: 1.1926593780517578, Learning Rate: 0.0005
2022-06-11-15_58_41  Epoch: 14, Training Step: 2100, Loss: 1.215949296951294, Learning Rate: 0.0005
2022-06-11-15_59_08  Epoch: 14, Training Step: 2200, Loss: 0.8825156688690186, Learning Rate: 0.0005
2022-06-11-15_59_35  Epoch: 14, Training Step: 2300, Loss: 1.252418875694275, Learning Rate: 0.0005
2022-06-11-16_00_01  Epoch: 14, Training Step: 2400, Loss: 0.961732029914856, Learning Rate: 0.0005
2022-06-11-16_00_28  Epoch: 14, Training Step: 2500, Loss: 1.0434844493865967, Learning Rate: 0.0005
2022-06-11-16_00_55  Epoch: 14, Training Step: 2600, Loss: 0.947956919670105, Learning Rate: 0.0005
2022-06-11-16_01_23  Epoch: 14, Training Step: 2700, Loss: 1.231647253036499, Learning Rate: 0.0005
2022-06-11-16_01_49  Epoch: 14, Training Step: 2800, Loss: 1.1034655570983887, Learning Rate: 0.0005
2022-06-11-16_02_15  Epoch: 14, Training Step: 2900, Loss: 1.4298374652862549, Learning Rate: 0.0005
2022-06-11-16_02_42  Epoch: 14, Training Step: 3000, Loss: 0.8487426042556763, Learning Rate: 0.0005
2022-06-11-16_03_09  Epoch: 14, Training Step: 3100, Loss: 1.3663572072982788, Learning Rate: 0.0005
2022-06-11-16_03_36  Epoch: 14, Training Step: 3200, Loss: 1.0110013484954834, Learning Rate: 0.0005
2022-06-11-16_06_37  Epoch: 15, Training Step: 0, Loss: 1.0731158256530762, Learning Rate: 0.0005
2022-06-11-16_07_05  Epoch: 15, Training Step: 100, Loss: 1.0160133838653564, Learning Rate: 0.0005
2022-06-11-16_07_33  Epoch: 15, Training Step: 200, Loss: 1.0473532676696777, Learning Rate: 0.0005
2022-06-11-16_08_00  Epoch: 15, Training Step: 300, Loss: 0.9967776536941528, Learning Rate: 0.0005
2022-06-11-16_08_27  Epoch: 15, Training Step: 400, Loss: 1.1063125133514404, Learning Rate: 0.0005
2022-06-11-16_08_53  Epoch: 15, Training Step: 500, Loss: 1.0319161415100098, Learning Rate: 0.0005
2022-06-11-16_09_20  Epoch: 15, Training Step: 600, Loss: 0.9754555821418762, Learning Rate: 0.0005
2022-06-11-16_09_47  Epoch: 15, Training Step: 700, Loss: 1.2341723442077637, Learning Rate: 0.0005
2022-06-11-16_10_14  Epoch: 15, Training Step: 800, Loss: 1.068359136581421, Learning Rate: 0.0005
2022-06-11-16_10_41  Epoch: 15, Training Step: 900, Loss: 1.2850701808929443, Learning Rate: 0.0005
2022-06-11-16_11_08  Epoch: 15, Training Step: 1000, Loss: 1.0809309482574463, Learning Rate: 0.0005
2022-06-11-16_11_35  Epoch: 15, Training Step: 1100, Loss: 0.8632314205169678, Learning Rate: 0.0005
2022-06-11-16_12_02  Epoch: 15, Training Step: 1200, Loss: 0.9922436475753784, Learning Rate: 0.0005
2022-06-11-16_12_29  Epoch: 15, Training Step: 1300, Loss: 1.242074966430664, Learning Rate: 0.0005
2022-06-11-16_12_56  Epoch: 15, Training Step: 1400, Loss: 1.0775301456451416, Learning Rate: 0.0005
2022-06-11-16_13_23  Epoch: 15, Training Step: 1500, Loss: 0.9774206280708313, Learning Rate: 0.0005
2022-06-11-16_13_50  Epoch: 15, Training Step: 1600, Loss: 1.457953691482544, Learning Rate: 0.0005
2022-06-11-16_14_17  Epoch: 15, Training Step: 1700, Loss: 1.2432178258895874, Learning Rate: 0.0005
2022-06-11-16_14_44  Epoch: 15, Training Step: 1800, Loss: 1.2473340034484863, Learning Rate: 0.0005
2022-06-11-16_15_11  Epoch: 15, Training Step: 1900, Loss: 0.8979220390319824, Learning Rate: 0.0005
2022-06-11-16_15_37  Epoch: 15, Training Step: 2000, Loss: 0.9823242425918579, Learning Rate: 0.0005
2022-06-11-16_16_05  Epoch: 15, Training Step: 2100, Loss: 1.194561243057251, Learning Rate: 0.0005
2022-06-11-16_16_32  Epoch: 15, Training Step: 2200, Loss: 0.9378173351287842, Learning Rate: 0.0005
2022-06-11-16_16_59  Epoch: 15, Training Step: 2300, Loss: 0.904889702796936, Learning Rate: 0.0005
2022-06-11-16_17_26  Epoch: 15, Training Step: 2400, Loss: 1.0827124118804932, Learning Rate: 0.0005
2022-06-11-16_17_53  Epoch: 15, Training Step: 2500, Loss: 0.8956049084663391, Learning Rate: 0.0005
2022-06-11-16_18_20  Epoch: 15, Training Step: 2600, Loss: 0.8999770879745483, Learning Rate: 0.0005
2022-06-11-16_18_47  Epoch: 15, Training Step: 2700, Loss: 1.1723721027374268, Learning Rate: 0.0005
2022-06-11-16_19_14  Epoch: 15, Training Step: 2800, Loss: 1.2060340642929077, Learning Rate: 0.0005
2022-06-11-16_19_41  Epoch: 15, Training Step: 2900, Loss: 0.9672418832778931, Learning Rate: 0.0005
2022-06-11-16_20_08  Epoch: 15, Training Step: 3000, Loss: 0.9879023432731628, Learning Rate: 0.0005
2022-06-11-16_20_36  Epoch: 15, Training Step: 3100, Loss: 0.9186134338378906, Learning Rate: 0.0005
2022-06-11-16_21_03  Epoch: 15, Training Step: 3200, Loss: 1.382629156112671, Learning Rate: 0.0005
2022-06-11-16_24_00  Epoch: 16, Training Step: 0, Loss: 0.8464668989181519, Learning Rate: 0.0005
2022-06-11-16_24_27  Epoch: 16, Training Step: 100, Loss: 0.9894727468490601, Learning Rate: 0.0005
2022-06-11-16_24_54  Epoch: 16, Training Step: 200, Loss: 0.9361720085144043, Learning Rate: 0.0005
2022-06-11-16_25_21  Epoch: 16, Training Step: 300, Loss: 1.1465487480163574, Learning Rate: 0.0005
2022-06-11-16_25_48  Epoch: 16, Training Step: 400, Loss: 0.961929202079773, Learning Rate: 0.0005
2022-06-11-16_26_14  Epoch: 16, Training Step: 500, Loss: 1.0741755962371826, Learning Rate: 0.0005
2022-06-11-16_26_41  Epoch: 16, Training Step: 600, Loss: 1.140052318572998, Learning Rate: 0.0005
2022-06-11-16_27_08  Epoch: 16, Training Step: 700, Loss: 0.9098001718521118, Learning Rate: 0.0005
2022-06-11-16_27_35  Epoch: 16, Training Step: 800, Loss: 0.9948786497116089, Learning Rate: 0.0005
2022-06-11-16_28_02  Epoch: 16, Training Step: 900, Loss: 1.0675108432769775, Learning Rate: 0.0005
2022-06-11-16_28_29  Epoch: 16, Training Step: 1000, Loss: 1.0062878131866455, Learning Rate: 0.0005
2022-06-11-16_28_56  Epoch: 16, Training Step: 1100, Loss: 1.0540313720703125, Learning Rate: 0.0005
2022-06-11-16_29_23  Epoch: 16, Training Step: 1200, Loss: 1.1576356887817383, Learning Rate: 0.0005
2022-06-11-16_29_50  Epoch: 16, Training Step: 1300, Loss: 1.120190143585205, Learning Rate: 0.0005
2022-06-11-16_30_16  Epoch: 16, Training Step: 1400, Loss: 1.0518758296966553, Learning Rate: 0.0005
2022-06-11-16_30_44  Epoch: 16, Training Step: 1500, Loss: 1.3410894870758057, Learning Rate: 0.0005
2022-06-11-16_31_10  Epoch: 16, Training Step: 1600, Loss: 1.3041331768035889, Learning Rate: 0.0005
2022-06-11-16_31_37  Epoch: 16, Training Step: 1700, Loss: 0.9481334686279297, Learning Rate: 0.0005
2022-06-11-16_32_04  Epoch: 16, Training Step: 1800, Loss: 1.0703068971633911, Learning Rate: 0.0005
2022-06-11-16_32_31  Epoch: 16, Training Step: 1900, Loss: 0.9075995087623596, Learning Rate: 0.0005
2022-06-11-16_32_58  Epoch: 16, Training Step: 2000, Loss: 1.4394972324371338, Learning Rate: 0.0005
2022-06-11-16_33_25  Epoch: 16, Training Step: 2100, Loss: 0.917809247970581, Learning Rate: 0.0005
2022-06-11-16_33_52  Epoch: 16, Training Step: 2200, Loss: 1.053597092628479, Learning Rate: 0.0005
2022-06-11-16_34_20  Epoch: 16, Training Step: 2300, Loss: 1.2647314071655273, Learning Rate: 0.0005
2022-06-11-16_34_46  Epoch: 16, Training Step: 2400, Loss: 0.9668329358100891, Learning Rate: 0.0005
2022-06-11-16_35_13  Epoch: 16, Training Step: 2500, Loss: 1.1018812656402588, Learning Rate: 0.0005
2022-06-11-16_35_39  Epoch: 16, Training Step: 2600, Loss: 1.0027198791503906, Learning Rate: 0.0005
2022-06-11-16_36_06  Epoch: 16, Training Step: 2700, Loss: 1.1969958543777466, Learning Rate: 0.0005
2022-06-11-16_36_32  Epoch: 16, Training Step: 2800, Loss: 1.491642713546753, Learning Rate: 0.0005
2022-06-11-16_36_59  Epoch: 16, Training Step: 2900, Loss: 1.1058461666107178, Learning Rate: 0.0005
2022-06-11-16_37_26  Epoch: 16, Training Step: 3000, Loss: 1.0708187818527222, Learning Rate: 0.0005
2022-06-11-16_37_53  Epoch: 16, Training Step: 3100, Loss: 1.0575523376464844, Learning Rate: 0.0005
2022-06-11-16_38_20  Epoch: 16, Training Step: 3200, Loss: 1.2220871448516846, Learning Rate: 0.0005
2022-06-11-16_41_23  Epoch: 17, Training Step: 0, Loss: 1.0312994718551636, Learning Rate: 0.0005
2022-06-11-16_41_51  Epoch: 17, Training Step: 100, Loss: 1.41098153591156, Learning Rate: 0.0005
2022-06-11-16_42_18  Epoch: 17, Training Step: 200, Loss: 1.0603597164154053, Learning Rate: 0.0005
2022-06-11-16_42_45  Epoch: 17, Training Step: 300, Loss: 1.0296939611434937, Learning Rate: 0.0005
2022-06-11-16_43_13  Epoch: 17, Training Step: 400, Loss: 1.3128314018249512, Learning Rate: 0.0005
2022-06-11-16_43_40  Epoch: 17, Training Step: 500, Loss: 1.1388170719146729, Learning Rate: 0.0005
2022-06-11-16_44_07  Epoch: 17, Training Step: 600, Loss: 1.1295585632324219, Learning Rate: 0.0005
2022-06-11-16_44_34  Epoch: 17, Training Step: 700, Loss: 1.15358304977417, Learning Rate: 0.0005
2022-06-11-16_45_00  Epoch: 17, Training Step: 800, Loss: 1.191986083984375, Learning Rate: 0.0005
2022-06-11-16_45_28  Epoch: 17, Training Step: 900, Loss: 0.9202686548233032, Learning Rate: 0.0005
2022-06-11-16_45_55  Epoch: 17, Training Step: 1000, Loss: 1.023421049118042, Learning Rate: 0.0005
2022-06-11-16_46_22  Epoch: 17, Training Step: 1100, Loss: 1.0573792457580566, Learning Rate: 0.0005
2022-06-11-16_46_49  Epoch: 17, Training Step: 1200, Loss: 1.2244832515716553, Learning Rate: 0.0005
2022-06-11-16_47_17  Epoch: 17, Training Step: 1300, Loss: 1.174664855003357, Learning Rate: 0.0005
2022-06-11-16_47_44  Epoch: 17, Training Step: 1400, Loss: 0.9969823360443115, Learning Rate: 0.0005
2022-06-11-16_48_11  Epoch: 17, Training Step: 1500, Loss: 1.0219454765319824, Learning Rate: 0.0005
2022-06-11-16_48_37  Epoch: 17, Training Step: 1600, Loss: 0.9886231422424316, Learning Rate: 0.0005
2022-06-11-16_49_04  Epoch: 17, Training Step: 1700, Loss: 1.216768503189087, Learning Rate: 0.0005
2022-06-11-16_49_31  Epoch: 17, Training Step: 1800, Loss: 1.6100236177444458, Learning Rate: 0.0005
2022-06-11-16_49_57  Epoch: 17, Training Step: 1900, Loss: 1.0877033472061157, Learning Rate: 0.0005
2022-06-11-16_50_24  Epoch: 17, Training Step: 2000, Loss: 1.1360857486724854, Learning Rate: 0.0005
2022-06-11-16_50_52  Epoch: 17, Training Step: 2100, Loss: 0.9480258226394653, Learning Rate: 0.0005
2022-06-11-16_51_19  Epoch: 17, Training Step: 2200, Loss: 1.1820428371429443, Learning Rate: 0.0005
2022-06-11-16_51_45  Epoch: 17, Training Step: 2300, Loss: 0.9227538108825684, Learning Rate: 0.0005
2022-06-11-16_52_13  Epoch: 17, Training Step: 2400, Loss: 0.9767598509788513, Learning Rate: 0.0005
2022-06-11-16_52_40  Epoch: 17, Training Step: 2500, Loss: 0.847714900970459, Learning Rate: 0.0005
2022-06-11-16_53_07  Epoch: 17, Training Step: 2600, Loss: 1.014905333518982, Learning Rate: 0.0005
2022-06-11-16_53_34  Epoch: 17, Training Step: 2700, Loss: 0.8809043169021606, Learning Rate: 0.0005
2022-06-11-16_54_01  Epoch: 17, Training Step: 2800, Loss: 0.8840841054916382, Learning Rate: 0.0005
2022-06-11-16_54_28  Epoch: 17, Training Step: 2900, Loss: 1.2066535949707031, Learning Rate: 0.0005
2022-06-11-16_54_55  Epoch: 17, Training Step: 3000, Loss: 1.2322132587432861, Learning Rate: 0.0005
2022-06-11-16_55_22  Epoch: 17, Training Step: 3100, Loss: 0.9175085425376892, Learning Rate: 0.0005
2022-06-11-16_55_49  Epoch: 17, Training Step: 3200, Loss: 1.0019276142120361, Learning Rate: 0.0005
2022-06-11-16_58_51  Epoch: 18, Training Step: 0, Loss: 0.9275822639465332, Learning Rate: 0.0005
2022-06-11-16_59_19  Epoch: 18, Training Step: 100, Loss: 0.9631880521774292, Learning Rate: 0.0005
2022-06-11-16_59_46  Epoch: 18, Training Step: 200, Loss: 0.9824031591415405, Learning Rate: 0.0005
2022-06-11-17_00_13  Epoch: 18, Training Step: 300, Loss: 1.0789155960083008, Learning Rate: 0.0005
2022-06-11-17_00_40  Epoch: 18, Training Step: 400, Loss: 1.0933277606964111, Learning Rate: 0.0005
2022-06-11-17_01_07  Epoch: 18, Training Step: 500, Loss: 0.8892877101898193, Learning Rate: 0.0005
2022-06-11-17_01_34  Epoch: 18, Training Step: 600, Loss: 1.0150611400604248, Learning Rate: 0.0005
2022-06-11-17_02_01  Epoch: 18, Training Step: 700, Loss: 1.2712070941925049, Learning Rate: 0.0005
2022-06-11-17_02_28  Epoch: 18, Training Step: 800, Loss: 0.9699919819831848, Learning Rate: 0.0005
2022-06-11-17_02_55  Epoch: 18, Training Step: 900, Loss: 1.6275653839111328, Learning Rate: 0.0005
2022-06-11-17_03_23  Epoch: 18, Training Step: 1000, Loss: 0.980226993560791, Learning Rate: 0.0005
2022-06-11-17_03_50  Epoch: 18, Training Step: 1100, Loss: 1.17983078956604, Learning Rate: 0.0005
2022-06-11-17_04_17  Epoch: 18, Training Step: 1200, Loss: 1.0245625972747803, Learning Rate: 0.0005
2022-06-11-17_04_44  Epoch: 18, Training Step: 1300, Loss: 1.0712435245513916, Learning Rate: 0.0005
2022-06-11-17_05_11  Epoch: 18, Training Step: 1400, Loss: 0.9731164574623108, Learning Rate: 0.0005
2022-06-11-17_05_38  Epoch: 18, Training Step: 1500, Loss: 1.3514699935913086, Learning Rate: 0.0005
2022-06-11-17_06_05  Epoch: 18, Training Step: 1600, Loss: 1.0943360328674316, Learning Rate: 0.0005
2022-06-11-17_06_32  Epoch: 18, Training Step: 1700, Loss: 1.0170714855194092, Learning Rate: 0.0005
2022-06-11-17_06_59  Epoch: 18, Training Step: 1800, Loss: 0.9210675954818726, Learning Rate: 0.0005
2022-06-11-17_07_25  Epoch: 18, Training Step: 1900, Loss: 0.9215133786201477, Learning Rate: 0.0005
2022-06-11-17_07_53  Epoch: 18, Training Step: 2000, Loss: 1.5458853244781494, Learning Rate: 0.0005
2022-06-11-17_08_19  Epoch: 18, Training Step: 2100, Loss: 1.0929828882217407, Learning Rate: 0.0005
2022-06-11-17_08_47  Epoch: 18, Training Step: 2200, Loss: 0.9689260721206665, Learning Rate: 0.0005
2022-06-11-17_09_13  Epoch: 18, Training Step: 2300, Loss: 0.9872651100158691, Learning Rate: 0.0005
2022-06-11-17_09_40  Epoch: 18, Training Step: 2400, Loss: 1.0072596073150635, Learning Rate: 0.0005
2022-06-11-17_10_07  Epoch: 18, Training Step: 2500, Loss: 1.1589759588241577, Learning Rate: 0.0005
2022-06-11-17_10_34  Epoch: 18, Training Step: 2600, Loss: 0.9628284573554993, Learning Rate: 0.0005
2022-06-11-17_11_01  Epoch: 18, Training Step: 2700, Loss: 1.1846179962158203, Learning Rate: 0.0005
2022-06-11-17_11_27  Epoch: 18, Training Step: 2800, Loss: 0.9188827276229858, Learning Rate: 0.0005
2022-06-11-17_11_55  Epoch: 18, Training Step: 2900, Loss: 0.9043879508972168, Learning Rate: 0.0005
2022-06-11-17_12_22  Epoch: 18, Training Step: 3000, Loss: 1.2526633739471436, Learning Rate: 0.0005
2022-06-11-17_12_48  Epoch: 18, Training Step: 3100, Loss: 1.0205609798431396, Learning Rate: 0.0005
2022-06-11-17_13_15  Epoch: 18, Training Step: 3200, Loss: 0.9468791484832764, Learning Rate: 0.0005
2022-06-11-17_16_22  Epoch: 19, Training Step: 0, Loss: 0.7945759892463684, Learning Rate: 0.0005
2022-06-11-17_16_49  Epoch: 19, Training Step: 100, Loss: 0.9097440242767334, Learning Rate: 0.0005
2022-06-11-17_17_16  Epoch: 19, Training Step: 200, Loss: 1.2820713520050049, Learning Rate: 0.0005
2022-06-11-17_17_42  Epoch: 19, Training Step: 300, Loss: 1.1356292963027954, Learning Rate: 0.0005
2022-06-11-17_18_09  Epoch: 19, Training Step: 400, Loss: 0.8955872058868408, Learning Rate: 0.0005
2022-06-11-17_18_37  Epoch: 19, Training Step: 500, Loss: 0.8772515654563904, Learning Rate: 0.0005
2022-06-11-17_19_04  Epoch: 19, Training Step: 600, Loss: 1.4392979145050049, Learning Rate: 0.0005
2022-06-11-17_19_31  Epoch: 19, Training Step: 700, Loss: 1.0193161964416504, Learning Rate: 0.0005
2022-06-11-17_19_58  Epoch: 19, Training Step: 800, Loss: 1.0154471397399902, Learning Rate: 0.0005
2022-06-11-17_20_25  Epoch: 19, Training Step: 900, Loss: 1.0616865158081055, Learning Rate: 0.0005
2022-06-11-17_20_52  Epoch: 19, Training Step: 1000, Loss: 0.8770995140075684, Learning Rate: 0.0005
2022-06-11-17_21_19  Epoch: 19, Training Step: 1100, Loss: 1.1002198457717896, Learning Rate: 0.0005
2022-06-11-17_21_46  Epoch: 19, Training Step: 1200, Loss: 1.0481185913085938, Learning Rate: 0.0005
2022-06-11-17_22_13  Epoch: 19, Training Step: 1300, Loss: 1.194113850593567, Learning Rate: 0.0005
2022-06-11-17_22_40  Epoch: 19, Training Step: 1400, Loss: 1.1951892375946045, Learning Rate: 0.0005
2022-06-11-17_23_07  Epoch: 19, Training Step: 1500, Loss: 1.184515118598938, Learning Rate: 0.0005
2022-06-11-17_23_34  Epoch: 19, Training Step: 1600, Loss: 0.9025834798812866, Learning Rate: 0.0005
2022-06-11-17_24_01  Epoch: 19, Training Step: 1700, Loss: 1.7003405094146729, Learning Rate: 0.0005
2022-06-11-17_24_28  Epoch: 19, Training Step: 1800, Loss: 1.143230676651001, Learning Rate: 0.0005
2022-06-11-17_24_55  Epoch: 19, Training Step: 1900, Loss: 1.0605370998382568, Learning Rate: 0.0005
2022-06-11-17_25_22  Epoch: 19, Training Step: 2000, Loss: 0.8786780834197998, Learning Rate: 0.0005
2022-06-11-17_25_48  Epoch: 19, Training Step: 2100, Loss: 1.0917623043060303, Learning Rate: 0.0005
2022-06-11-17_26_15  Epoch: 19, Training Step: 2200, Loss: 1.1427028179168701, Learning Rate: 0.0005
2022-06-11-17_26_42  Epoch: 19, Training Step: 2300, Loss: 0.9640397429466248, Learning Rate: 0.0005
2022-06-11-17_27_09  Epoch: 19, Training Step: 2400, Loss: 1.1442444324493408, Learning Rate: 0.0005
2022-06-11-17_27_36  Epoch: 19, Training Step: 2500, Loss: 1.0127668380737305, Learning Rate: 0.0005
2022-06-11-17_28_03  Epoch: 19, Training Step: 2600, Loss: 0.9142045974731445, Learning Rate: 0.0005
2022-06-11-17_28_30  Epoch: 19, Training Step: 2700, Loss: 1.0751678943634033, Learning Rate: 0.0005
2022-06-11-17_28_57  Epoch: 19, Training Step: 2800, Loss: 1.000347375869751, Learning Rate: 0.0005
2022-06-11-17_29_24  Epoch: 19, Training Step: 2900, Loss: 1.0758402347564697, Learning Rate: 0.0005
2022-06-11-17_29_51  Epoch: 19, Training Step: 3000, Loss: 1.154860496520996, Learning Rate: 0.0005
2022-06-11-17_30_18  Epoch: 19, Training Step: 3100, Loss: 1.0086051225662231, Learning Rate: 0.0005
2022-06-11-17_30_46  Epoch: 19, Training Step: 3200, Loss: 1.053052544593811, Learning Rate: 0.0005
2022-06-11-17_33_49  Epoch: 20, Training Step: 0, Loss: 0.9345813989639282, Learning Rate: 0.00025
2022-06-11-17_34_16  Epoch: 20, Training Step: 100, Loss: 0.9525861740112305, Learning Rate: 0.00025
2022-06-11-17_34_43  Epoch: 20, Training Step: 200, Loss: 1.1528624296188354, Learning Rate: 0.00025
2022-06-11-17_35_10  Epoch: 20, Training Step: 300, Loss: 1.082244873046875, Learning Rate: 0.00025
2022-06-11-17_35_37  Epoch: 20, Training Step: 400, Loss: 0.9844247102737427, Learning Rate: 0.00025
2022-06-11-17_36_05  Epoch: 20, Training Step: 500, Loss: 1.1950461864471436, Learning Rate: 0.00025
2022-06-11-17_36_32  Epoch: 20, Training Step: 600, Loss: 0.8908789753913879, Learning Rate: 0.00025
2022-06-11-17_36_58  Epoch: 20, Training Step: 700, Loss: 0.9239649772644043, Learning Rate: 0.00025
2022-06-11-17_37_26  Epoch: 20, Training Step: 800, Loss: 0.9359740614891052, Learning Rate: 0.00025
2022-06-11-17_37_53  Epoch: 20, Training Step: 900, Loss: 0.9045329093933105, Learning Rate: 0.00025
2022-06-11-17_38_20  Epoch: 20, Training Step: 1000, Loss: 1.014051914215088, Learning Rate: 0.00025
2022-06-11-17_38_47  Epoch: 20, Training Step: 1100, Loss: 0.9461745023727417, Learning Rate: 0.00025
2022-06-11-17_39_14  Epoch: 20, Training Step: 1200, Loss: 1.0692896842956543, Learning Rate: 0.00025
2022-06-11-17_39_41  Epoch: 20, Training Step: 1300, Loss: 0.9772086143493652, Learning Rate: 0.00025
2022-06-11-17_40_08  Epoch: 20, Training Step: 1400, Loss: 0.984085202217102, Learning Rate: 0.00025
2022-06-11-17_40_36  Epoch: 20, Training Step: 1500, Loss: 1.026557207107544, Learning Rate: 0.00025
2022-06-11-17_41_02  Epoch: 20, Training Step: 1600, Loss: 1.1712117195129395, Learning Rate: 0.00025
2022-06-11-17_41_29  Epoch: 20, Training Step: 1700, Loss: 1.2872921228408813, Learning Rate: 0.00025
2022-06-11-17_41_57  Epoch: 20, Training Step: 1800, Loss: 0.9321684241294861, Learning Rate: 0.00025
2022-06-11-17_42_24  Epoch: 20, Training Step: 1900, Loss: 0.9138909578323364, Learning Rate: 0.00025
2022-06-11-17_42_51  Epoch: 20, Training Step: 2000, Loss: 1.0616540908813477, Learning Rate: 0.00025
2022-06-11-17_43_18  Epoch: 20, Training Step: 2100, Loss: 1.1120816469192505, Learning Rate: 0.00025
2022-06-11-17_43_45  Epoch: 20, Training Step: 2200, Loss: 1.133469820022583, Learning Rate: 0.00025
2022-06-11-17_44_12  Epoch: 20, Training Step: 2300, Loss: 1.0321006774902344, Learning Rate: 0.00025
2022-06-11-17_44_40  Epoch: 20, Training Step: 2400, Loss: 1.1385127305984497, Learning Rate: 0.00025
2022-06-11-17_45_07  Epoch: 20, Training Step: 2500, Loss: 0.872397780418396, Learning Rate: 0.00025
2022-06-11-17_45_34  Epoch: 20, Training Step: 2600, Loss: 0.8945860862731934, Learning Rate: 0.00025
2022-06-11-17_46_01  Epoch: 20, Training Step: 2700, Loss: 1.073378324508667, Learning Rate: 0.00025
2022-06-11-17_46_28  Epoch: 20, Training Step: 2800, Loss: 1.3166817426681519, Learning Rate: 0.00025
2022-06-11-17_46_55  Epoch: 20, Training Step: 2900, Loss: 0.9290545582771301, Learning Rate: 0.00025
2022-06-11-17_47_21  Epoch: 20, Training Step: 3000, Loss: 0.8756380677223206, Learning Rate: 0.00025
2022-06-11-17_47_48  Epoch: 20, Training Step: 3100, Loss: 1.005760669708252, Learning Rate: 0.00025
2022-06-11-17_48_15  Epoch: 20, Training Step: 3200, Loss: 0.8743054270744324, Learning Rate: 0.00025
2022-06-11-17_51_13  Epoch: 21, Training Step: 0, Loss: 1.3005311489105225, Learning Rate: 0.00025
2022-06-11-17_51_41  Epoch: 21, Training Step: 100, Loss: 0.9805651903152466, Learning Rate: 0.00025
2022-06-11-17_52_09  Epoch: 21, Training Step: 200, Loss: 0.9904885292053223, Learning Rate: 0.00025
2022-06-11-17_52_36  Epoch: 21, Training Step: 300, Loss: 1.0280566215515137, Learning Rate: 0.00025
2022-06-11-17_53_03  Epoch: 21, Training Step: 400, Loss: 1.3948554992675781, Learning Rate: 0.00025
2022-06-11-17_53_31  Epoch: 21, Training Step: 500, Loss: 1.0199434757232666, Learning Rate: 0.00025
2022-06-11-17_53_58  Epoch: 21, Training Step: 600, Loss: 0.8186314105987549, Learning Rate: 0.00025
2022-06-11-17_54_26  Epoch: 21, Training Step: 700, Loss: 0.9115383625030518, Learning Rate: 0.00025
2022-06-11-17_54_53  Epoch: 21, Training Step: 800, Loss: 0.8731721639633179, Learning Rate: 0.00025
2022-06-11-17_55_20  Epoch: 21, Training Step: 900, Loss: 0.9929087162017822, Learning Rate: 0.00025
2022-06-11-17_55_48  Epoch: 21, Training Step: 1000, Loss: 0.9013129472732544, Learning Rate: 0.00025
2022-06-11-17_56_14  Epoch: 21, Training Step: 1100, Loss: 0.8828596472740173, Learning Rate: 0.00025
2022-06-11-17_56_41  Epoch: 21, Training Step: 1200, Loss: 0.9695720672607422, Learning Rate: 0.00025
2022-06-11-17_57_08  Epoch: 21, Training Step: 1300, Loss: 1.0758765935897827, Learning Rate: 0.00025
2022-06-11-17_57_35  Epoch: 21, Training Step: 1400, Loss: 0.7239454984664917, Learning Rate: 0.00025
2022-06-11-17_58_01  Epoch: 21, Training Step: 1500, Loss: 0.9100764393806458, Learning Rate: 0.00025
2022-06-11-17_58_28  Epoch: 21, Training Step: 1600, Loss: 0.9745696187019348, Learning Rate: 0.00025
2022-06-11-17_58_55  Epoch: 21, Training Step: 1700, Loss: 0.9328654408454895, Learning Rate: 0.00025
2022-06-11-17_59_23  Epoch: 21, Training Step: 1800, Loss: 0.9017747044563293, Learning Rate: 0.00025
2022-06-11-17_59_50  Epoch: 21, Training Step: 1900, Loss: 0.9708882570266724, Learning Rate: 0.00025
2022-06-11-18_00_17  Epoch: 21, Training Step: 2000, Loss: 1.0016522407531738, Learning Rate: 0.00025
2022-06-11-18_00_44  Epoch: 21, Training Step: 2100, Loss: 0.988453209400177, Learning Rate: 0.00025
2022-06-11-18_01_12  Epoch: 21, Training Step: 2200, Loss: 0.8163861632347107, Learning Rate: 0.00025
2022-06-11-18_01_39  Epoch: 21, Training Step: 2300, Loss: 1.2341840267181396, Learning Rate: 0.00025
2022-06-11-18_02_06  Epoch: 21, Training Step: 2400, Loss: 1.1160469055175781, Learning Rate: 0.00025
2022-06-11-18_02_34  Epoch: 21, Training Step: 2500, Loss: 1.4309735298156738, Learning Rate: 0.00025
2022-06-11-18_03_01  Epoch: 21, Training Step: 2600, Loss: 0.9301249384880066, Learning Rate: 0.00025
2022-06-11-18_03_28  Epoch: 21, Training Step: 2700, Loss: 1.2655917406082153, Learning Rate: 0.00025
2022-06-11-18_03_55  Epoch: 21, Training Step: 2800, Loss: 0.7835489511489868, Learning Rate: 0.00025
2022-06-11-18_04_22  Epoch: 21, Training Step: 2900, Loss: 0.9778629541397095, Learning Rate: 0.00025
2022-06-11-18_04_49  Epoch: 21, Training Step: 3000, Loss: 1.0103299617767334, Learning Rate: 0.00025
2022-06-11-18_05_15  Epoch: 21, Training Step: 3100, Loss: 0.7915757894515991, Learning Rate: 0.00025
2022-06-11-18_05_43  Epoch: 21, Training Step: 3200, Loss: 1.3687223196029663, Learning Rate: 0.00025
2022-06-11-18_08_48  Epoch: 22, Training Step: 0, Loss: 0.7346060276031494, Learning Rate: 0.00025
2022-06-11-18_09_15  Epoch: 22, Training Step: 100, Loss: 0.9699645042419434, Learning Rate: 0.00025
2022-06-11-18_09_42  Epoch: 22, Training Step: 200, Loss: 1.0006285905838013, Learning Rate: 0.00025
2022-06-11-18_10_09  Epoch: 22, Training Step: 300, Loss: 0.8308112025260925, Learning Rate: 0.00025
2022-06-11-18_10_37  Epoch: 22, Training Step: 400, Loss: 1.1768004894256592, Learning Rate: 0.00025
2022-06-11-18_11_04  Epoch: 22, Training Step: 500, Loss: 0.925939679145813, Learning Rate: 0.00025
2022-06-11-18_11_31  Epoch: 22, Training Step: 600, Loss: 0.8490626811981201, Learning Rate: 0.00025
2022-06-11-18_11_59  Epoch: 22, Training Step: 700, Loss: 1.206601858139038, Learning Rate: 0.00025
2022-06-11-18_12_25  Epoch: 22, Training Step: 800, Loss: 0.9693781733512878, Learning Rate: 0.00025
2022-06-11-18_12_51  Epoch: 22, Training Step: 900, Loss: 0.8433037996292114, Learning Rate: 0.00025
2022-06-11-18_13_18  Epoch: 22, Training Step: 1000, Loss: 0.848613977432251, Learning Rate: 0.00025
2022-06-11-18_13_45  Epoch: 22, Training Step: 1100, Loss: 0.9128106832504272, Learning Rate: 0.00025
2022-06-11-18_14_12  Epoch: 22, Training Step: 1200, Loss: 1.1126363277435303, Learning Rate: 0.00025
2022-06-11-18_14_39  Epoch: 22, Training Step: 1300, Loss: 0.7393532991409302, Learning Rate: 0.00025
2022-06-11-18_15_06  Epoch: 22, Training Step: 1400, Loss: 1.016756534576416, Learning Rate: 0.00025
2022-06-11-18_15_33  Epoch: 22, Training Step: 1500, Loss: 0.7724355459213257, Learning Rate: 0.00025
2022-06-11-18_15_59  Epoch: 22, Training Step: 1600, Loss: 0.9212371110916138, Learning Rate: 0.00025
2022-06-11-18_16_26  Epoch: 22, Training Step: 1700, Loss: 1.589282512664795, Learning Rate: 0.00025
2022-06-11-18_16_54  Epoch: 22, Training Step: 1800, Loss: 1.0782960653305054, Learning Rate: 0.00025
2022-06-11-18_17_21  Epoch: 22, Training Step: 1900, Loss: 0.9002927541732788, Learning Rate: 0.00025
2022-06-11-18_17_49  Epoch: 22, Training Step: 2000, Loss: 1.159659504890442, Learning Rate: 0.00025
2022-06-11-18_18_16  Epoch: 22, Training Step: 2100, Loss: 1.3081517219543457, Learning Rate: 0.00025
2022-06-11-18_18_43  Epoch: 22, Training Step: 2200, Loss: 1.1234033107757568, Learning Rate: 0.00025
2022-06-11-18_19_10  Epoch: 22, Training Step: 2300, Loss: 1.0342686176300049, Learning Rate: 0.00025
2022-06-11-18_19_36  Epoch: 22, Training Step: 2400, Loss: 1.0610642433166504, Learning Rate: 0.00025
2022-06-11-18_20_03  Epoch: 22, Training Step: 2500, Loss: 0.8762274980545044, Learning Rate: 0.00025
2022-06-11-18_20_30  Epoch: 22, Training Step: 2600, Loss: 0.9156196117401123, Learning Rate: 0.00025
2022-06-11-18_20_57  Epoch: 22, Training Step: 2700, Loss: 0.9209938645362854, Learning Rate: 0.00025
2022-06-11-18_21_25  Epoch: 22, Training Step: 2800, Loss: 0.9679930806159973, Learning Rate: 0.00025
2022-06-11-18_21_51  Epoch: 22, Training Step: 2900, Loss: 0.999901533126831, Learning Rate: 0.00025
2022-06-11-18_22_18  Epoch: 22, Training Step: 3000, Loss: 1.1107721328735352, Learning Rate: 0.00025
2022-06-11-18_22_45  Epoch: 22, Training Step: 3100, Loss: 0.9407622814178467, Learning Rate: 0.00025
2022-06-11-18_23_12  Epoch: 22, Training Step: 3200, Loss: 1.2099530696868896, Learning Rate: 0.00025
2022-06-11-18_26_14  Epoch: 23, Training Step: 0, Loss: 0.9988101124763489, Learning Rate: 0.00025
2022-06-11-18_26_41  Epoch: 23, Training Step: 100, Loss: 0.9016162753105164, Learning Rate: 0.00025
2022-06-11-18_27_08  Epoch: 23, Training Step: 200, Loss: 0.8077956438064575, Learning Rate: 0.00025
2022-06-11-18_27_36  Epoch: 23, Training Step: 300, Loss: 0.9820177555084229, Learning Rate: 0.00025
2022-06-11-18_28_03  Epoch: 23, Training Step: 400, Loss: 0.97159743309021, Learning Rate: 0.00025
2022-06-11-18_28_31  Epoch: 23, Training Step: 500, Loss: 0.9890820980072021, Learning Rate: 0.00025
2022-06-11-18_28_58  Epoch: 23, Training Step: 600, Loss: 1.280753254890442, Learning Rate: 0.00025
2022-06-11-18_29_25  Epoch: 23, Training Step: 700, Loss: 0.9697909355163574, Learning Rate: 0.00025
2022-06-11-18_29_53  Epoch: 23, Training Step: 800, Loss: 0.9540127515792847, Learning Rate: 0.00025
2022-06-11-18_30_20  Epoch: 23, Training Step: 900, Loss: 0.9297490119934082, Learning Rate: 0.00025
2022-06-11-18_30_47  Epoch: 23, Training Step: 1000, Loss: 0.853931188583374, Learning Rate: 0.00025
2022-06-11-18_31_14  Epoch: 23, Training Step: 1100, Loss: 1.3916454315185547, Learning Rate: 0.00025
2022-06-11-18_31_41  Epoch: 23, Training Step: 1200, Loss: 0.9835955500602722, Learning Rate: 0.00025
2022-06-11-18_32_08  Epoch: 23, Training Step: 1300, Loss: 1.080772876739502, Learning Rate: 0.00025
2022-06-11-18_32_35  Epoch: 23, Training Step: 1400, Loss: 0.7930363416671753, Learning Rate: 0.00025
2022-06-11-18_33_02  Epoch: 23, Training Step: 1500, Loss: 0.89519202709198, Learning Rate: 0.00025
2022-06-11-18_33_29  Epoch: 23, Training Step: 1600, Loss: 0.9146289825439453, Learning Rate: 0.00025
2022-06-11-18_33_56  Epoch: 23, Training Step: 1700, Loss: 1.3485944271087646, Learning Rate: 0.00025
2022-06-11-18_34_23  Epoch: 23, Training Step: 1800, Loss: 0.8116648197174072, Learning Rate: 0.00025
2022-06-11-18_34_51  Epoch: 23, Training Step: 1900, Loss: 1.0813325643539429, Learning Rate: 0.00025
2022-06-11-18_35_18  Epoch: 23, Training Step: 2000, Loss: 1.0407943725585938, Learning Rate: 0.00025
2022-06-11-18_35_44  Epoch: 23, Training Step: 2100, Loss: 0.9415706396102905, Learning Rate: 0.00025
2022-06-11-18_36_12  Epoch: 23, Training Step: 2200, Loss: 0.760160505771637, Learning Rate: 0.00025
2022-06-11-18_36_39  Epoch: 23, Training Step: 2300, Loss: 0.898127555847168, Learning Rate: 0.00025
2022-06-11-18_37_06  Epoch: 23, Training Step: 2400, Loss: 1.0596888065338135, Learning Rate: 0.00025
2022-06-11-18_37_33  Epoch: 23, Training Step: 2500, Loss: 1.3871512413024902, Learning Rate: 0.00025
2022-06-11-18_38_00  Epoch: 23, Training Step: 2600, Loss: 0.9244734644889832, Learning Rate: 0.00025
2022-06-11-18_38_27  Epoch: 23, Training Step: 2700, Loss: 0.8486628532409668, Learning Rate: 0.00025
2022-06-11-18_38_54  Epoch: 23, Training Step: 2800, Loss: 0.7536532878875732, Learning Rate: 0.00025
2022-06-11-18_39_21  Epoch: 23, Training Step: 2900, Loss: 0.9243487119674683, Learning Rate: 0.00025
2022-06-11-18_39_48  Epoch: 23, Training Step: 3000, Loss: 0.9517555236816406, Learning Rate: 0.00025
2022-06-11-18_40_15  Epoch: 23, Training Step: 3100, Loss: 0.8823007345199585, Learning Rate: 0.00025
2022-06-11-18_40_41  Epoch: 23, Training Step: 3200, Loss: 0.9565399289131165, Learning Rate: 0.00025
2022-06-11-18_43_41  Epoch: 24, Training Step: 0, Loss: 0.9549180865287781, Learning Rate: 0.00025
2022-06-11-18_44_08  Epoch: 24, Training Step: 100, Loss: 0.9744919538497925, Learning Rate: 0.00025
2022-06-11-18_44_36  Epoch: 24, Training Step: 200, Loss: 0.9317215085029602, Learning Rate: 0.00025
2022-06-11-18_45_03  Epoch: 24, Training Step: 300, Loss: 0.9951742887496948, Learning Rate: 0.00025
2022-06-11-18_45_30  Epoch: 24, Training Step: 400, Loss: 0.901938796043396, Learning Rate: 0.00025
2022-06-11-18_45_57  Epoch: 24, Training Step: 500, Loss: 0.8919981122016907, Learning Rate: 0.00025
2022-06-11-18_46_24  Epoch: 24, Training Step: 600, Loss: 0.9357828497886658, Learning Rate: 0.00025
2022-06-11-18_46_51  Epoch: 24, Training Step: 700, Loss: 0.9503477215766907, Learning Rate: 0.00025
2022-06-11-18_47_18  Epoch: 24, Training Step: 800, Loss: 0.879065752029419, Learning Rate: 0.00025
2022-06-11-18_47_46  Epoch: 24, Training Step: 900, Loss: 1.1344923973083496, Learning Rate: 0.00025
2022-06-11-18_48_13  Epoch: 24, Training Step: 1000, Loss: 1.0157599449157715, Learning Rate: 0.00025
2022-06-11-18_48_40  Epoch: 24, Training Step: 1100, Loss: 1.020493984222412, Learning Rate: 0.00025
2022-06-11-18_49_07  Epoch: 24, Training Step: 1200, Loss: 0.8946858644485474, Learning Rate: 0.00025
2022-06-11-18_49_34  Epoch: 24, Training Step: 1300, Loss: 1.0760942697525024, Learning Rate: 0.00025
2022-06-11-18_50_01  Epoch: 24, Training Step: 1400, Loss: 0.9997231960296631, Learning Rate: 0.00025
2022-06-11-18_50_28  Epoch: 24, Training Step: 1500, Loss: 0.9258443117141724, Learning Rate: 0.00025
2022-06-11-18_50_56  Epoch: 24, Training Step: 1600, Loss: 0.8319621682167053, Learning Rate: 0.00025
2022-06-11-18_51_23  Epoch: 24, Training Step: 1700, Loss: 0.8927501440048218, Learning Rate: 0.00025
2022-06-11-18_51_51  Epoch: 24, Training Step: 1800, Loss: 1.5313189029693604, Learning Rate: 0.00025
2022-06-11-18_52_17  Epoch: 24, Training Step: 1900, Loss: 0.9931049346923828, Learning Rate: 0.00025
2022-06-11-18_52_45  Epoch: 24, Training Step: 2000, Loss: 0.9244735240936279, Learning Rate: 0.00025
2022-06-11-18_53_12  Epoch: 24, Training Step: 2100, Loss: 0.8658232092857361, Learning Rate: 0.00025
2022-06-11-18_53_38  Epoch: 24, Training Step: 2200, Loss: 0.8367720246315002, Learning Rate: 0.00025
2022-06-11-18_54_05  Epoch: 24, Training Step: 2300, Loss: 0.7599195837974548, Learning Rate: 0.00025
2022-06-11-18_54_33  Epoch: 24, Training Step: 2400, Loss: 0.8145314455032349, Learning Rate: 0.00025
2022-06-11-18_54_59  Epoch: 24, Training Step: 2500, Loss: 0.9110699892044067, Learning Rate: 0.00025
2022-06-11-18_55_26  Epoch: 24, Training Step: 2600, Loss: 0.993023157119751, Learning Rate: 0.00025
2022-06-11-18_55_52  Epoch: 24, Training Step: 2700, Loss: 1.0913374423980713, Learning Rate: 0.00025
2022-06-11-18_56_19  Epoch: 24, Training Step: 2800, Loss: 0.9073799848556519, Learning Rate: 0.00025
2022-06-11-18_56_47  Epoch: 24, Training Step: 2900, Loss: 1.1290849447250366, Learning Rate: 0.00025
2022-06-11-18_57_15  Epoch: 24, Training Step: 3000, Loss: 0.901308000087738, Learning Rate: 0.00025
2022-06-11-18_57_41  Epoch: 24, Training Step: 3100, Loss: 0.9968143105506897, Learning Rate: 0.00025
2022-06-11-18_58_08  Epoch: 24, Training Step: 3200, Loss: 0.9162509441375732, Learning Rate: 0.00025
2022-06-11-19_01_09  Epoch: 25, Training Step: 0, Loss: 0.862675666809082, Learning Rate: 0.00025
2022-06-11-19_01_36  Epoch: 25, Training Step: 100, Loss: 0.9601795673370361, Learning Rate: 0.00025
2022-06-11-19_02_03  Epoch: 25, Training Step: 200, Loss: 0.7686642408370972, Learning Rate: 0.00025
2022-06-11-19_02_30  Epoch: 25, Training Step: 300, Loss: 0.9620267748832703, Learning Rate: 0.00025
2022-06-11-19_02_57  Epoch: 25, Training Step: 400, Loss: 1.060594916343689, Learning Rate: 0.00025
2022-06-11-19_03_24  Epoch: 25, Training Step: 500, Loss: 0.873223066329956, Learning Rate: 0.00025
2022-06-11-19_03_52  Epoch: 25, Training Step: 600, Loss: 0.9481650590896606, Learning Rate: 0.00025
2022-06-11-19_04_19  Epoch: 25, Training Step: 700, Loss: 0.9125058650970459, Learning Rate: 0.00025
2022-06-11-19_04_45  Epoch: 25, Training Step: 800, Loss: 0.8757778406143188, Learning Rate: 0.00025
2022-06-11-19_05_12  Epoch: 25, Training Step: 900, Loss: 0.862925112247467, Learning Rate: 0.00025
2022-06-11-19_05_39  Epoch: 25, Training Step: 1000, Loss: 0.9851460456848145, Learning Rate: 0.00025
2022-06-11-19_06_06  Epoch: 25, Training Step: 1100, Loss: 0.8122467994689941, Learning Rate: 0.00025
2022-06-11-19_06_34  Epoch: 25, Training Step: 1200, Loss: 0.8878682851791382, Learning Rate: 0.00025
2022-06-11-19_07_01  Epoch: 25, Training Step: 1300, Loss: 1.3267402648925781, Learning Rate: 0.00025
2022-06-11-19_07_28  Epoch: 25, Training Step: 1400, Loss: 0.9356541633605957, Learning Rate: 0.00025
2022-06-11-19_07_55  Epoch: 25, Training Step: 1500, Loss: 0.8956243991851807, Learning Rate: 0.00025
2022-06-11-19_08_22  Epoch: 25, Training Step: 1600, Loss: 1.17634916305542, Learning Rate: 0.00025
2022-06-11-19_08_49  Epoch: 25, Training Step: 1700, Loss: 1.2450155019760132, Learning Rate: 0.00025
2022-06-11-19_09_16  Epoch: 25, Training Step: 1800, Loss: 0.9086157083511353, Learning Rate: 0.00025
2022-06-11-19_09_43  Epoch: 25, Training Step: 1900, Loss: 0.8727829456329346, Learning Rate: 0.00025
2022-06-11-19_10_09  Epoch: 25, Training Step: 2000, Loss: 1.159909725189209, Learning Rate: 0.00025
2022-06-11-19_10_35  Epoch: 25, Training Step: 2100, Loss: 0.8612064719200134, Learning Rate: 0.00025
2022-06-11-19_11_02  Epoch: 25, Training Step: 2200, Loss: 0.9742562770843506, Learning Rate: 0.00025
2022-06-11-19_11_29  Epoch: 25, Training Step: 2300, Loss: 0.9404335021972656, Learning Rate: 0.00025
2022-06-11-19_11_56  Epoch: 25, Training Step: 2400, Loss: 1.0221694707870483, Learning Rate: 0.00025
2022-06-11-19_12_23  Epoch: 25, Training Step: 2500, Loss: 0.8390865921974182, Learning Rate: 0.00025
2022-06-11-19_12_50  Epoch: 25, Training Step: 2600, Loss: 0.9982247352600098, Learning Rate: 0.00025
2022-06-11-19_13_18  Epoch: 25, Training Step: 2700, Loss: 0.9944661855697632, Learning Rate: 0.00025
2022-06-11-19_13_45  Epoch: 25, Training Step: 2800, Loss: 0.9044969081878662, Learning Rate: 0.00025
2022-06-11-19_14_12  Epoch: 25, Training Step: 2900, Loss: 1.0249830484390259, Learning Rate: 0.00025
2022-06-11-19_14_39  Epoch: 25, Training Step: 3000, Loss: 0.9435646533966064, Learning Rate: 0.00025
2022-06-11-19_15_06  Epoch: 25, Training Step: 3100, Loss: 1.1983270645141602, Learning Rate: 0.00025
2022-06-11-19_15_33  Epoch: 25, Training Step: 3200, Loss: 0.8424021005630493, Learning Rate: 0.00025
2022-06-11-19_18_32  Epoch: 26, Training Step: 0, Loss: 0.7389034628868103, Learning Rate: 0.00025
2022-06-11-19_19_00  Epoch: 26, Training Step: 100, Loss: 0.8223761320114136, Learning Rate: 0.00025
2022-06-11-19_19_27  Epoch: 26, Training Step: 200, Loss: 0.9777522087097168, Learning Rate: 0.00025
2022-06-11-19_19_54  Epoch: 26, Training Step: 300, Loss: 0.8856748938560486, Learning Rate: 0.00025
2022-06-11-19_20_21  Epoch: 26, Training Step: 400, Loss: 0.9192643165588379, Learning Rate: 0.00025
2022-06-11-19_20_48  Epoch: 26, Training Step: 500, Loss: 0.8550344109535217, Learning Rate: 0.00025
2022-06-11-19_21_15  Epoch: 26, Training Step: 600, Loss: 0.8703646659851074, Learning Rate: 0.00025
2022-06-11-19_21_42  Epoch: 26, Training Step: 700, Loss: 0.9329502582550049, Learning Rate: 0.00025
2022-06-11-19_22_09  Epoch: 26, Training Step: 800, Loss: 0.8506279587745667, Learning Rate: 0.00025
2022-06-11-19_22_36  Epoch: 26, Training Step: 900, Loss: 1.0066531896591187, Learning Rate: 0.00025
2022-06-11-19_23_03  Epoch: 26, Training Step: 1000, Loss: 0.8358492851257324, Learning Rate: 0.00025
2022-06-11-19_23_30  Epoch: 26, Training Step: 1100, Loss: 0.8848425149917603, Learning Rate: 0.00025
2022-06-11-19_23_57  Epoch: 26, Training Step: 1200, Loss: 1.0124443769454956, Learning Rate: 0.00025
2022-06-11-19_24_25  Epoch: 26, Training Step: 1300, Loss: 1.0561161041259766, Learning Rate: 0.00025
2022-06-11-19_24_52  Epoch: 26, Training Step: 1400, Loss: 1.1348457336425781, Learning Rate: 0.00025
2022-06-11-19_25_19  Epoch: 26, Training Step: 1500, Loss: 0.8297845125198364, Learning Rate: 0.00025
2022-06-11-19_25_46  Epoch: 26, Training Step: 1600, Loss: 0.9890791177749634, Learning Rate: 0.00025
2022-06-11-19_26_13  Epoch: 26, Training Step: 1700, Loss: 0.8650026321411133, Learning Rate: 0.00025
2022-06-11-19_26_40  Epoch: 26, Training Step: 1800, Loss: 1.062695860862732, Learning Rate: 0.00025
2022-06-11-19_27_06  Epoch: 26, Training Step: 1900, Loss: 0.9091081619262695, Learning Rate: 0.00025
2022-06-11-19_27_33  Epoch: 26, Training Step: 2000, Loss: 1.156977891921997, Learning Rate: 0.00025
2022-06-11-19_28_00  Epoch: 26, Training Step: 2100, Loss: 0.9876797795295715, Learning Rate: 0.00025
2022-06-11-19_28_27  Epoch: 26, Training Step: 2200, Loss: 0.8394131064414978, Learning Rate: 0.00025
2022-06-11-19_28_54  Epoch: 26, Training Step: 2300, Loss: 0.9067733287811279, Learning Rate: 0.00025
2022-06-11-19_29_21  Epoch: 26, Training Step: 2400, Loss: 0.8008846044540405, Learning Rate: 0.00025
2022-06-11-19_29_48  Epoch: 26, Training Step: 2500, Loss: 0.8905937671661377, Learning Rate: 0.00025
2022-06-11-19_30_14  Epoch: 26, Training Step: 2600, Loss: 1.1771560907363892, Learning Rate: 0.00025
2022-06-11-19_30_41  Epoch: 26, Training Step: 2700, Loss: 0.8355034589767456, Learning Rate: 0.00025
2022-06-11-19_31_07  Epoch: 26, Training Step: 2800, Loss: 0.8669276237487793, Learning Rate: 0.00025
2022-06-11-19_31_35  Epoch: 26, Training Step: 2900, Loss: 1.108419418334961, Learning Rate: 0.00025
2022-06-11-19_32_01  Epoch: 26, Training Step: 3000, Loss: 0.7543034553527832, Learning Rate: 0.00025
2022-06-11-19_32_28  Epoch: 26, Training Step: 3100, Loss: 1.0014594793319702, Learning Rate: 0.00025
2022-06-11-19_32_55  Epoch: 26, Training Step: 3200, Loss: 0.8599255084991455, Learning Rate: 0.00025
2022-06-11-19_35_58  Epoch: 27, Training Step: 0, Loss: 1.025149941444397, Learning Rate: 0.00025
2022-06-11-19_36_25  Epoch: 27, Training Step: 100, Loss: 1.1495221853256226, Learning Rate: 0.00025
2022-06-11-19_36_52  Epoch: 27, Training Step: 200, Loss: 0.8278506994247437, Learning Rate: 0.00025
2022-06-11-19_37_20  Epoch: 27, Training Step: 300, Loss: 1.2536051273345947, Learning Rate: 0.00025
2022-06-11-19_37_48  Epoch: 27, Training Step: 400, Loss: 1.194040060043335, Learning Rate: 0.00025
2022-06-11-19_38_15  Epoch: 27, Training Step: 500, Loss: 0.8502441048622131, Learning Rate: 0.00025
2022-06-11-19_38_42  Epoch: 27, Training Step: 600, Loss: 1.0856084823608398, Learning Rate: 0.00025
2022-06-11-19_39_09  Epoch: 27, Training Step: 700, Loss: 0.9652798175811768, Learning Rate: 0.00025
2022-06-11-19_39_36  Epoch: 27, Training Step: 800, Loss: 1.0870554447174072, Learning Rate: 0.00025
2022-06-11-19_40_04  Epoch: 27, Training Step: 900, Loss: 0.7685470581054688, Learning Rate: 0.00025
2022-06-11-19_40_31  Epoch: 27, Training Step: 1000, Loss: 0.9074989557266235, Learning Rate: 0.00025
2022-06-11-19_40_58  Epoch: 27, Training Step: 1100, Loss: 0.9970541000366211, Learning Rate: 0.00025
2022-06-11-19_41_24  Epoch: 27, Training Step: 1200, Loss: 1.0681123733520508, Learning Rate: 0.00025
2022-06-11-19_41_51  Epoch: 27, Training Step: 1300, Loss: 1.0736454725265503, Learning Rate: 0.00025
2022-06-11-19_42_18  Epoch: 27, Training Step: 1400, Loss: 1.0968352556228638, Learning Rate: 0.00025
2022-06-11-19_42_45  Epoch: 27, Training Step: 1500, Loss: 0.7945334911346436, Learning Rate: 0.00025
2022-06-11-19_43_12  Epoch: 27, Training Step: 1600, Loss: 1.2760999202728271, Learning Rate: 0.00025
2022-06-11-19_43_39  Epoch: 27, Training Step: 1700, Loss: 0.8298996686935425, Learning Rate: 0.00025
2022-06-11-19_44_06  Epoch: 27, Training Step: 1800, Loss: 0.95982825756073, Learning Rate: 0.00025
2022-06-11-19_44_33  Epoch: 27, Training Step: 1900, Loss: 0.9472727179527283, Learning Rate: 0.00025
2022-06-11-19_44_59  Epoch: 27, Training Step: 2000, Loss: 0.8937520384788513, Learning Rate: 0.00025
2022-06-11-19_45_26  Epoch: 27, Training Step: 2100, Loss: 0.9896981716156006, Learning Rate: 0.00025
2022-06-11-19_45_53  Epoch: 27, Training Step: 2200, Loss: 0.9471180438995361, Learning Rate: 0.00025
2022-06-11-19_46_19  Epoch: 27, Training Step: 2300, Loss: 0.9264287948608398, Learning Rate: 0.00025
2022-06-11-19_46_46  Epoch: 27, Training Step: 2400, Loss: 0.8690487146377563, Learning Rate: 0.00025
2022-06-11-19_47_13  Epoch: 27, Training Step: 2500, Loss: 0.8480191230773926, Learning Rate: 0.00025
2022-06-11-19_47_40  Epoch: 27, Training Step: 2600, Loss: 0.9329455494880676, Learning Rate: 0.00025
2022-06-11-19_48_07  Epoch: 27, Training Step: 2700, Loss: 0.8435046672821045, Learning Rate: 0.00025
2022-06-11-19_48_33  Epoch: 27, Training Step: 2800, Loss: 0.90038001537323, Learning Rate: 0.00025
2022-06-11-19_49_00  Epoch: 27, Training Step: 2900, Loss: 0.8396531939506531, Learning Rate: 0.00025
2022-06-11-19_49_27  Epoch: 27, Training Step: 3000, Loss: 0.9591464996337891, Learning Rate: 0.00025
2022-06-11-19_49_54  Epoch: 27, Training Step: 3100, Loss: 0.9433832168579102, Learning Rate: 0.00025
2022-06-11-19_50_21  Epoch: 27, Training Step: 3200, Loss: 1.0212254524230957, Learning Rate: 0.00025
2022-06-11-19_53_24  Epoch: 28, Training Step: 0, Loss: 0.8780732154846191, Learning Rate: 0.00025
2022-06-11-19_53_51  Epoch: 28, Training Step: 100, Loss: 0.8807330131530762, Learning Rate: 0.00025
2022-06-11-19_54_18  Epoch: 28, Training Step: 200, Loss: 0.8360706567764282, Learning Rate: 0.00025
2022-06-11-19_54_44  Epoch: 28, Training Step: 300, Loss: 0.9520106911659241, Learning Rate: 0.00025
2022-06-11-19_55_11  Epoch: 28, Training Step: 400, Loss: 0.9693423509597778, Learning Rate: 0.00025
2022-06-11-19_55_38  Epoch: 28, Training Step: 500, Loss: 0.9175353050231934, Learning Rate: 0.00025
2022-06-11-19_56_05  Epoch: 28, Training Step: 600, Loss: 0.7433186173439026, Learning Rate: 0.00025
2022-06-11-19_56_32  Epoch: 28, Training Step: 700, Loss: 1.1144444942474365, Learning Rate: 0.00025
2022-06-11-19_57_00  Epoch: 28, Training Step: 800, Loss: 0.8785755634307861, Learning Rate: 0.00025
2022-06-11-19_57_27  Epoch: 28, Training Step: 900, Loss: 0.8857266306877136, Learning Rate: 0.00025
2022-06-11-19_57_54  Epoch: 28, Training Step: 1000, Loss: 1.0420461893081665, Learning Rate: 0.00025
2022-06-11-19_58_22  Epoch: 28, Training Step: 1100, Loss: 0.9731950759887695, Learning Rate: 0.00025
2022-06-11-19_58_49  Epoch: 28, Training Step: 1200, Loss: 0.98939049243927, Learning Rate: 0.00025
2022-06-11-19_59_16  Epoch: 28, Training Step: 1300, Loss: 0.854816734790802, Learning Rate: 0.00025
2022-06-11-19_59_42  Epoch: 28, Training Step: 1400, Loss: 0.972298800945282, Learning Rate: 0.00025
2022-06-11-20_00_09  Epoch: 28, Training Step: 1500, Loss: 0.9461076855659485, Learning Rate: 0.00025
2022-06-11-20_00_36  Epoch: 28, Training Step: 1600, Loss: 0.888363242149353, Learning Rate: 0.00025
2022-06-11-20_01_03  Epoch: 28, Training Step: 1700, Loss: 0.9599910974502563, Learning Rate: 0.00025
2022-06-11-20_01_30  Epoch: 28, Training Step: 1800, Loss: 0.8396291136741638, Learning Rate: 0.00025
2022-06-11-20_01_56  Epoch: 28, Training Step: 1900, Loss: 1.1883901357650757, Learning Rate: 0.00025
2022-06-11-20_02_23  Epoch: 28, Training Step: 2000, Loss: 0.9094724655151367, Learning Rate: 0.00025
2022-06-11-20_02_50  Epoch: 28, Training Step: 2100, Loss: 0.9536718130111694, Learning Rate: 0.00025
2022-06-11-20_03_17  Epoch: 28, Training Step: 2200, Loss: 1.214015007019043, Learning Rate: 0.00025
2022-06-11-20_03_44  Epoch: 28, Training Step: 2300, Loss: 0.8233423233032227, Learning Rate: 0.00025
2022-06-11-20_04_11  Epoch: 28, Training Step: 2400, Loss: 0.8906610608100891, Learning Rate: 0.00025
2022-06-11-20_04_38  Epoch: 28, Training Step: 2500, Loss: 1.1354520320892334, Learning Rate: 0.00025
2022-06-11-20_05_05  Epoch: 28, Training Step: 2600, Loss: 0.9407401084899902, Learning Rate: 0.00025
2022-06-11-20_05_32  Epoch: 28, Training Step: 2700, Loss: 0.9746192693710327, Learning Rate: 0.00025
2022-06-11-20_05_58  Epoch: 28, Training Step: 2800, Loss: 0.7722938656806946, Learning Rate: 0.00025
2022-06-11-20_06_25  Epoch: 28, Training Step: 2900, Loss: 0.7859436869621277, Learning Rate: 0.00025
2022-06-11-20_06_52  Epoch: 28, Training Step: 3000, Loss: 0.8162869811058044, Learning Rate: 0.00025
2022-06-11-20_07_19  Epoch: 28, Training Step: 3100, Loss: 0.8478895425796509, Learning Rate: 0.00025
2022-06-11-20_07_46  Epoch: 28, Training Step: 3200, Loss: 0.9541570544242859, Learning Rate: 0.00025
2022-06-11-20_10_48  Epoch: 29, Training Step: 0, Loss: 1.1435452699661255, Learning Rate: 0.00025
2022-06-11-20_11_15  Epoch: 29, Training Step: 100, Loss: 1.0960681438446045, Learning Rate: 0.00025
2022-06-11-20_11_42  Epoch: 29, Training Step: 200, Loss: 0.9295014142990112, Learning Rate: 0.00025
2022-06-11-20_12_09  Epoch: 29, Training Step: 300, Loss: 1.0059412717819214, Learning Rate: 0.00025
2022-06-11-20_12_37  Epoch: 29, Training Step: 400, Loss: 1.1906177997589111, Learning Rate: 0.00025
2022-06-11-20_13_04  Epoch: 29, Training Step: 500, Loss: 0.903793215751648, Learning Rate: 0.00025
2022-06-11-20_13_31  Epoch: 29, Training Step: 600, Loss: 0.8773871660232544, Learning Rate: 0.00025
2022-06-11-20_13_57  Epoch: 29, Training Step: 700, Loss: 1.1942505836486816, Learning Rate: 0.00025
2022-06-11-20_14_24  Epoch: 29, Training Step: 800, Loss: 0.798445463180542, Learning Rate: 0.00025
2022-06-11-20_14_51  Epoch: 29, Training Step: 900, Loss: 0.9147088527679443, Learning Rate: 0.00025
2022-06-11-20_15_18  Epoch: 29, Training Step: 1000, Loss: 1.0032382011413574, Learning Rate: 0.00025
2022-06-11-20_15_45  Epoch: 29, Training Step: 1100, Loss: 0.8207402229309082, Learning Rate: 0.00025
2022-06-11-20_16_12  Epoch: 29, Training Step: 1200, Loss: 0.9540300369262695, Learning Rate: 0.00025
2022-06-11-20_16_39  Epoch: 29, Training Step: 1300, Loss: 1.075345516204834, Learning Rate: 0.00025
2022-06-11-20_17_06  Epoch: 29, Training Step: 1400, Loss: 0.9030152559280396, Learning Rate: 0.00025
2022-06-11-20_17_33  Epoch: 29, Training Step: 1500, Loss: 0.8813462853431702, Learning Rate: 0.00025
2022-06-11-20_18_00  Epoch: 29, Training Step: 1600, Loss: 0.9787764549255371, Learning Rate: 0.00025
2022-06-11-20_18_27  Epoch: 29, Training Step: 1700, Loss: 1.1170506477355957, Learning Rate: 0.00025
2022-06-11-20_18_55  Epoch: 29, Training Step: 1800, Loss: 1.1774587631225586, Learning Rate: 0.00025
2022-06-11-20_19_21  Epoch: 29, Training Step: 1900, Loss: 0.9728193283081055, Learning Rate: 0.00025
2022-06-11-20_19_48  Epoch: 29, Training Step: 2000, Loss: 0.9765400886535645, Learning Rate: 0.00025
2022-06-11-20_20_15  Epoch: 29, Training Step: 2100, Loss: 0.7992860078811646, Learning Rate: 0.00025
2022-06-11-20_20_42  Epoch: 29, Training Step: 2200, Loss: 0.910498321056366, Learning Rate: 0.00025
2022-06-11-20_21_09  Epoch: 29, Training Step: 2300, Loss: 1.046818494796753, Learning Rate: 0.00025
2022-06-11-20_21_36  Epoch: 29, Training Step: 2400, Loss: 0.9611718058586121, Learning Rate: 0.00025
2022-06-11-20_22_03  Epoch: 29, Training Step: 2500, Loss: 1.0115116834640503, Learning Rate: 0.00025
2022-06-11-20_22_30  Epoch: 29, Training Step: 2600, Loss: 0.8682632446289062, Learning Rate: 0.00025
2022-06-11-20_22_57  Epoch: 29, Training Step: 2700, Loss: 0.9120146036148071, Learning Rate: 0.00025
2022-06-11-20_23_24  Epoch: 29, Training Step: 2800, Loss: 0.8389914035797119, Learning Rate: 0.00025
2022-06-11-20_23_50  Epoch: 29, Training Step: 2900, Loss: 0.9246135950088501, Learning Rate: 0.00025
2022-06-11-20_24_17  Epoch: 29, Training Step: 3000, Loss: 0.8297016620635986, Learning Rate: 0.00025
2022-06-11-20_24_44  Epoch: 29, Training Step: 3100, Loss: 0.7607934474945068, Learning Rate: 0.00025
2022-06-11-20_25_11  Epoch: 29, Training Step: 3200, Loss: 0.9373234510421753, Learning Rate: 0.00025
2022-06-11-20_28_12  Epoch: 30, Training Step: 0, Loss: 1.0089380741119385, Learning Rate: 0.000125
2022-06-11-20_28_39  Epoch: 30, Training Step: 100, Loss: 0.9063102006912231, Learning Rate: 0.000125
2022-06-11-20_29_06  Epoch: 30, Training Step: 200, Loss: 1.0924690961837769, Learning Rate: 0.000125
2022-06-11-20_29_33  Epoch: 30, Training Step: 300, Loss: 1.292679786682129, Learning Rate: 0.000125
2022-06-11-20_30_00  Epoch: 30, Training Step: 400, Loss: 0.9633914828300476, Learning Rate: 0.000125
2022-06-11-20_30_27  Epoch: 30, Training Step: 500, Loss: 0.951327919960022, Learning Rate: 0.000125
2022-06-11-20_30_54  Epoch: 30, Training Step: 600, Loss: 0.8349587917327881, Learning Rate: 0.000125
2022-06-11-20_31_21  Epoch: 30, Training Step: 700, Loss: 1.022747278213501, Learning Rate: 0.000125
2022-06-11-20_31_48  Epoch: 30, Training Step: 800, Loss: 0.7789938449859619, Learning Rate: 0.000125
2022-06-11-20_32_14  Epoch: 30, Training Step: 900, Loss: 1.0282316207885742, Learning Rate: 0.000125
2022-06-11-20_32_41  Epoch: 30, Training Step: 1000, Loss: 0.795874834060669, Learning Rate: 0.000125
2022-06-11-20_33_09  Epoch: 30, Training Step: 1100, Loss: 0.8936898708343506, Learning Rate: 0.000125
2022-06-11-20_33_35  Epoch: 30, Training Step: 1200, Loss: 0.9149688482284546, Learning Rate: 0.000125
2022-06-11-20_34_02  Epoch: 30, Training Step: 1300, Loss: 0.8351978063583374, Learning Rate: 0.000125
2022-06-11-20_34_29  Epoch: 30, Training Step: 1400, Loss: 0.985630452632904, Learning Rate: 0.000125
2022-06-11-20_34_56  Epoch: 30, Training Step: 1500, Loss: 0.9248990416526794, Learning Rate: 0.000125
2022-06-11-20_35_23  Epoch: 30, Training Step: 1600, Loss: 1.1353769302368164, Learning Rate: 0.000125
2022-06-11-20_35_50  Epoch: 30, Training Step: 1700, Loss: 1.2592747211456299, Learning Rate: 0.000125
2022-06-11-20_36_17  Epoch: 30, Training Step: 1800, Loss: 1.0650420188903809, Learning Rate: 0.000125
2022-06-11-20_36_44  Epoch: 30, Training Step: 1900, Loss: 0.9049177169799805, Learning Rate: 0.000125
2022-06-11-20_37_11  Epoch: 30, Training Step: 2000, Loss: 0.7934025526046753, Learning Rate: 0.000125
2022-06-11-20_37_37  Epoch: 30, Training Step: 2100, Loss: 0.9250368475914001, Learning Rate: 0.000125
2022-06-11-20_38_05  Epoch: 30, Training Step: 2200, Loss: 0.9602797031402588, Learning Rate: 0.000125
2022-06-11-20_38_31  Epoch: 30, Training Step: 2300, Loss: 0.9438354969024658, Learning Rate: 0.000125
2022-06-11-20_38_58  Epoch: 30, Training Step: 2400, Loss: 1.1423746347427368, Learning Rate: 0.000125
2022-06-11-20_39_26  Epoch: 30, Training Step: 2500, Loss: 0.7625436782836914, Learning Rate: 0.000125
2022-06-11-20_39_52  Epoch: 30, Training Step: 2600, Loss: 0.8983653783798218, Learning Rate: 0.000125
2022-06-11-20_40_19  Epoch: 30, Training Step: 2700, Loss: 0.91134113073349, Learning Rate: 0.000125
2022-06-11-20_40_46  Epoch: 30, Training Step: 2800, Loss: 0.9809200167655945, Learning Rate: 0.000125
2022-06-11-20_41_12  Epoch: 30, Training Step: 2900, Loss: 0.9574508666992188, Learning Rate: 0.000125
2022-06-11-20_41_39  Epoch: 30, Training Step: 3000, Loss: 0.8535436391830444, Learning Rate: 0.000125
2022-06-11-20_42_06  Epoch: 30, Training Step: 3100, Loss: 1.0011953115463257, Learning Rate: 0.000125
2022-06-11-20_42_32  Epoch: 30, Training Step: 3200, Loss: 1.1276286840438843, Learning Rate: 0.000125
2022-06-11-20_45_30  Epoch: 31, Training Step: 0, Loss: 0.852196216583252, Learning Rate: 0.000125
2022-06-11-20_45_57  Epoch: 31, Training Step: 100, Loss: 0.8983737230300903, Learning Rate: 0.000125
2022-06-11-20_46_24  Epoch: 31, Training Step: 200, Loss: 0.8708558082580566, Learning Rate: 0.000125
2022-06-11-20_46_51  Epoch: 31, Training Step: 300, Loss: 1.0040031671524048, Learning Rate: 0.000125
2022-06-11-20_47_17  Epoch: 31, Training Step: 400, Loss: 0.9753713011741638, Learning Rate: 0.000125
2022-06-11-20_47_44  Epoch: 31, Training Step: 500, Loss: 0.8344316482543945, Learning Rate: 0.000125
2022-06-11-20_48_10  Epoch: 31, Training Step: 600, Loss: 1.0117024183273315, Learning Rate: 0.000125
2022-06-11-20_48_37  Epoch: 31, Training Step: 700, Loss: 0.8631255626678467, Learning Rate: 0.000125
2022-06-11-20_49_04  Epoch: 31, Training Step: 800, Loss: 0.92943274974823, Learning Rate: 0.000125
2022-06-11-20_49_31  Epoch: 31, Training Step: 900, Loss: 1.139116883277893, Learning Rate: 0.000125
2022-06-11-20_49_59  Epoch: 31, Training Step: 1000, Loss: 1.0195748805999756, Learning Rate: 0.000125
2022-06-11-20_50_25  Epoch: 31, Training Step: 1100, Loss: 0.7847373485565186, Learning Rate: 0.000125
2022-06-11-20_50_52  Epoch: 31, Training Step: 1200, Loss: 1.1087708473205566, Learning Rate: 0.000125
2022-06-11-20_51_19  Epoch: 31, Training Step: 1300, Loss: 0.7511277198791504, Learning Rate: 0.000125
2022-06-11-20_51_46  Epoch: 31, Training Step: 1400, Loss: 1.663487195968628, Learning Rate: 0.000125
2022-06-11-20_52_13  Epoch: 31, Training Step: 1500, Loss: 0.8837978839874268, Learning Rate: 0.000125
2022-06-11-20_52_40  Epoch: 31, Training Step: 1600, Loss: 0.8655200600624084, Learning Rate: 0.000125
2022-06-11-20_53_07  Epoch: 31, Training Step: 1700, Loss: 0.9551008343696594, Learning Rate: 0.000125
2022-06-11-20_53_34  Epoch: 31, Training Step: 1800, Loss: 0.959174394607544, Learning Rate: 0.000125
2022-06-11-20_54_01  Epoch: 31, Training Step: 1900, Loss: 0.8662303686141968, Learning Rate: 0.000125
2022-06-11-20_54_29  Epoch: 31, Training Step: 2000, Loss: 0.865851640701294, Learning Rate: 0.000125
2022-06-11-20_54_56  Epoch: 31, Training Step: 2100, Loss: 1.0113861560821533, Learning Rate: 0.000125
2022-06-11-20_55_22  Epoch: 31, Training Step: 2200, Loss: 0.870966911315918, Learning Rate: 0.000125
2022-06-11-20_55_51  Epoch: 31, Training Step: 2300, Loss: 1.0039176940917969, Learning Rate: 0.000125
2022-06-11-20_56_18  Epoch: 31, Training Step: 2400, Loss: 0.9756741523742676, Learning Rate: 0.000125
2022-06-11-20_56_45  Epoch: 31, Training Step: 2500, Loss: 0.8822104930877686, Learning Rate: 0.000125
2022-06-11-20_57_11  Epoch: 31, Training Step: 2600, Loss: 0.9846557378768921, Learning Rate: 0.000125
2022-06-11-20_57_38  Epoch: 31, Training Step: 2700, Loss: 0.9295759797096252, Learning Rate: 0.000125
2022-06-11-20_58_05  Epoch: 31, Training Step: 2800, Loss: 0.8763608336448669, Learning Rate: 0.000125
2022-06-11-20_58_32  Epoch: 31, Training Step: 2900, Loss: 0.7893849015235901, Learning Rate: 0.000125
2022-06-11-20_58_59  Epoch: 31, Training Step: 3000, Loss: 0.7594848275184631, Learning Rate: 0.000125
2022-06-11-20_59_26  Epoch: 31, Training Step: 3100, Loss: 0.7425490021705627, Learning Rate: 0.000125
2022-06-11-20_59_53  Epoch: 31, Training Step: 3200, Loss: 0.8026797771453857, Learning Rate: 0.000125
2022-06-11-21_02_52  Epoch: 32, Training Step: 0, Loss: 1.0567169189453125, Learning Rate: 0.000125
2022-06-11-21_03_19  Epoch: 32, Training Step: 100, Loss: 0.7765622138977051, Learning Rate: 0.000125
2022-06-11-21_03_47  Epoch: 32, Training Step: 200, Loss: 0.9680785536766052, Learning Rate: 0.000125
2022-06-11-21_04_14  Epoch: 32, Training Step: 300, Loss: 0.901129961013794, Learning Rate: 0.000125
2022-06-11-21_04_41  Epoch: 32, Training Step: 400, Loss: 0.6803513765335083, Learning Rate: 0.000125
2022-06-11-21_05_08  Epoch: 32, Training Step: 500, Loss: 1.2019362449645996, Learning Rate: 0.000125
2022-06-11-21_05_36  Epoch: 32, Training Step: 600, Loss: 0.8146860003471375, Learning Rate: 0.000125
2022-06-11-21_06_03  Epoch: 32, Training Step: 700, Loss: 0.9640932679176331, Learning Rate: 0.000125
2022-06-11-21_06_30  Epoch: 32, Training Step: 800, Loss: 0.84153151512146, Learning Rate: 0.000125
2022-06-11-21_06_57  Epoch: 32, Training Step: 900, Loss: 0.9419435262680054, Learning Rate: 0.000125
2022-06-11-21_07_23  Epoch: 32, Training Step: 1000, Loss: 0.8326245546340942, Learning Rate: 0.000125
2022-06-11-21_07_50  Epoch: 32, Training Step: 1100, Loss: 0.9412356019020081, Learning Rate: 0.000125
2022-06-11-21_08_17  Epoch: 32, Training Step: 1200, Loss: 1.027252435684204, Learning Rate: 0.000125
2022-06-11-21_08_43  Epoch: 32, Training Step: 1300, Loss: 1.048658013343811, Learning Rate: 0.000125
2022-06-11-21_09_09  Epoch: 32, Training Step: 1400, Loss: 1.0982568264007568, Learning Rate: 0.000125
2022-06-11-21_09_36  Epoch: 32, Training Step: 1500, Loss: 0.8571915626525879, Learning Rate: 0.000125
2022-06-11-21_10_02  Epoch: 32, Training Step: 1600, Loss: 0.789006233215332, Learning Rate: 0.000125
2022-06-11-21_10_29  Epoch: 32, Training Step: 1700, Loss: 0.9781419038772583, Learning Rate: 0.000125
2022-06-11-21_10_56  Epoch: 32, Training Step: 1800, Loss: 0.9028483629226685, Learning Rate: 0.000125
2022-06-11-21_11_23  Epoch: 32, Training Step: 1900, Loss: 0.8870769739151001, Learning Rate: 0.000125
2022-06-11-21_11_50  Epoch: 32, Training Step: 2000, Loss: 0.7356525659561157, Learning Rate: 0.000125
2022-06-11-21_12_16  Epoch: 32, Training Step: 2100, Loss: 0.9570140242576599, Learning Rate: 0.000125
2022-06-11-21_12_43  Epoch: 32, Training Step: 2200, Loss: 0.9642022848129272, Learning Rate: 0.000125
2022-06-11-21_13_11  Epoch: 32, Training Step: 2300, Loss: 0.8552653193473816, Learning Rate: 0.000125
2022-06-11-21_13_37  Epoch: 32, Training Step: 2400, Loss: 0.8746115565299988, Learning Rate: 0.000125
2022-06-11-21_14_04  Epoch: 32, Training Step: 2500, Loss: 0.9202626943588257, Learning Rate: 0.000125
2022-06-11-21_14_31  Epoch: 32, Training Step: 2600, Loss: 0.8161144852638245, Learning Rate: 0.000125
2022-06-11-21_14_58  Epoch: 32, Training Step: 2700, Loss: 0.9317480325698853, Learning Rate: 0.000125
2022-06-11-21_15_25  Epoch: 32, Training Step: 2800, Loss: 0.9666707515716553, Learning Rate: 0.000125
2022-06-11-21_15_52  Epoch: 32, Training Step: 2900, Loss: 0.839634120464325, Learning Rate: 0.000125
2022-06-11-21_16_19  Epoch: 32, Training Step: 3000, Loss: 1.0066769123077393, Learning Rate: 0.000125
2022-06-11-21_16_46  Epoch: 32, Training Step: 3100, Loss: 0.7143929600715637, Learning Rate: 0.000125
2022-06-11-21_17_13  Epoch: 32, Training Step: 3200, Loss: 1.0750722885131836, Learning Rate: 0.000125
2022-06-11-21_20_11  Epoch: 33, Training Step: 0, Loss: 0.9217096567153931, Learning Rate: 0.000125
2022-06-11-21_20_38  Epoch: 33, Training Step: 100, Loss: 0.7764994502067566, Learning Rate: 0.000125
2022-06-11-21_21_06  Epoch: 33, Training Step: 200, Loss: 0.7223625183105469, Learning Rate: 0.000125
2022-06-11-21_21_33  Epoch: 33, Training Step: 300, Loss: 0.7839286923408508, Learning Rate: 0.000125
2022-06-11-21_21_59  Epoch: 33, Training Step: 400, Loss: 0.7128937244415283, Learning Rate: 0.000125
2022-06-11-21_22_27  Epoch: 33, Training Step: 500, Loss: 0.8991310596466064, Learning Rate: 0.000125
2022-06-11-21_22_54  Epoch: 33, Training Step: 600, Loss: 0.8737640380859375, Learning Rate: 0.000125
2022-06-11-21_23_21  Epoch: 33, Training Step: 700, Loss: 0.8669629096984863, Learning Rate: 0.000125
2022-06-11-21_23_48  Epoch: 33, Training Step: 800, Loss: 0.9320110082626343, Learning Rate: 0.000125
2022-06-11-21_24_15  Epoch: 33, Training Step: 900, Loss: 0.782880425453186, Learning Rate: 0.000125
2022-06-11-21_24_42  Epoch: 33, Training Step: 1000, Loss: 0.7826260328292847, Learning Rate: 0.000125
2022-06-11-21_25_09  Epoch: 33, Training Step: 1100, Loss: 1.1876660585403442, Learning Rate: 0.000125
2022-06-11-21_25_36  Epoch: 33, Training Step: 1200, Loss: 0.7689127326011658, Learning Rate: 0.000125
2022-06-11-21_26_03  Epoch: 33, Training Step: 1300, Loss: 1.1582324504852295, Learning Rate: 0.000125
2022-06-11-21_26_30  Epoch: 33, Training Step: 1400, Loss: 0.8925960063934326, Learning Rate: 0.000125
2022-06-11-21_26_57  Epoch: 33, Training Step: 1500, Loss: 0.9561735391616821, Learning Rate: 0.000125
2022-06-11-21_27_24  Epoch: 33, Training Step: 1600, Loss: 0.795418381690979, Learning Rate: 0.000125
2022-06-11-21_27_51  Epoch: 33, Training Step: 1700, Loss: 0.921633243560791, Learning Rate: 0.000125
2022-06-11-21_28_18  Epoch: 33, Training Step: 1800, Loss: 0.8230977654457092, Learning Rate: 0.000125
2022-06-11-21_28_45  Epoch: 33, Training Step: 1900, Loss: 0.8495578765869141, Learning Rate: 0.000125
2022-06-11-21_29_12  Epoch: 33, Training Step: 2000, Loss: 0.8032999634742737, Learning Rate: 0.000125
2022-06-11-21_29_39  Epoch: 33, Training Step: 2100, Loss: 0.9498187303543091, Learning Rate: 0.000125
2022-06-11-21_30_06  Epoch: 33, Training Step: 2200, Loss: 0.947039008140564, Learning Rate: 0.000125
2022-06-11-21_30_33  Epoch: 33, Training Step: 2300, Loss: 0.7854176759719849, Learning Rate: 0.000125
2022-06-11-21_30_59  Epoch: 33, Training Step: 2400, Loss: 0.8777375221252441, Learning Rate: 0.000125
2022-06-11-21_31_26  Epoch: 33, Training Step: 2500, Loss: 1.169827938079834, Learning Rate: 0.000125
2022-06-11-21_31_54  Epoch: 33, Training Step: 2600, Loss: 0.7648063898086548, Learning Rate: 0.000125
2022-06-11-21_32_20  Epoch: 33, Training Step: 2700, Loss: 1.1029071807861328, Learning Rate: 0.000125
2022-06-11-21_32_48  Epoch: 33, Training Step: 2800, Loss: 0.9589505791664124, Learning Rate: 0.000125
2022-06-11-21_33_15  Epoch: 33, Training Step: 2900, Loss: 0.8072681427001953, Learning Rate: 0.000125
2022-06-11-21_33_42  Epoch: 33, Training Step: 3000, Loss: 0.8190362453460693, Learning Rate: 0.000125
2022-06-11-21_34_09  Epoch: 33, Training Step: 3100, Loss: 1.1608936786651611, Learning Rate: 0.000125
2022-06-11-21_34_35  Epoch: 33, Training Step: 3200, Loss: 1.0138906240463257, Learning Rate: 0.000125
2022-06-11-21_37_35  Epoch: 34, Training Step: 0, Loss: 0.8742166757583618, Learning Rate: 0.000125
2022-06-11-21_38_02  Epoch: 34, Training Step: 100, Loss: 0.8559372425079346, Learning Rate: 0.000125
2022-06-11-21_38_29  Epoch: 34, Training Step: 200, Loss: 0.9229861497879028, Learning Rate: 0.000125
2022-06-11-21_38_56  Epoch: 34, Training Step: 300, Loss: 0.9942050576210022, Learning Rate: 0.000125
2022-06-11-21_39_23  Epoch: 34, Training Step: 400, Loss: 0.7535024881362915, Learning Rate: 0.000125
2022-06-11-21_39_50  Epoch: 34, Training Step: 500, Loss: 0.8562888503074646, Learning Rate: 0.000125
2022-06-11-21_40_18  Epoch: 34, Training Step: 600, Loss: 0.895297646522522, Learning Rate: 0.000125
2022-06-11-21_40_45  Epoch: 34, Training Step: 700, Loss: 1.2407305240631104, Learning Rate: 0.000125
2022-06-11-21_41_11  Epoch: 34, Training Step: 800, Loss: 0.8921023011207581, Learning Rate: 0.000125
2022-06-11-21_41_39  Epoch: 34, Training Step: 900, Loss: 1.0126984119415283, Learning Rate: 0.000125
2022-06-11-21_42_05  Epoch: 34, Training Step: 1000, Loss: 1.0054070949554443, Learning Rate: 0.000125
2022-06-11-21_42_33  Epoch: 34, Training Step: 1100, Loss: 1.0203053951263428, Learning Rate: 0.000125
2022-06-11-21_43_00  Epoch: 34, Training Step: 1200, Loss: 0.9398208260536194, Learning Rate: 0.000125
2022-06-11-21_43_26  Epoch: 34, Training Step: 1300, Loss: 0.9980794191360474, Learning Rate: 0.000125
2022-06-11-21_43_53  Epoch: 34, Training Step: 1400, Loss: 0.810594916343689, Learning Rate: 0.000125
2022-06-11-21_44_19  Epoch: 34, Training Step: 1500, Loss: 0.9826419949531555, Learning Rate: 0.000125
2022-06-11-21_44_47  Epoch: 34, Training Step: 1600, Loss: 1.008899450302124, Learning Rate: 0.000125
2022-06-11-21_45_14  Epoch: 34, Training Step: 1700, Loss: 0.798191249370575, Learning Rate: 0.000125
2022-06-11-21_45_41  Epoch: 34, Training Step: 1800, Loss: 0.8013134598731995, Learning Rate: 0.000125
2022-06-11-21_46_08  Epoch: 34, Training Step: 1900, Loss: 0.8877815008163452, Learning Rate: 0.000125
2022-06-11-21_46_35  Epoch: 34, Training Step: 2000, Loss: 0.9137178063392639, Learning Rate: 0.000125
2022-06-11-21_47_02  Epoch: 34, Training Step: 2100, Loss: 0.8266667723655701, Learning Rate: 0.000125
2022-06-11-21_47_29  Epoch: 34, Training Step: 2200, Loss: 0.8625988960266113, Learning Rate: 0.000125
2022-06-11-21_47_57  Epoch: 34, Training Step: 2300, Loss: 0.9369667768478394, Learning Rate: 0.000125
2022-06-11-21_48_23  Epoch: 34, Training Step: 2400, Loss: 0.9374396800994873, Learning Rate: 0.000125
2022-06-11-21_48_50  Epoch: 34, Training Step: 2500, Loss: 1.1073031425476074, Learning Rate: 0.000125
2022-06-11-21_49_18  Epoch: 34, Training Step: 2600, Loss: 0.8576316237449646, Learning Rate: 0.000125
2022-06-11-21_49_45  Epoch: 34, Training Step: 2700, Loss: 1.065764307975769, Learning Rate: 0.000125
2022-06-11-21_50_12  Epoch: 34, Training Step: 2800, Loss: 0.9020052552223206, Learning Rate: 0.000125
2022-06-11-21_50_39  Epoch: 34, Training Step: 2900, Loss: 1.1413675546646118, Learning Rate: 0.000125
2022-06-11-21_51_07  Epoch: 34, Training Step: 3000, Loss: 0.8835266828536987, Learning Rate: 0.000125
2022-06-11-21_51_34  Epoch: 34, Training Step: 3100, Loss: 0.9212762713432312, Learning Rate: 0.000125
2022-06-11-21_52_01  Epoch: 34, Training Step: 3200, Loss: 0.9093402624130249, Learning Rate: 0.000125
2022-06-11-21_55_01  Epoch: 35, Training Step: 0, Loss: 0.9266039133071899, Learning Rate: 0.000125
2022-06-11-21_55_28  Epoch: 35, Training Step: 100, Loss: 0.7611613273620605, Learning Rate: 0.000125
2022-06-11-21_55_55  Epoch: 35, Training Step: 200, Loss: 0.8540494441986084, Learning Rate: 0.000125
2022-06-11-21_56_21  Epoch: 35, Training Step: 300, Loss: 0.8190320134162903, Learning Rate: 0.000125
2022-06-11-21_56_48  Epoch: 35, Training Step: 400, Loss: 0.8187471032142639, Learning Rate: 0.000125
2022-06-11-21_57_15  Epoch: 35, Training Step: 500, Loss: 0.8733075857162476, Learning Rate: 0.000125
2022-06-11-21_57_43  Epoch: 35, Training Step: 600, Loss: 0.7691554427146912, Learning Rate: 0.000125
2022-06-11-21_58_09  Epoch: 35, Training Step: 700, Loss: 1.0024852752685547, Learning Rate: 0.000125
2022-06-11-21_58_36  Epoch: 35, Training Step: 800, Loss: 0.7880160808563232, Learning Rate: 0.000125
2022-06-11-21_59_03  Epoch: 35, Training Step: 900, Loss: 0.7879139184951782, Learning Rate: 0.000125
2022-06-11-21_59_30  Epoch: 35, Training Step: 1000, Loss: 0.9755235910415649, Learning Rate: 0.000125
2022-06-11-21_59_56  Epoch: 35, Training Step: 1100, Loss: 0.7573502063751221, Learning Rate: 0.000125
2022-06-11-22_00_23  Epoch: 35, Training Step: 1200, Loss: 0.8755667209625244, Learning Rate: 0.000125
2022-06-11-22_00_50  Epoch: 35, Training Step: 1300, Loss: 0.8011988997459412, Learning Rate: 0.000125
2022-06-11-22_01_18  Epoch: 35, Training Step: 1400, Loss: 0.8038996458053589, Learning Rate: 0.000125
2022-06-11-22_01_45  Epoch: 35, Training Step: 1500, Loss: 0.8210569024085999, Learning Rate: 0.000125
2022-06-11-22_02_12  Epoch: 35, Training Step: 1600, Loss: 0.8901757001876831, Learning Rate: 0.000125
2022-06-11-22_02_39  Epoch: 35, Training Step: 1700, Loss: 0.9830962419509888, Learning Rate: 0.000125
2022-06-11-22_03_06  Epoch: 35, Training Step: 1800, Loss: 0.8752402067184448, Learning Rate: 0.000125
2022-06-11-22_03_33  Epoch: 35, Training Step: 1900, Loss: 0.9402948617935181, Learning Rate: 0.000125
2022-06-11-22_04_00  Epoch: 35, Training Step: 2000, Loss: 0.8893231153488159, Learning Rate: 0.000125
2022-06-11-22_04_27  Epoch: 35, Training Step: 2100, Loss: 0.9492497444152832, Learning Rate: 0.000125
2022-06-11-22_04_54  Epoch: 35, Training Step: 2200, Loss: 0.7918190956115723, Learning Rate: 0.000125
2022-06-11-22_05_21  Epoch: 35, Training Step: 2300, Loss: 0.8403763175010681, Learning Rate: 0.000125
2022-06-11-22_05_48  Epoch: 35, Training Step: 2400, Loss: 0.8689536452293396, Learning Rate: 0.000125
2022-06-11-22_06_15  Epoch: 35, Training Step: 2500, Loss: 0.8162779808044434, Learning Rate: 0.000125
2022-06-11-22_06_42  Epoch: 35, Training Step: 2600, Loss: 1.2257184982299805, Learning Rate: 0.000125
2022-06-11-22_07_09  Epoch: 35, Training Step: 2700, Loss: 0.7750494480133057, Learning Rate: 0.000125
2022-06-11-22_07_36  Epoch: 35, Training Step: 2800, Loss: 0.938485860824585, Learning Rate: 0.000125
2022-06-11-22_08_04  Epoch: 35, Training Step: 2900, Loss: 1.0027897357940674, Learning Rate: 0.000125
2022-06-11-22_08_31  Epoch: 35, Training Step: 3000, Loss: 0.8930666446685791, Learning Rate: 0.000125
2022-06-11-22_08_58  Epoch: 35, Training Step: 3100, Loss: 0.7679070234298706, Learning Rate: 0.000125
2022-06-11-22_09_26  Epoch: 35, Training Step: 3200, Loss: 1.090556263923645, Learning Rate: 0.000125
2022-06-11-22_12_29  Epoch: 36, Training Step: 0, Loss: 0.8635035753250122, Learning Rate: 0.000125
2022-06-11-22_12_57  Epoch: 36, Training Step: 100, Loss: 0.7972176671028137, Learning Rate: 0.000125
2022-06-11-22_13_24  Epoch: 36, Training Step: 200, Loss: 0.9521808624267578, Learning Rate: 0.000125
2022-06-11-22_13_50  Epoch: 36, Training Step: 300, Loss: 0.7666101455688477, Learning Rate: 0.000125
2022-06-11-22_14_17  Epoch: 36, Training Step: 400, Loss: 0.9357000589370728, Learning Rate: 0.000125
2022-06-11-22_14_44  Epoch: 36, Training Step: 500, Loss: 0.6597259044647217, Learning Rate: 0.000125
2022-06-11-22_15_11  Epoch: 36, Training Step: 600, Loss: 0.9504345655441284, Learning Rate: 0.000125
2022-06-11-22_15_38  Epoch: 36, Training Step: 700, Loss: 0.7284978628158569, Learning Rate: 0.000125
2022-06-11-22_16_06  Epoch: 36, Training Step: 800, Loss: 0.9066827297210693, Learning Rate: 0.000125
2022-06-11-22_16_33  Epoch: 36, Training Step: 900, Loss: 0.806980311870575, Learning Rate: 0.000125
2022-06-11-22_17_00  Epoch: 36, Training Step: 1000, Loss: 0.831842839717865, Learning Rate: 0.000125
2022-06-11-22_17_27  Epoch: 36, Training Step: 1100, Loss: 0.8044476509094238, Learning Rate: 0.000125
2022-06-11-22_17_53  Epoch: 36, Training Step: 1200, Loss: 1.0321452617645264, Learning Rate: 0.000125
2022-06-11-22_18_20  Epoch: 36, Training Step: 1300, Loss: 1.2357053756713867, Learning Rate: 0.000125
2022-06-11-22_18_48  Epoch: 36, Training Step: 1400, Loss: 0.7845997214317322, Learning Rate: 0.000125
2022-06-11-22_19_15  Epoch: 36, Training Step: 1500, Loss: 0.8866742849349976, Learning Rate: 0.000125
2022-06-11-22_19_42  Epoch: 36, Training Step: 1600, Loss: 1.0508657693862915, Learning Rate: 0.000125
2022-06-11-22_20_09  Epoch: 36, Training Step: 1700, Loss: 0.7817529439926147, Learning Rate: 0.000125
2022-06-11-22_20_37  Epoch: 36, Training Step: 1800, Loss: 0.8099085092544556, Learning Rate: 0.000125
2022-06-11-22_21_04  Epoch: 36, Training Step: 1900, Loss: 0.9012621641159058, Learning Rate: 0.000125
2022-06-11-22_21_31  Epoch: 36, Training Step: 2000, Loss: 0.9564832448959351, Learning Rate: 0.000125
2022-06-11-22_21_58  Epoch: 36, Training Step: 2100, Loss: 1.0169185400009155, Learning Rate: 0.000125
2022-06-11-22_22_25  Epoch: 36, Training Step: 2200, Loss: 0.9624894261360168, Learning Rate: 0.000125
2022-06-11-22_22_52  Epoch: 36, Training Step: 2300, Loss: 0.7668477892875671, Learning Rate: 0.000125
2022-06-11-22_23_19  Epoch: 36, Training Step: 2400, Loss: 0.9515031576156616, Learning Rate: 0.000125
2022-06-11-22_23_47  Epoch: 36, Training Step: 2500, Loss: 0.9279842972755432, Learning Rate: 0.000125
2022-06-11-22_24_14  Epoch: 36, Training Step: 2600, Loss: 0.9161689281463623, Learning Rate: 0.000125
2022-06-11-22_24_41  Epoch: 36, Training Step: 2700, Loss: 0.7072797417640686, Learning Rate: 0.000125
2022-06-11-22_25_08  Epoch: 36, Training Step: 2800, Loss: 0.8082160949707031, Learning Rate: 0.000125
2022-06-11-22_25_35  Epoch: 36, Training Step: 2900, Loss: 1.0089563131332397, Learning Rate: 0.000125
2022-06-11-22_26_02  Epoch: 36, Training Step: 3000, Loss: 0.8821069002151489, Learning Rate: 0.000125
2022-06-11-22_26_29  Epoch: 36, Training Step: 3100, Loss: 0.9306237697601318, Learning Rate: 0.000125
2022-06-11-22_26_57  Epoch: 36, Training Step: 3200, Loss: 0.7823744416236877, Learning Rate: 0.000125
2022-06-11-22_29_59  Epoch: 37, Training Step: 0, Loss: 0.9370913505554199, Learning Rate: 0.000125
2022-06-11-22_30_26  Epoch: 37, Training Step: 100, Loss: 0.8236967921257019, Learning Rate: 0.000125
2022-06-11-22_30_53  Epoch: 37, Training Step: 200, Loss: 0.9171831607818604, Learning Rate: 0.000125
2022-06-11-22_31_20  Epoch: 37, Training Step: 300, Loss: 1.2841242551803589, Learning Rate: 0.000125
2022-06-11-22_31_48  Epoch: 37, Training Step: 400, Loss: 0.767849326133728, Learning Rate: 0.000125
2022-06-11-22_32_15  Epoch: 37, Training Step: 500, Loss: 0.9680030345916748, Learning Rate: 0.000125
2022-06-11-22_32_42  Epoch: 37, Training Step: 600, Loss: 0.8640519976615906, Learning Rate: 0.000125
2022-06-11-22_33_09  Epoch: 37, Training Step: 700, Loss: 0.9105665683746338, Learning Rate: 0.000125
2022-06-11-22_33_35  Epoch: 37, Training Step: 800, Loss: 0.9051740169525146, Learning Rate: 0.000125
2022-06-11-22_34_02  Epoch: 37, Training Step: 900, Loss: 0.9173147678375244, Learning Rate: 0.000125
2022-06-11-22_34_28  Epoch: 37, Training Step: 1000, Loss: 1.000838279724121, Learning Rate: 0.000125
2022-06-11-22_34_55  Epoch: 37, Training Step: 1100, Loss: 0.9594334363937378, Learning Rate: 0.000125
2022-06-11-22_35_22  Epoch: 37, Training Step: 1200, Loss: 0.7478601336479187, Learning Rate: 0.000125
2022-06-11-22_35_49  Epoch: 37, Training Step: 1300, Loss: 0.6906942129135132, Learning Rate: 0.000125
2022-06-11-22_36_16  Epoch: 37, Training Step: 1400, Loss: 0.8830128312110901, Learning Rate: 0.000125
2022-06-11-22_36_44  Epoch: 37, Training Step: 1500, Loss: 0.8150452971458435, Learning Rate: 0.000125
2022-06-11-22_37_11  Epoch: 37, Training Step: 1600, Loss: 0.946479856967926, Learning Rate: 0.000125
2022-06-11-22_37_38  Epoch: 37, Training Step: 1700, Loss: 1.0468536615371704, Learning Rate: 0.000125
2022-06-11-22_38_05  Epoch: 37, Training Step: 1800, Loss: 0.8442329168319702, Learning Rate: 0.000125
2022-06-11-22_38_32  Epoch: 37, Training Step: 1900, Loss: 0.9437978863716125, Learning Rate: 0.000125
2022-06-11-22_39_00  Epoch: 37, Training Step: 2000, Loss: 0.8460584878921509, Learning Rate: 0.000125
2022-06-11-22_39_27  Epoch: 37, Training Step: 2100, Loss: 1.0560450553894043, Learning Rate: 0.000125
2022-06-11-22_39_54  Epoch: 37, Training Step: 2200, Loss: 0.767163097858429, Learning Rate: 0.000125
2022-06-11-22_40_21  Epoch: 37, Training Step: 2300, Loss: 0.8315833806991577, Learning Rate: 0.000125
2022-06-11-22_40_48  Epoch: 37, Training Step: 2400, Loss: 0.8664864301681519, Learning Rate: 0.000125
2022-06-11-22_41_14  Epoch: 37, Training Step: 2500, Loss: 0.9311069250106812, Learning Rate: 0.000125
2022-06-11-22_41_41  Epoch: 37, Training Step: 2600, Loss: 1.036820411682129, Learning Rate: 0.000125
2022-06-11-22_42_08  Epoch: 37, Training Step: 2700, Loss: 0.8092399835586548, Learning Rate: 0.000125
2022-06-11-22_42_35  Epoch: 37, Training Step: 2800, Loss: 0.7893586754798889, Learning Rate: 0.000125
2022-06-11-22_43_02  Epoch: 37, Training Step: 2900, Loss: 0.8408689498901367, Learning Rate: 0.000125
2022-06-11-22_43_30  Epoch: 37, Training Step: 3000, Loss: 0.6862204670906067, Learning Rate: 0.000125
2022-06-11-22_43_57  Epoch: 37, Training Step: 3100, Loss: 0.8559917211532593, Learning Rate: 0.000125
2022-06-11-22_44_24  Epoch: 37, Training Step: 3200, Loss: 1.0860543251037598, Learning Rate: 0.000125
2022-06-11-22_47_23  Epoch: 38, Training Step: 0, Loss: 0.8913089036941528, Learning Rate: 0.000125
2022-06-11-22_47_50  Epoch: 38, Training Step: 100, Loss: 0.8352278470993042, Learning Rate: 0.000125
2022-06-11-22_48_17  Epoch: 38, Training Step: 200, Loss: 1.1629420518875122, Learning Rate: 0.000125
2022-06-11-22_48_43  Epoch: 38, Training Step: 300, Loss: 0.7377471923828125, Learning Rate: 0.000125
2022-06-11-22_49_11  Epoch: 38, Training Step: 400, Loss: 0.8815869688987732, Learning Rate: 0.000125
2022-06-11-22_49_37  Epoch: 38, Training Step: 500, Loss: 1.0128662586212158, Learning Rate: 0.000125
2022-06-11-22_50_04  Epoch: 38, Training Step: 600, Loss: 0.9051955938339233, Learning Rate: 0.000125
2022-06-11-22_50_31  Epoch: 38, Training Step: 700, Loss: 1.0795767307281494, Learning Rate: 0.000125
2022-06-11-22_50_58  Epoch: 38, Training Step: 800, Loss: 0.9251846671104431, Learning Rate: 0.000125
2022-06-11-22_51_24  Epoch: 38, Training Step: 900, Loss: 0.8619027137756348, Learning Rate: 0.000125
2022-06-11-22_51_51  Epoch: 38, Training Step: 1000, Loss: 0.8970040082931519, Learning Rate: 0.000125
2022-06-11-22_52_17  Epoch: 38, Training Step: 1100, Loss: 0.8557158708572388, Learning Rate: 0.000125
2022-06-11-22_52_44  Epoch: 38, Training Step: 1200, Loss: 0.7953816056251526, Learning Rate: 0.000125
2022-06-11-22_53_11  Epoch: 38, Training Step: 1300, Loss: 0.9152793884277344, Learning Rate: 0.000125
2022-06-11-22_53_37  Epoch: 38, Training Step: 1400, Loss: 0.9665930271148682, Learning Rate: 0.000125
2022-06-11-22_54_05  Epoch: 38, Training Step: 1500, Loss: 1.1350377798080444, Learning Rate: 0.000125
2022-06-11-22_54_32  Epoch: 38, Training Step: 1600, Loss: 0.7866080403327942, Learning Rate: 0.000125
2022-06-11-22_54_59  Epoch: 38, Training Step: 1700, Loss: 0.885205864906311, Learning Rate: 0.000125
2022-06-11-22_55_25  Epoch: 38, Training Step: 1800, Loss: 0.8781180381774902, Learning Rate: 0.000125
2022-06-11-22_55_52  Epoch: 38, Training Step: 1900, Loss: 0.7730535268783569, Learning Rate: 0.000125
2022-06-11-22_56_19  Epoch: 38, Training Step: 2000, Loss: 0.9874126315116882, Learning Rate: 0.000125
2022-06-11-22_56_46  Epoch: 38, Training Step: 2100, Loss: 0.8155918121337891, Learning Rate: 0.000125
2022-06-11-22_57_13  Epoch: 38, Training Step: 2200, Loss: 0.97541344165802, Learning Rate: 0.000125
2022-06-11-22_57_40  Epoch: 38, Training Step: 2300, Loss: 0.8056744337081909, Learning Rate: 0.000125
2022-06-11-22_58_07  Epoch: 38, Training Step: 2400, Loss: 0.8257802128791809, Learning Rate: 0.000125
2022-06-11-22_58_34  Epoch: 38, Training Step: 2500, Loss: 0.9977825284004211, Learning Rate: 0.000125
2022-06-11-22_59_01  Epoch: 38, Training Step: 2600, Loss: 1.1593788862228394, Learning Rate: 0.000125
2022-06-11-22_59_29  Epoch: 38, Training Step: 2700, Loss: 0.9710540771484375, Learning Rate: 0.000125
2022-06-11-22_59_56  Epoch: 38, Training Step: 2800, Loss: 0.7735368013381958, Learning Rate: 0.000125
2022-06-11-23_00_23  Epoch: 38, Training Step: 2900, Loss: 0.8243797421455383, Learning Rate: 0.000125
2022-06-11-23_00_50  Epoch: 38, Training Step: 3000, Loss: 0.8495292663574219, Learning Rate: 0.000125
2022-06-11-23_01_17  Epoch: 38, Training Step: 3100, Loss: 0.8208845257759094, Learning Rate: 0.000125
2022-06-11-23_01_44  Epoch: 38, Training Step: 3200, Loss: 0.8429834842681885, Learning Rate: 0.000125
2022-06-11-23_04_41  Epoch: 39, Training Step: 0, Loss: 0.9526809453964233, Learning Rate: 0.000125
2022-06-11-23_05_08  Epoch: 39, Training Step: 100, Loss: 0.868976891040802, Learning Rate: 0.000125
2022-06-11-23_05_34  Epoch: 39, Training Step: 200, Loss: 0.8205044269561768, Learning Rate: 0.000125
2022-06-11-23_06_01  Epoch: 39, Training Step: 300, Loss: 1.0516481399536133, Learning Rate: 0.000125
2022-06-11-23_06_27  Epoch: 39, Training Step: 400, Loss: 0.9939656853675842, Learning Rate: 0.000125
2022-06-11-23_06_54  Epoch: 39, Training Step: 500, Loss: 0.8277256488800049, Learning Rate: 0.000125
2022-06-11-23_07_20  Epoch: 39, Training Step: 600, Loss: 0.9503573179244995, Learning Rate: 0.000125
2022-06-11-23_07_47  Epoch: 39, Training Step: 700, Loss: 1.1608251333236694, Learning Rate: 0.000125
2022-06-11-23_08_14  Epoch: 39, Training Step: 800, Loss: 0.709736704826355, Learning Rate: 0.000125
2022-06-11-23_08_41  Epoch: 39, Training Step: 900, Loss: 0.8646585941314697, Learning Rate: 0.000125
2022-06-11-23_09_08  Epoch: 39, Training Step: 1000, Loss: 0.8345353007316589, Learning Rate: 0.000125
2022-06-11-23_09_36  Epoch: 39, Training Step: 1100, Loss: 1.123828411102295, Learning Rate: 0.000125
2022-06-11-23_10_03  Epoch: 39, Training Step: 1200, Loss: 0.8520575761795044, Learning Rate: 0.000125
2022-06-11-23_10_30  Epoch: 39, Training Step: 1300, Loss: 0.8463184237480164, Learning Rate: 0.000125
2022-06-11-23_10_58  Epoch: 39, Training Step: 1400, Loss: 1.0788273811340332, Learning Rate: 0.000125
2022-06-11-23_11_25  Epoch: 39, Training Step: 1500, Loss: 0.953519344329834, Learning Rate: 0.000125
2022-06-11-23_11_52  Epoch: 39, Training Step: 1600, Loss: 1.1094361543655396, Learning Rate: 0.000125
2022-06-11-23_12_19  Epoch: 39, Training Step: 1700, Loss: 0.7706555128097534, Learning Rate: 0.000125
2022-06-11-23_12_47  Epoch: 39, Training Step: 1800, Loss: 0.8582216501235962, Learning Rate: 0.000125
2022-06-11-23_13_14  Epoch: 39, Training Step: 1900, Loss: 0.8672633171081543, Learning Rate: 0.000125
2022-06-11-23_13_41  Epoch: 39, Training Step: 2000, Loss: 0.866761326789856, Learning Rate: 0.000125
2022-06-11-23_14_08  Epoch: 39, Training Step: 2100, Loss: 0.9006837606430054, Learning Rate: 0.000125
2022-06-11-23_14_35  Epoch: 39, Training Step: 2200, Loss: 0.9863570332527161, Learning Rate: 0.000125
2022-06-11-23_15_02  Epoch: 39, Training Step: 2300, Loss: 0.8219646215438843, Learning Rate: 0.000125
2022-06-11-23_15_29  Epoch: 39, Training Step: 2400, Loss: 1.1161633729934692, Learning Rate: 0.000125
2022-06-11-23_15_56  Epoch: 39, Training Step: 2500, Loss: 0.8421936631202698, Learning Rate: 0.000125
2022-06-11-23_16_23  Epoch: 39, Training Step: 2600, Loss: 0.7556877136230469, Learning Rate: 0.000125
2022-06-11-23_16_50  Epoch: 39, Training Step: 2700, Loss: 0.7789091467857361, Learning Rate: 0.000125
2022-06-11-23_17_17  Epoch: 39, Training Step: 2800, Loss: 0.9500892758369446, Learning Rate: 0.000125
2022-06-11-23_17_44  Epoch: 39, Training Step: 2900, Loss: 0.9477372169494629, Learning Rate: 0.000125
2022-06-11-23_18_11  Epoch: 39, Training Step: 3000, Loss: 0.8482341766357422, Learning Rate: 0.000125
2022-06-11-23_18_38  Epoch: 39, Training Step: 3100, Loss: 0.8584193587303162, Learning Rate: 0.000125
2022-06-11-23_19_05  Epoch: 39, Training Step: 3200, Loss: 0.8083606362342834, Learning Rate: 0.000125
2022-06-11-23_22_03  Epoch: 40, Training Step: 0, Loss: 0.9309777021408081, Learning Rate: 6.25e-05
2022-06-11-23_22_30  Epoch: 40, Training Step: 100, Loss: 0.829049825668335, Learning Rate: 6.25e-05
2022-06-11-23_22_57  Epoch: 40, Training Step: 200, Loss: 0.855431318283081, Learning Rate: 6.25e-05
2022-06-11-23_23_24  Epoch: 40, Training Step: 300, Loss: 0.755567193031311, Learning Rate: 6.25e-05
2022-06-11-23_23_51  Epoch: 40, Training Step: 400, Loss: 0.8072544932365417, Learning Rate: 6.25e-05
2022-06-11-23_24_18  Epoch: 40, Training Step: 500, Loss: 0.8071353435516357, Learning Rate: 6.25e-05
2022-06-11-23_24_45  Epoch: 40, Training Step: 600, Loss: 0.797035276889801, Learning Rate: 6.25e-05
2022-06-11-23_25_12  Epoch: 40, Training Step: 700, Loss: 0.8985613584518433, Learning Rate: 6.25e-05
2022-06-11-23_25_39  Epoch: 40, Training Step: 800, Loss: 0.8927477598190308, Learning Rate: 6.25e-05
2022-06-11-23_26_07  Epoch: 40, Training Step: 900, Loss: 0.9731470346450806, Learning Rate: 6.25e-05
2022-06-11-23_26_35  Epoch: 40, Training Step: 1000, Loss: 0.9411882758140564, Learning Rate: 6.25e-05
2022-06-11-23_27_02  Epoch: 40, Training Step: 1100, Loss: 0.9772317409515381, Learning Rate: 6.25e-05
2022-06-11-23_27_29  Epoch: 40, Training Step: 1200, Loss: 1.0296145677566528, Learning Rate: 6.25e-05
2022-06-11-23_27_56  Epoch: 40, Training Step: 1300, Loss: 0.8828752040863037, Learning Rate: 6.25e-05
2022-06-11-23_28_23  Epoch: 40, Training Step: 1400, Loss: 0.8445868492126465, Learning Rate: 6.25e-05
2022-06-11-23_28_49  Epoch: 40, Training Step: 1500, Loss: 0.9048571586608887, Learning Rate: 6.25e-05
2022-06-11-23_29_16  Epoch: 40, Training Step: 1600, Loss: 0.8518323302268982, Learning Rate: 6.25e-05
2022-06-11-23_29_43  Epoch: 40, Training Step: 1700, Loss: 0.8452066779136658, Learning Rate: 6.25e-05
2022-06-11-23_30_10  Epoch: 40, Training Step: 1800, Loss: 1.1377801895141602, Learning Rate: 6.25e-05
2022-06-11-23_30_37  Epoch: 40, Training Step: 1900, Loss: 1.0823321342468262, Learning Rate: 6.25e-05
2022-06-11-23_31_04  Epoch: 40, Training Step: 2000, Loss: 0.8239088654518127, Learning Rate: 6.25e-05
2022-06-11-23_31_31  Epoch: 40, Training Step: 2100, Loss: 0.6954933404922485, Learning Rate: 6.25e-05
2022-06-11-23_31_59  Epoch: 40, Training Step: 2200, Loss: 1.297248363494873, Learning Rate: 6.25e-05
2022-06-11-23_32_26  Epoch: 40, Training Step: 2300, Loss: 0.9098025560379028, Learning Rate: 6.25e-05
2022-06-11-23_32_52  Epoch: 40, Training Step: 2400, Loss: 0.8570628762245178, Learning Rate: 6.25e-05
2022-06-11-23_33_19  Epoch: 40, Training Step: 2500, Loss: 0.7001075744628906, Learning Rate: 6.25e-05
2022-06-11-23_33_46  Epoch: 40, Training Step: 2600, Loss: 0.7346656918525696, Learning Rate: 6.25e-05
2022-06-11-23_34_13  Epoch: 40, Training Step: 2700, Loss: 0.9987619519233704, Learning Rate: 6.25e-05
2022-06-11-23_34_40  Epoch: 40, Training Step: 2800, Loss: 1.0157541036605835, Learning Rate: 6.25e-05
2022-06-11-23_35_07  Epoch: 40, Training Step: 2900, Loss: 1.0760695934295654, Learning Rate: 6.25e-05
2022-06-11-23_35_34  Epoch: 40, Training Step: 3000, Loss: 0.7960832118988037, Learning Rate: 6.25e-05
2022-06-11-23_36_02  Epoch: 40, Training Step: 3100, Loss: 0.961101770401001, Learning Rate: 6.25e-05
2022-06-11-23_36_29  Epoch: 40, Training Step: 3200, Loss: 0.8076043128967285, Learning Rate: 6.25e-05
2022-06-11-23_39_31  Epoch: 41, Training Step: 0, Loss: 1.121938943862915, Learning Rate: 6.25e-05
2022-06-11-23_39_58  Epoch: 41, Training Step: 100, Loss: 0.765457808971405, Learning Rate: 6.25e-05
2022-06-11-23_40_24  Epoch: 41, Training Step: 200, Loss: 0.8531539440155029, Learning Rate: 6.25e-05
2022-06-11-23_40_51  Epoch: 41, Training Step: 300, Loss: 0.8400998711585999, Learning Rate: 6.25e-05
2022-06-11-23_41_18  Epoch: 41, Training Step: 400, Loss: 0.8263832330703735, Learning Rate: 6.25e-05
2022-06-11-23_41_45  Epoch: 41, Training Step: 500, Loss: 1.0097486972808838, Learning Rate: 6.25e-05
2022-06-11-23_42_12  Epoch: 41, Training Step: 600, Loss: 0.8905144929885864, Learning Rate: 6.25e-05
2022-06-11-23_42_39  Epoch: 41, Training Step: 700, Loss: 0.8948413729667664, Learning Rate: 6.25e-05
2022-06-11-23_43_07  Epoch: 41, Training Step: 800, Loss: 1.1044155359268188, Learning Rate: 6.25e-05
2022-06-11-23_43_34  Epoch: 41, Training Step: 900, Loss: 0.7347403764724731, Learning Rate: 6.25e-05
2022-06-11-23_44_01  Epoch: 41, Training Step: 1000, Loss: 0.7971290349960327, Learning Rate: 6.25e-05
2022-06-11-23_44_28  Epoch: 41, Training Step: 1100, Loss: 1.0565073490142822, Learning Rate: 6.25e-05
2022-06-11-23_44_55  Epoch: 41, Training Step: 1200, Loss: 0.9578322172164917, Learning Rate: 6.25e-05
2022-06-11-23_45_22  Epoch: 41, Training Step: 1300, Loss: 0.8511728048324585, Learning Rate: 6.25e-05
2022-06-11-23_45_49  Epoch: 41, Training Step: 1400, Loss: 0.7647604942321777, Learning Rate: 6.25e-05
2022-06-11-23_46_16  Epoch: 41, Training Step: 1500, Loss: 0.6985163688659668, Learning Rate: 6.25e-05
2022-06-11-23_46_44  Epoch: 41, Training Step: 1600, Loss: 1.0886704921722412, Learning Rate: 6.25e-05
2022-06-11-23_47_11  Epoch: 41, Training Step: 1700, Loss: 0.8318994045257568, Learning Rate: 6.25e-05
2022-06-11-23_47_38  Epoch: 41, Training Step: 1800, Loss: 0.7569391131401062, Learning Rate: 6.25e-05
2022-06-11-23_48_04  Epoch: 41, Training Step: 1900, Loss: 0.86649090051651, Learning Rate: 6.25e-05
2022-06-11-23_48_31  Epoch: 41, Training Step: 2000, Loss: 0.8441520929336548, Learning Rate: 6.25e-05
2022-06-11-23_48_59  Epoch: 41, Training Step: 2100, Loss: 0.8233740329742432, Learning Rate: 6.25e-05
2022-06-11-23_49_26  Epoch: 41, Training Step: 2200, Loss: 0.9042680859565735, Learning Rate: 6.25e-05
2022-06-11-23_49_52  Epoch: 41, Training Step: 2300, Loss: 0.7524698376655579, Learning Rate: 6.25e-05
2022-06-11-23_50_20  Epoch: 41, Training Step: 2400, Loss: 0.8272562026977539, Learning Rate: 6.25e-05
2022-06-11-23_50_47  Epoch: 41, Training Step: 2500, Loss: 0.7283020615577698, Learning Rate: 6.25e-05
2022-06-11-23_51_15  Epoch: 41, Training Step: 2600, Loss: 0.8445135354995728, Learning Rate: 6.25e-05
2022-06-11-23_51_43  Epoch: 41, Training Step: 2700, Loss: 0.92569899559021, Learning Rate: 6.25e-05
2022-06-11-23_52_10  Epoch: 41, Training Step: 2800, Loss: 0.8213207721710205, Learning Rate: 6.25e-05
2022-06-11-23_52_37  Epoch: 41, Training Step: 2900, Loss: 0.9344696402549744, Learning Rate: 6.25e-05
2022-06-11-23_53_04  Epoch: 41, Training Step: 3000, Loss: 1.1466026306152344, Learning Rate: 6.25e-05
2022-06-11-23_53_32  Epoch: 41, Training Step: 3100, Loss: 0.7381082773208618, Learning Rate: 6.25e-05
2022-06-11-23_53_59  Epoch: 41, Training Step: 3200, Loss: 0.8781810998916626, Learning Rate: 6.25e-05
2022-06-11-23_57_00  Epoch: 42, Training Step: 0, Loss: 0.8464163541793823, Learning Rate: 6.25e-05
2022-06-11-23_57_27  Epoch: 42, Training Step: 100, Loss: 0.7341798543930054, Learning Rate: 6.25e-05
2022-06-11-23_57_55  Epoch: 42, Training Step: 200, Loss: 0.8230748772621155, Learning Rate: 6.25e-05
2022-06-11-23_58_21  Epoch: 42, Training Step: 300, Loss: 0.8898023366928101, Learning Rate: 6.25e-05
2022-06-11-23_58_48  Epoch: 42, Training Step: 400, Loss: 1.107383131980896, Learning Rate: 6.25e-05
2022-06-11-23_59_15  Epoch: 42, Training Step: 500, Loss: 0.9632580280303955, Learning Rate: 6.25e-05
2022-06-11-23_59_42  Epoch: 42, Training Step: 600, Loss: 0.8607520461082458, Learning Rate: 6.25e-05
2022-06-12-00_00_10  Epoch: 42, Training Step: 700, Loss: 0.9288723468780518, Learning Rate: 6.25e-05
2022-06-12-00_00_37  Epoch: 42, Training Step: 800, Loss: 0.7283220887184143, Learning Rate: 6.25e-05
2022-06-12-00_01_04  Epoch: 42, Training Step: 900, Loss: 0.8636670708656311, Learning Rate: 6.25e-05
2022-06-12-00_01_30  Epoch: 42, Training Step: 1000, Loss: 0.7660636305809021, Learning Rate: 6.25e-05
2022-06-12-00_01_58  Epoch: 42, Training Step: 1100, Loss: 0.8852269649505615, Learning Rate: 6.25e-05
2022-06-12-00_02_25  Epoch: 42, Training Step: 1200, Loss: 0.9043778777122498, Learning Rate: 6.25e-05
2022-06-12-00_02_52  Epoch: 42, Training Step: 1300, Loss: 0.8353132009506226, Learning Rate: 6.25e-05
2022-06-12-00_03_20  Epoch: 42, Training Step: 1400, Loss: 0.8687894940376282, Learning Rate: 6.25e-05
2022-06-12-00_03_47  Epoch: 42, Training Step: 1500, Loss: 0.7782343029975891, Learning Rate: 6.25e-05
2022-06-12-00_04_15  Epoch: 42, Training Step: 1600, Loss: 1.0742707252502441, Learning Rate: 6.25e-05
2022-06-12-00_04_41  Epoch: 42, Training Step: 1700, Loss: 0.8940029740333557, Learning Rate: 6.25e-05
2022-06-12-00_05_09  Epoch: 42, Training Step: 1800, Loss: 0.8849921822547913, Learning Rate: 6.25e-05
2022-06-12-00_05_36  Epoch: 42, Training Step: 1900, Loss: 1.0213544368743896, Learning Rate: 6.25e-05
2022-06-12-00_06_03  Epoch: 42, Training Step: 2000, Loss: 0.7989734411239624, Learning Rate: 6.25e-05
2022-06-12-00_06_30  Epoch: 42, Training Step: 2100, Loss: 0.8088486194610596, Learning Rate: 6.25e-05
2022-06-12-00_06_57  Epoch: 42, Training Step: 2200, Loss: 0.95162433385849, Learning Rate: 6.25e-05
2022-06-12-00_07_23  Epoch: 42, Training Step: 2300, Loss: 0.8110201358795166, Learning Rate: 6.25e-05
2022-06-12-00_07_50  Epoch: 42, Training Step: 2400, Loss: 0.920369565486908, Learning Rate: 6.25e-05
2022-06-12-00_08_17  Epoch: 42, Training Step: 2500, Loss: 0.8753979206085205, Learning Rate: 6.25e-05
2022-06-12-00_08_45  Epoch: 42, Training Step: 2600, Loss: 0.8494988679885864, Learning Rate: 6.25e-05
2022-06-12-00_09_11  Epoch: 42, Training Step: 2700, Loss: 0.8908437490463257, Learning Rate: 6.25e-05
2022-06-12-00_09_39  Epoch: 42, Training Step: 2800, Loss: 0.783178448677063, Learning Rate: 6.25e-05
2022-06-12-00_10_06  Epoch: 42, Training Step: 2900, Loss: 0.6967076063156128, Learning Rate: 6.25e-05
2022-06-12-00_10_33  Epoch: 42, Training Step: 3000, Loss: 0.897792637348175, Learning Rate: 6.25e-05
2022-06-12-00_11_00  Epoch: 42, Training Step: 3100, Loss: 0.6663957834243774, Learning Rate: 6.25e-05
2022-06-12-00_11_27  Epoch: 42, Training Step: 3200, Loss: 0.7070255279541016, Learning Rate: 6.25e-05
2022-06-12-00_14_30  Epoch: 43, Training Step: 0, Loss: 0.8073984384536743, Learning Rate: 6.25e-05
2022-06-12-00_14_57  Epoch: 43, Training Step: 100, Loss: 1.0094032287597656, Learning Rate: 6.25e-05
2022-06-12-00_15_23  Epoch: 43, Training Step: 200, Loss: 0.819766640663147, Learning Rate: 6.25e-05
2022-06-12-00_15_50  Epoch: 43, Training Step: 300, Loss: 0.9648663997650146, Learning Rate: 6.25e-05
2022-06-12-00_16_18  Epoch: 43, Training Step: 400, Loss: 0.8162301778793335, Learning Rate: 6.25e-05
2022-06-12-00_16_45  Epoch: 43, Training Step: 500, Loss: 1.1404398679733276, Learning Rate: 6.25e-05
2022-06-12-00_17_12  Epoch: 43, Training Step: 600, Loss: 0.8740176558494568, Learning Rate: 6.25e-05
2022-06-12-00_17_40  Epoch: 43, Training Step: 700, Loss: 0.9200564026832581, Learning Rate: 6.25e-05
2022-06-12-00_18_08  Epoch: 43, Training Step: 800, Loss: 0.9241465926170349, Learning Rate: 6.25e-05
2022-06-12-00_18_35  Epoch: 43, Training Step: 900, Loss: 0.904729962348938, Learning Rate: 6.25e-05
2022-06-12-00_19_02  Epoch: 43, Training Step: 1000, Loss: 0.8672870993614197, Learning Rate: 6.25e-05
2022-06-12-00_19_29  Epoch: 43, Training Step: 1100, Loss: 0.7982662916183472, Learning Rate: 6.25e-05
2022-06-12-00_19_56  Epoch: 43, Training Step: 1200, Loss: 0.8552737832069397, Learning Rate: 6.25e-05
2022-06-12-00_20_25  Epoch: 43, Training Step: 1300, Loss: 0.8723077178001404, Learning Rate: 6.25e-05
2022-06-12-00_20_52  Epoch: 43, Training Step: 1400, Loss: 0.6960334777832031, Learning Rate: 6.25e-05
2022-06-12-00_21_20  Epoch: 43, Training Step: 1500, Loss: 1.0962979793548584, Learning Rate: 6.25e-05
2022-06-12-00_21_47  Epoch: 43, Training Step: 1600, Loss: 0.8523000478744507, Learning Rate: 6.25e-05
2022-06-12-00_22_14  Epoch: 43, Training Step: 1700, Loss: 1.175668478012085, Learning Rate: 6.25e-05
2022-06-12-00_22_41  Epoch: 43, Training Step: 1800, Loss: 1.0102558135986328, Learning Rate: 6.25e-05
2022-06-12-00_23_09  Epoch: 43, Training Step: 1900, Loss: 1.0074833631515503, Learning Rate: 6.25e-05
2022-06-12-00_23_36  Epoch: 43, Training Step: 2000, Loss: 0.9622515439987183, Learning Rate: 6.25e-05
2022-06-12-00_24_04  Epoch: 43, Training Step: 2100, Loss: 0.8009833097457886, Learning Rate: 6.25e-05
2022-06-12-00_24_31  Epoch: 43, Training Step: 2200, Loss: 1.0746210813522339, Learning Rate: 6.25e-05
2022-06-12-00_24_58  Epoch: 43, Training Step: 2300, Loss: 0.8683133125305176, Learning Rate: 6.25e-05
2022-06-12-00_25_26  Epoch: 43, Training Step: 2400, Loss: 0.9595528244972229, Learning Rate: 6.25e-05
2022-06-12-00_25_53  Epoch: 43, Training Step: 2500, Loss: 0.9099496603012085, Learning Rate: 6.25e-05
2022-06-12-00_26_20  Epoch: 43, Training Step: 2600, Loss: 0.8303593993186951, Learning Rate: 6.25e-05
2022-06-12-00_26_47  Epoch: 43, Training Step: 2700, Loss: 1.183638334274292, Learning Rate: 6.25e-05
2022-06-12-00_27_14  Epoch: 43, Training Step: 2800, Loss: 1.2250633239746094, Learning Rate: 6.25e-05
2022-06-12-00_27_41  Epoch: 43, Training Step: 2900, Loss: 0.962096631526947, Learning Rate: 6.25e-05
2022-06-12-00_28_08  Epoch: 43, Training Step: 3000, Loss: 1.1013216972351074, Learning Rate: 6.25e-05
2022-06-12-00_28_35  Epoch: 43, Training Step: 3100, Loss: 0.8552319407463074, Learning Rate: 6.25e-05
2022-06-12-00_29_02  Epoch: 43, Training Step: 3200, Loss: 0.7546924948692322, Learning Rate: 6.25e-05
2022-06-12-00_32_07  Epoch: 44, Training Step: 0, Loss: 0.7404696345329285, Learning Rate: 6.25e-05
2022-06-12-00_32_33  Epoch: 44, Training Step: 100, Loss: 0.872718095779419, Learning Rate: 6.25e-05
2022-06-12-00_33_00  Epoch: 44, Training Step: 200, Loss: 0.8108270764350891, Learning Rate: 6.25e-05
2022-06-12-00_33_28  Epoch: 44, Training Step: 300, Loss: 1.124476432800293, Learning Rate: 6.25e-05
2022-06-12-00_33_55  Epoch: 44, Training Step: 400, Loss: 0.8258832693099976, Learning Rate: 6.25e-05
2022-06-12-00_34_22  Epoch: 44, Training Step: 500, Loss: 1.0521202087402344, Learning Rate: 6.25e-05
2022-06-12-00_34_49  Epoch: 44, Training Step: 600, Loss: 0.7432891726493835, Learning Rate: 6.25e-05
2022-06-12-00_35_16  Epoch: 44, Training Step: 700, Loss: 0.853096604347229, Learning Rate: 6.25e-05
2022-06-12-00_35_43  Epoch: 44, Training Step: 800, Loss: 0.7254366278648376, Learning Rate: 6.25e-05
2022-06-12-00_36_11  Epoch: 44, Training Step: 900, Loss: 0.8732860088348389, Learning Rate: 6.25e-05
2022-06-12-00_36_38  Epoch: 44, Training Step: 1000, Loss: 0.8217312097549438, Learning Rate: 6.25e-05
2022-06-12-00_37_05  Epoch: 44, Training Step: 1100, Loss: 0.8046842813491821, Learning Rate: 6.25e-05
2022-06-12-00_37_33  Epoch: 44, Training Step: 1200, Loss: 0.6921611428260803, Learning Rate: 6.25e-05
2022-06-12-00_37_59  Epoch: 44, Training Step: 1300, Loss: 1.2344506978988647, Learning Rate: 6.25e-05
2022-06-12-00_38_26  Epoch: 44, Training Step: 1400, Loss: 0.7362496852874756, Learning Rate: 6.25e-05
2022-06-12-00_38_53  Epoch: 44, Training Step: 1500, Loss: 0.7271660566329956, Learning Rate: 6.25e-05
2022-06-12-00_39_20  Epoch: 44, Training Step: 1600, Loss: 0.8049279451370239, Learning Rate: 6.25e-05
2022-06-12-00_39_48  Epoch: 44, Training Step: 1700, Loss: 0.8729250431060791, Learning Rate: 6.25e-05
2022-06-12-00_40_15  Epoch: 44, Training Step: 1800, Loss: 0.7453538179397583, Learning Rate: 6.25e-05
2022-06-12-00_40_42  Epoch: 44, Training Step: 1900, Loss: 0.7994369864463806, Learning Rate: 6.25e-05
2022-06-12-00_41_09  Epoch: 44, Training Step: 2000, Loss: 0.6579374670982361, Learning Rate: 6.25e-05
2022-06-12-00_41_37  Epoch: 44, Training Step: 2100, Loss: 0.6858291625976562, Learning Rate: 6.25e-05
2022-06-12-00_42_05  Epoch: 44, Training Step: 2200, Loss: 0.8137428760528564, Learning Rate: 6.25e-05
2022-06-12-00_42_32  Epoch: 44, Training Step: 2300, Loss: 0.8940929770469666, Learning Rate: 6.25e-05
2022-06-12-00_42_59  Epoch: 44, Training Step: 2400, Loss: 0.8738229274749756, Learning Rate: 6.25e-05
2022-06-12-00_43_27  Epoch: 44, Training Step: 2500, Loss: 0.8329092264175415, Learning Rate: 6.25e-05
2022-06-12-00_43_54  Epoch: 44, Training Step: 2600, Loss: 1.0439045429229736, Learning Rate: 6.25e-05
2022-06-12-00_44_21  Epoch: 44, Training Step: 2700, Loss: 0.7606196403503418, Learning Rate: 6.25e-05
2022-06-12-00_44_48  Epoch: 44, Training Step: 2800, Loss: 0.8435570001602173, Learning Rate: 6.25e-05
2022-06-12-00_45_16  Epoch: 44, Training Step: 2900, Loss: 0.9045331478118896, Learning Rate: 6.25e-05
2022-06-12-00_45_43  Epoch: 44, Training Step: 3000, Loss: 1.02479088306427, Learning Rate: 6.25e-05
2022-06-12-00_46_10  Epoch: 44, Training Step: 3100, Loss: 1.0340070724487305, Learning Rate: 6.25e-05
2022-06-12-00_46_37  Epoch: 44, Training Step: 3200, Loss: 0.7522020936012268, Learning Rate: 6.25e-05
2022-06-12-00_49_39  Epoch: 45, Training Step: 0, Loss: 0.8844631910324097, Learning Rate: 6.25e-05
2022-06-12-00_50_06  Epoch: 45, Training Step: 100, Loss: 0.8543038368225098, Learning Rate: 6.25e-05
2022-06-12-00_50_32  Epoch: 45, Training Step: 200, Loss: 0.8142261505126953, Learning Rate: 6.25e-05
2022-06-12-00_50_59  Epoch: 45, Training Step: 300, Loss: 0.9325891137123108, Learning Rate: 6.25e-05
2022-06-12-00_51_27  Epoch: 45, Training Step: 400, Loss: 0.8166831731796265, Learning Rate: 6.25e-05
2022-06-12-00_51_54  Epoch: 45, Training Step: 500, Loss: 0.9924242496490479, Learning Rate: 6.25e-05
2022-06-12-00_52_20  Epoch: 45, Training Step: 600, Loss: 0.7921148538589478, Learning Rate: 6.25e-05
2022-06-12-00_52_47  Epoch: 45, Training Step: 700, Loss: 0.8683629035949707, Learning Rate: 6.25e-05
2022-06-12-00_53_14  Epoch: 45, Training Step: 800, Loss: 0.8119634389877319, Learning Rate: 6.25e-05
2022-06-12-00_53_41  Epoch: 45, Training Step: 900, Loss: 1.019721508026123, Learning Rate: 6.25e-05
2022-06-12-00_54_09  Epoch: 45, Training Step: 1000, Loss: 0.9055252075195312, Learning Rate: 6.25e-05
2022-06-12-00_54_36  Epoch: 45, Training Step: 1100, Loss: 0.7498995065689087, Learning Rate: 6.25e-05
2022-06-12-00_55_03  Epoch: 45, Training Step: 1200, Loss: 0.9184561371803284, Learning Rate: 6.25e-05
2022-06-12-00_55_30  Epoch: 45, Training Step: 1300, Loss: 0.9300345182418823, Learning Rate: 6.25e-05
2022-06-12-00_55_57  Epoch: 45, Training Step: 1400, Loss: 0.6518152952194214, Learning Rate: 6.25e-05
2022-06-12-00_56_25  Epoch: 45, Training Step: 1500, Loss: 0.8646877408027649, Learning Rate: 6.25e-05
2022-06-12-00_56_51  Epoch: 45, Training Step: 1600, Loss: 0.8413746356964111, Learning Rate: 6.25e-05
2022-06-12-00_57_18  Epoch: 45, Training Step: 1700, Loss: 0.8360850811004639, Learning Rate: 6.25e-05
2022-06-12-00_57_45  Epoch: 45, Training Step: 1800, Loss: 1.440039873123169, Learning Rate: 6.25e-05
2022-06-12-00_58_13  Epoch: 45, Training Step: 1900, Loss: 0.8902511596679688, Learning Rate: 6.25e-05
2022-06-12-00_58_39  Epoch: 45, Training Step: 2000, Loss: 0.8643779754638672, Learning Rate: 6.25e-05
2022-06-12-00_59_06  Epoch: 45, Training Step: 2100, Loss: 0.7702398300170898, Learning Rate: 6.25e-05
2022-06-12-00_59_33  Epoch: 45, Training Step: 2200, Loss: 0.8065152168273926, Learning Rate: 6.25e-05
2022-06-12-01_00_00  Epoch: 45, Training Step: 2300, Loss: 1.0677692890167236, Learning Rate: 6.25e-05
2022-06-12-01_00_27  Epoch: 45, Training Step: 2400, Loss: 0.7439135313034058, Learning Rate: 6.25e-05
2022-06-12-01_00_54  Epoch: 45, Training Step: 2500, Loss: 0.8436087369918823, Learning Rate: 6.25e-05
2022-06-12-01_01_21  Epoch: 45, Training Step: 2600, Loss: 1.2144734859466553, Learning Rate: 6.25e-05
2022-06-12-01_01_49  Epoch: 45, Training Step: 2700, Loss: 0.8508630990982056, Learning Rate: 6.25e-05
2022-06-12-01_02_16  Epoch: 45, Training Step: 2800, Loss: 0.9791079163551331, Learning Rate: 6.25e-05
2022-06-12-01_02_43  Epoch: 45, Training Step: 2900, Loss: 1.0514194965362549, Learning Rate: 6.25e-05
2022-06-12-01_03_10  Epoch: 45, Training Step: 3000, Loss: 1.152587890625, Learning Rate: 6.25e-05
2022-06-12-01_03_37  Epoch: 45, Training Step: 3100, Loss: 0.7347607612609863, Learning Rate: 6.25e-05
2022-06-12-01_04_04  Epoch: 45, Training Step: 3200, Loss: 1.0780372619628906, Learning Rate: 6.25e-05
2022-06-12-01_07_01  Epoch: 46, Training Step: 0, Loss: 0.9748823642730713, Learning Rate: 6.25e-05
2022-06-12-01_07_27  Epoch: 46, Training Step: 100, Loss: 0.7756438851356506, Learning Rate: 6.25e-05
2022-06-12-01_07_54  Epoch: 46, Training Step: 200, Loss: 0.7660658359527588, Learning Rate: 6.25e-05
2022-06-12-01_08_21  Epoch: 46, Training Step: 300, Loss: 0.7639565467834473, Learning Rate: 6.25e-05
2022-06-12-01_08_48  Epoch: 46, Training Step: 400, Loss: 0.8110992908477783, Learning Rate: 6.25e-05
2022-06-12-01_09_15  Epoch: 46, Training Step: 500, Loss: 0.7846798896789551, Learning Rate: 6.25e-05
2022-06-12-01_09_42  Epoch: 46, Training Step: 600, Loss: 0.7692000865936279, Learning Rate: 6.25e-05
2022-06-12-01_10_09  Epoch: 46, Training Step: 700, Loss: 0.9194573163986206, Learning Rate: 6.25e-05
2022-06-12-01_10_36  Epoch: 46, Training Step: 800, Loss: 0.8597099781036377, Learning Rate: 6.25e-05
2022-06-12-01_11_03  Epoch: 46, Training Step: 900, Loss: 0.815990686416626, Learning Rate: 6.25e-05
2022-06-12-01_11_30  Epoch: 46, Training Step: 1000, Loss: 0.7773833274841309, Learning Rate: 6.25e-05
2022-06-12-01_11_57  Epoch: 46, Training Step: 1100, Loss: 0.8240829706192017, Learning Rate: 6.25e-05
2022-06-12-01_12_24  Epoch: 46, Training Step: 1200, Loss: 0.8638907074928284, Learning Rate: 6.25e-05
2022-06-12-01_12_51  Epoch: 46, Training Step: 1300, Loss: 0.7961182594299316, Learning Rate: 6.25e-05
2022-06-12-01_13_19  Epoch: 46, Training Step: 1400, Loss: 0.7322272658348083, Learning Rate: 6.25e-05
2022-06-12-01_13_46  Epoch: 46, Training Step: 1500, Loss: 0.8401719331741333, Learning Rate: 6.25e-05
2022-06-12-01_14_13  Epoch: 46, Training Step: 1600, Loss: 0.9512969255447388, Learning Rate: 6.25e-05
2022-06-12-01_14_40  Epoch: 46, Training Step: 1700, Loss: 0.7586396336555481, Learning Rate: 6.25e-05
2022-06-12-01_15_07  Epoch: 46, Training Step: 1800, Loss: 0.6937196850776672, Learning Rate: 6.25e-05
2022-06-12-01_15_34  Epoch: 46, Training Step: 1900, Loss: 0.8536505699157715, Learning Rate: 6.25e-05
2022-06-12-01_16_01  Epoch: 46, Training Step: 2000, Loss: 0.7402044534683228, Learning Rate: 6.25e-05
2022-06-12-01_16_28  Epoch: 46, Training Step: 2100, Loss: 0.7640736103057861, Learning Rate: 6.25e-05
2022-06-12-01_16_56  Epoch: 46, Training Step: 2200, Loss: 0.965293288230896, Learning Rate: 6.25e-05
2022-06-12-01_17_23  Epoch: 46, Training Step: 2300, Loss: 0.8645187616348267, Learning Rate: 6.25e-05
2022-06-12-01_17_50  Epoch: 46, Training Step: 2400, Loss: 0.770906925201416, Learning Rate: 6.25e-05
2022-06-12-01_18_17  Epoch: 46, Training Step: 2500, Loss: 0.9677406549453735, Learning Rate: 6.25e-05
2022-06-12-01_18_44  Epoch: 46, Training Step: 2600, Loss: 0.756959080696106, Learning Rate: 6.25e-05
2022-06-12-01_19_11  Epoch: 46, Training Step: 2700, Loss: 1.0497431755065918, Learning Rate: 6.25e-05
2022-06-12-01_19_39  Epoch: 46, Training Step: 2800, Loss: 0.7952247858047485, Learning Rate: 6.25e-05
2022-06-12-01_20_06  Epoch: 46, Training Step: 2900, Loss: 0.6847403049468994, Learning Rate: 6.25e-05
2022-06-12-01_20_33  Epoch: 46, Training Step: 3000, Loss: 0.907419741153717, Learning Rate: 6.25e-05
2022-06-12-01_20_59  Epoch: 46, Training Step: 3100, Loss: 1.0073471069335938, Learning Rate: 6.25e-05
2022-06-12-01_21_26  Epoch: 46, Training Step: 3200, Loss: 0.8415652513504028, Learning Rate: 6.25e-05
2022-06-12-01_24_26  Epoch: 47, Training Step: 0, Loss: 0.9647861123085022, Learning Rate: 6.25e-05
2022-06-12-01_24_53  Epoch: 47, Training Step: 100, Loss: 0.7506555318832397, Learning Rate: 6.25e-05
2022-06-12-01_25_19  Epoch: 47, Training Step: 200, Loss: 0.7848193049430847, Learning Rate: 6.25e-05
2022-06-12-01_25_47  Epoch: 47, Training Step: 300, Loss: 1.269752860069275, Learning Rate: 6.25e-05
2022-06-12-01_26_14  Epoch: 47, Training Step: 400, Loss: 0.8784148097038269, Learning Rate: 6.25e-05
2022-06-12-01_26_41  Epoch: 47, Training Step: 500, Loss: 0.9775700569152832, Learning Rate: 6.25e-05
2022-06-12-01_27_08  Epoch: 47, Training Step: 600, Loss: 0.892494797706604, Learning Rate: 6.25e-05
2022-06-12-01_27_34  Epoch: 47, Training Step: 700, Loss: 0.9886285066604614, Learning Rate: 6.25e-05
2022-06-12-01_28_01  Epoch: 47, Training Step: 800, Loss: 0.8083218336105347, Learning Rate: 6.25e-05
2022-06-12-01_28_29  Epoch: 47, Training Step: 900, Loss: 0.8994783163070679, Learning Rate: 6.25e-05
2022-06-12-01_28_56  Epoch: 47, Training Step: 1000, Loss: 0.8340847492218018, Learning Rate: 6.25e-05
2022-06-12-01_29_23  Epoch: 47, Training Step: 1100, Loss: 0.8848559856414795, Learning Rate: 6.25e-05
2022-06-12-01_29_51  Epoch: 47, Training Step: 1200, Loss: 0.9180721044540405, Learning Rate: 6.25e-05
2022-06-12-01_30_18  Epoch: 47, Training Step: 1300, Loss: 0.7143244743347168, Learning Rate: 6.25e-05
2022-06-12-01_30_45  Epoch: 47, Training Step: 1400, Loss: 0.9132274389266968, Learning Rate: 6.25e-05
2022-06-12-01_31_12  Epoch: 47, Training Step: 1500, Loss: 1.2004623413085938, Learning Rate: 6.25e-05
2022-06-12-01_31_39  Epoch: 47, Training Step: 1600, Loss: 0.9313943386077881, Learning Rate: 6.25e-05
2022-06-12-01_32_06  Epoch: 47, Training Step: 1700, Loss: 1.1980595588684082, Learning Rate: 6.25e-05
2022-06-12-01_32_34  Epoch: 47, Training Step: 1800, Loss: 0.7476207613945007, Learning Rate: 6.25e-05
2022-06-12-01_33_01  Epoch: 47, Training Step: 1900, Loss: 0.8655279278755188, Learning Rate: 6.25e-05
2022-06-12-01_33_29  Epoch: 47, Training Step: 2000, Loss: 0.7196485996246338, Learning Rate: 6.25e-05
2022-06-12-01_33_57  Epoch: 47, Training Step: 2100, Loss: 0.7337096929550171, Learning Rate: 6.25e-05
2022-06-12-01_34_25  Epoch: 47, Training Step: 2200, Loss: 0.8291623592376709, Learning Rate: 6.25e-05
2022-06-12-01_34_51  Epoch: 47, Training Step: 2300, Loss: 0.7327580451965332, Learning Rate: 6.25e-05
2022-06-12-01_35_19  Epoch: 47, Training Step: 2400, Loss: 1.3682740926742554, Learning Rate: 6.25e-05
2022-06-12-01_35_46  Epoch: 47, Training Step: 2500, Loss: 0.8703289031982422, Learning Rate: 6.25e-05
2022-06-12-01_36_14  Epoch: 47, Training Step: 2600, Loss: 0.7330816388130188, Learning Rate: 6.25e-05
2022-06-12-01_36_40  Epoch: 47, Training Step: 2700, Loss: 0.864316463470459, Learning Rate: 6.25e-05
2022-06-12-01_37_07  Epoch: 47, Training Step: 2800, Loss: 0.8072002530097961, Learning Rate: 6.25e-05
2022-06-12-01_37_34  Epoch: 47, Training Step: 2900, Loss: 0.7880430221557617, Learning Rate: 6.25e-05
2022-06-12-01_38_01  Epoch: 47, Training Step: 3000, Loss: 0.8421894311904907, Learning Rate: 6.25e-05
2022-06-12-01_38_29  Epoch: 47, Training Step: 3100, Loss: 0.7981270551681519, Learning Rate: 6.25e-05
2022-06-12-01_38_55  Epoch: 47, Training Step: 3200, Loss: 0.8808261752128601, Learning Rate: 6.25e-05
2022-06-12-01_42_03  Epoch: 48, Training Step: 0, Loss: 0.809022068977356, Learning Rate: 6.25e-05
2022-06-12-01_42_30  Epoch: 48, Training Step: 100, Loss: 0.9853792190551758, Learning Rate: 6.25e-05
2022-06-12-01_42_57  Epoch: 48, Training Step: 200, Loss: 0.7593026161193848, Learning Rate: 6.25e-05
2022-06-12-01_43_24  Epoch: 48, Training Step: 300, Loss: 0.8557202816009521, Learning Rate: 6.25e-05
2022-06-12-01_43_51  Epoch: 48, Training Step: 400, Loss: 0.7518710494041443, Learning Rate: 6.25e-05
2022-06-12-01_44_18  Epoch: 48, Training Step: 500, Loss: 0.7957769632339478, Learning Rate: 6.25e-05
2022-06-12-01_44_45  Epoch: 48, Training Step: 600, Loss: 0.964535653591156, Learning Rate: 6.25e-05
2022-06-12-01_45_13  Epoch: 48, Training Step: 700, Loss: 0.8037853240966797, Learning Rate: 6.25e-05
2022-06-12-01_45_41  Epoch: 48, Training Step: 800, Loss: 0.9743736982345581, Learning Rate: 6.25e-05
2022-06-12-01_46_09  Epoch: 48, Training Step: 900, Loss: 0.9870485067367554, Learning Rate: 6.25e-05
2022-06-12-01_46_37  Epoch: 48, Training Step: 1000, Loss: 0.8681106567382812, Learning Rate: 6.25e-05
2022-06-12-01_47_04  Epoch: 48, Training Step: 1100, Loss: 0.8279588222503662, Learning Rate: 6.25e-05
2022-06-12-01_47_31  Epoch: 48, Training Step: 1200, Loss: 0.9670326113700867, Learning Rate: 6.25e-05
2022-06-12-01_47_58  Epoch: 48, Training Step: 1300, Loss: 0.8823281526565552, Learning Rate: 6.25e-05
2022-06-12-01_48_25  Epoch: 48, Training Step: 1400, Loss: 0.7580034732818604, Learning Rate: 6.25e-05
2022-06-12-01_48_52  Epoch: 48, Training Step: 1500, Loss: 0.9557831287384033, Learning Rate: 6.25e-05
2022-06-12-01_49_20  Epoch: 48, Training Step: 1600, Loss: 0.8620928525924683, Learning Rate: 6.25e-05
2022-06-12-01_49_47  Epoch: 48, Training Step: 1700, Loss: 1.1821424961090088, Learning Rate: 6.25e-05
2022-06-12-01_50_15  Epoch: 48, Training Step: 1800, Loss: 0.7689695358276367, Learning Rate: 6.25e-05
2022-06-12-01_50_42  Epoch: 48, Training Step: 1900, Loss: 0.9389303922653198, Learning Rate: 6.25e-05
2022-06-12-01_51_10  Epoch: 48, Training Step: 2000, Loss: 0.8921616673469543, Learning Rate: 6.25e-05
2022-06-12-01_51_36  Epoch: 48, Training Step: 2100, Loss: 0.8091363906860352, Learning Rate: 6.25e-05
2022-06-12-01_52_03  Epoch: 48, Training Step: 2200, Loss: 1.0514142513275146, Learning Rate: 6.25e-05
2022-06-12-01_52_30  Epoch: 48, Training Step: 2300, Loss: 0.90705806016922, Learning Rate: 6.25e-05
2022-06-12-01_52_57  Epoch: 48, Training Step: 2400, Loss: 0.9404730200767517, Learning Rate: 6.25e-05
2022-06-12-01_53_24  Epoch: 48, Training Step: 2500, Loss: 0.7786328196525574, Learning Rate: 6.25e-05
2022-06-12-01_53_51  Epoch: 48, Training Step: 2600, Loss: 0.9040403366088867, Learning Rate: 6.25e-05
2022-06-12-01_54_19  Epoch: 48, Training Step: 2700, Loss: 0.785162627696991, Learning Rate: 6.25e-05
2022-06-12-01_54_46  Epoch: 48, Training Step: 2800, Loss: 0.7779343128204346, Learning Rate: 6.25e-05
2022-06-12-01_55_13  Epoch: 48, Training Step: 2900, Loss: 1.0919458866119385, Learning Rate: 6.25e-05
2022-06-12-01_55_40  Epoch: 48, Training Step: 3000, Loss: 0.7104207277297974, Learning Rate: 6.25e-05
2022-06-12-01_56_07  Epoch: 48, Training Step: 3100, Loss: 0.7201714515686035, Learning Rate: 6.25e-05
2022-06-12-01_56_34  Epoch: 48, Training Step: 3200, Loss: 0.9942306280136108, Learning Rate: 6.25e-05
2022-06-12-01_59_34  Epoch: 49, Training Step: 0, Loss: 0.7092026472091675, Learning Rate: 6.25e-05
2022-06-12-02_00_00  Epoch: 49, Training Step: 100, Loss: 0.9412117004394531, Learning Rate: 6.25e-05
2022-06-12-02_00_27  Epoch: 49, Training Step: 200, Loss: 0.7888604998588562, Learning Rate: 6.25e-05
2022-06-12-02_00_53  Epoch: 49, Training Step: 300, Loss: 0.8097448945045471, Learning Rate: 6.25e-05
2022-06-12-02_01_20  Epoch: 49, Training Step: 400, Loss: 0.8351122140884399, Learning Rate: 6.25e-05
2022-06-12-02_01_48  Epoch: 49, Training Step: 500, Loss: 0.7726148366928101, Learning Rate: 6.25e-05
2022-06-12-02_02_14  Epoch: 49, Training Step: 600, Loss: 0.8856651782989502, Learning Rate: 6.25e-05
2022-06-12-02_02_41  Epoch: 49, Training Step: 700, Loss: 0.9999424815177917, Learning Rate: 6.25e-05
2022-06-12-02_03_08  Epoch: 49, Training Step: 800, Loss: 1.0497785806655884, Learning Rate: 6.25e-05
2022-06-12-02_03_36  Epoch: 49, Training Step: 900, Loss: 0.9427759647369385, Learning Rate: 6.25e-05
2022-06-12-02_04_03  Epoch: 49, Training Step: 1000, Loss: 0.8385639190673828, Learning Rate: 6.25e-05
2022-06-12-02_04_30  Epoch: 49, Training Step: 1100, Loss: 0.7765993475914001, Learning Rate: 6.25e-05
2022-06-12-02_04_57  Epoch: 49, Training Step: 1200, Loss: 0.9422476887702942, Learning Rate: 6.25e-05
2022-06-12-02_05_24  Epoch: 49, Training Step: 1300, Loss: 0.830399751663208, Learning Rate: 6.25e-05
2022-06-12-02_05_51  Epoch: 49, Training Step: 1400, Loss: 1.054277777671814, Learning Rate: 6.25e-05
2022-06-12-02_06_18  Epoch: 49, Training Step: 1500, Loss: 0.9451398849487305, Learning Rate: 6.25e-05
2022-06-12-02_06_45  Epoch: 49, Training Step: 1600, Loss: 0.8301129341125488, Learning Rate: 6.25e-05
2022-06-12-02_07_12  Epoch: 49, Training Step: 1700, Loss: 0.9432960152626038, Learning Rate: 6.25e-05
2022-06-12-02_07_39  Epoch: 49, Training Step: 1800, Loss: 0.8571578860282898, Learning Rate: 6.25e-05
2022-06-12-02_08_06  Epoch: 49, Training Step: 1900, Loss: 0.6828075051307678, Learning Rate: 6.25e-05
2022-06-12-02_08_34  Epoch: 49, Training Step: 2000, Loss: 0.8586134910583496, Learning Rate: 6.25e-05
2022-06-12-02_09_02  Epoch: 49, Training Step: 2100, Loss: 0.7624460458755493, Learning Rate: 6.25e-05
2022-06-12-02_09_28  Epoch: 49, Training Step: 2200, Loss: 0.7425589561462402, Learning Rate: 6.25e-05
2022-06-12-02_09_56  Epoch: 49, Training Step: 2300, Loss: 0.7137418985366821, Learning Rate: 6.25e-05
2022-06-12-02_10_23  Epoch: 49, Training Step: 2400, Loss: 1.0859706401824951, Learning Rate: 6.25e-05
2022-06-12-02_10_51  Epoch: 49, Training Step: 2500, Loss: 0.813585638999939, Learning Rate: 6.25e-05
2022-06-12-02_11_18  Epoch: 49, Training Step: 2600, Loss: 0.8270605802536011, Learning Rate: 6.25e-05
2022-06-12-02_11_46  Epoch: 49, Training Step: 2700, Loss: 0.8307135105133057, Learning Rate: 6.25e-05
2022-06-12-02_12_13  Epoch: 49, Training Step: 2800, Loss: 0.8471084833145142, Learning Rate: 6.25e-05
2022-06-12-02_12_40  Epoch: 49, Training Step: 2900, Loss: 0.8282585144042969, Learning Rate: 6.25e-05
2022-06-12-02_13_07  Epoch: 49, Training Step: 3000, Loss: 0.7885725498199463, Learning Rate: 6.25e-05
2022-06-12-02_13_35  Epoch: 49, Training Step: 3100, Loss: 0.9106813669204712, Learning Rate: 6.25e-05
2022-06-12-02_14_01  Epoch: 49, Training Step: 3200, Loss: 0.8499017953872681, Learning Rate: 6.25e-05
2022-06-12-02_17_05  Epoch: 50, Training Step: 0, Loss: 0.9579184055328369, Learning Rate: 3.125e-05
2022-06-12-02_17_33  Epoch: 50, Training Step: 100, Loss: 0.7725305557250977, Learning Rate: 3.125e-05
2022-06-12-02_18_00  Epoch: 50, Training Step: 200, Loss: 0.813147783279419, Learning Rate: 3.125e-05
2022-06-12-02_18_26  Epoch: 50, Training Step: 300, Loss: 0.8771581649780273, Learning Rate: 3.125e-05
2022-06-12-02_18_54  Epoch: 50, Training Step: 400, Loss: 0.7885425686836243, Learning Rate: 3.125e-05
2022-06-12-02_19_22  Epoch: 50, Training Step: 500, Loss: 0.6902363300323486, Learning Rate: 3.125e-05
2022-06-12-02_19_49  Epoch: 50, Training Step: 600, Loss: 0.8572132587432861, Learning Rate: 3.125e-05
2022-06-12-02_20_17  Epoch: 50, Training Step: 700, Loss: 0.8189560174942017, Learning Rate: 3.125e-05
2022-06-12-02_20_44  Epoch: 50, Training Step: 800, Loss: 0.848207950592041, Learning Rate: 3.125e-05
2022-06-12-02_21_12  Epoch: 50, Training Step: 900, Loss: 0.9066947102546692, Learning Rate: 3.125e-05
2022-06-12-02_21_38  Epoch: 50, Training Step: 1000, Loss: 0.8836425542831421, Learning Rate: 3.125e-05
2022-06-12-02_22_05  Epoch: 50, Training Step: 1100, Loss: 0.9453224539756775, Learning Rate: 3.125e-05
2022-06-12-02_22_32  Epoch: 50, Training Step: 1200, Loss: 0.8476535081863403, Learning Rate: 3.125e-05
2022-06-12-02_22_59  Epoch: 50, Training Step: 1300, Loss: 0.8588254451751709, Learning Rate: 3.125e-05
2022-06-12-02_23_26  Epoch: 50, Training Step: 1400, Loss: 0.6227418184280396, Learning Rate: 3.125e-05
2022-06-12-02_23_53  Epoch: 50, Training Step: 1500, Loss: 0.9000284075737, Learning Rate: 3.125e-05
2022-06-12-02_24_21  Epoch: 50, Training Step: 1600, Loss: 0.9922530651092529, Learning Rate: 3.125e-05
2022-06-12-02_24_48  Epoch: 50, Training Step: 1700, Loss: 0.9490017890930176, Learning Rate: 3.125e-05
2022-06-12-02_25_15  Epoch: 50, Training Step: 1800, Loss: 0.8797361254692078, Learning Rate: 3.125e-05
2022-06-12-02_25_42  Epoch: 50, Training Step: 1900, Loss: 0.8494244813919067, Learning Rate: 3.125e-05
2022-06-12-02_26_09  Epoch: 50, Training Step: 2000, Loss: 1.0781296491622925, Learning Rate: 3.125e-05
2022-06-12-02_26_36  Epoch: 50, Training Step: 2100, Loss: 0.7525725364685059, Learning Rate: 3.125e-05
2022-06-12-02_27_03  Epoch: 50, Training Step: 2200, Loss: 0.8773324489593506, Learning Rate: 3.125e-05
2022-06-12-02_27_31  Epoch: 50, Training Step: 2300, Loss: 0.8434651494026184, Learning Rate: 3.125e-05
2022-06-12-02_27_58  Epoch: 50, Training Step: 2400, Loss: 0.8994027972221375, Learning Rate: 3.125e-05
2022-06-12-02_28_25  Epoch: 50, Training Step: 2500, Loss: 0.7212586402893066, Learning Rate: 3.125e-05
2022-06-12-02_28_52  Epoch: 50, Training Step: 2600, Loss: 0.9633779525756836, Learning Rate: 3.125e-05
2022-06-12-02_29_18  Epoch: 50, Training Step: 2700, Loss: 0.8940168619155884, Learning Rate: 3.125e-05
2022-06-12-02_29_45  Epoch: 50, Training Step: 2800, Loss: 0.7431294918060303, Learning Rate: 3.125e-05
2022-06-12-02_30_12  Epoch: 50, Training Step: 2900, Loss: 0.9369167685508728, Learning Rate: 3.125e-05
2022-06-12-02_30_40  Epoch: 50, Training Step: 3000, Loss: 0.7348295450210571, Learning Rate: 3.125e-05
2022-06-12-02_31_08  Epoch: 50, Training Step: 3100, Loss: 1.0133650302886963, Learning Rate: 3.125e-05
2022-06-12-02_31_35  Epoch: 50, Training Step: 3200, Loss: 0.6642633080482483, Learning Rate: 3.125e-05
2022-06-12-02_34_37  Epoch: 51, Training Step: 0, Loss: 0.9912567138671875, Learning Rate: 3.125e-05
2022-06-12-02_35_04  Epoch: 51, Training Step: 100, Loss: 0.8010666370391846, Learning Rate: 3.125e-05
2022-06-12-02_35_31  Epoch: 51, Training Step: 200, Loss: 0.8175521492958069, Learning Rate: 3.125e-05
2022-06-12-02_35_59  Epoch: 51, Training Step: 300, Loss: 1.0373499393463135, Learning Rate: 3.125e-05
2022-06-12-02_36_26  Epoch: 51, Training Step: 400, Loss: 0.7692145109176636, Learning Rate: 3.125e-05
2022-06-12-02_36_53  Epoch: 51, Training Step: 500, Loss: 0.9481431841850281, Learning Rate: 3.125e-05
2022-06-12-02_37_20  Epoch: 51, Training Step: 600, Loss: 0.65605628490448, Learning Rate: 3.125e-05
2022-06-12-02_37_47  Epoch: 51, Training Step: 700, Loss: 0.8718332052230835, Learning Rate: 3.125e-05
2022-06-12-02_38_14  Epoch: 51, Training Step: 800, Loss: 0.8798304796218872, Learning Rate: 3.125e-05
2022-06-12-02_38_40  Epoch: 51, Training Step: 900, Loss: 0.8637810945510864, Learning Rate: 3.125e-05
2022-06-12-02_39_07  Epoch: 51, Training Step: 1000, Loss: 0.7350958585739136, Learning Rate: 3.125e-05
2022-06-12-02_39_36  Epoch: 51, Training Step: 1100, Loss: 0.7344156503677368, Learning Rate: 3.125e-05
2022-06-12-02_40_03  Epoch: 51, Training Step: 1200, Loss: 0.8830313682556152, Learning Rate: 3.125e-05
2022-06-12-02_40_30  Epoch: 51, Training Step: 1300, Loss: 0.7605577111244202, Learning Rate: 3.125e-05
2022-06-12-02_40_57  Epoch: 51, Training Step: 1400, Loss: 0.8113782405853271, Learning Rate: 3.125e-05
2022-06-12-02_41_24  Epoch: 51, Training Step: 1500, Loss: 0.8002309203147888, Learning Rate: 3.125e-05
2022-06-12-02_41_52  Epoch: 51, Training Step: 1600, Loss: 0.8841738700866699, Learning Rate: 3.125e-05
2022-06-12-02_42_18  Epoch: 51, Training Step: 1700, Loss: 0.8745527267456055, Learning Rate: 3.125e-05
2022-06-12-02_42_46  Epoch: 51, Training Step: 1800, Loss: 0.8311724066734314, Learning Rate: 3.125e-05
2022-06-12-02_43_13  Epoch: 51, Training Step: 1900, Loss: 0.8848451375961304, Learning Rate: 3.125e-05
2022-06-12-02_43_40  Epoch: 51, Training Step: 2000, Loss: 0.740615725517273, Learning Rate: 3.125e-05
2022-06-12-02_44_07  Epoch: 51, Training Step: 2100, Loss: 0.8596643209457397, Learning Rate: 3.125e-05
2022-06-12-02_44_35  Epoch: 51, Training Step: 2200, Loss: 0.9528359174728394, Learning Rate: 3.125e-05
2022-06-12-02_45_01  Epoch: 51, Training Step: 2300, Loss: 0.9504352807998657, Learning Rate: 3.125e-05
2022-06-12-02_45_28  Epoch: 51, Training Step: 2400, Loss: 0.7997568249702454, Learning Rate: 3.125e-05
2022-06-12-02_45_55  Epoch: 51, Training Step: 2500, Loss: 0.8651854991912842, Learning Rate: 3.125e-05
2022-06-12-02_46_22  Epoch: 51, Training Step: 2600, Loss: 0.8657313585281372, Learning Rate: 3.125e-05
2022-06-12-02_46_50  Epoch: 51, Training Step: 2700, Loss: 0.769006609916687, Learning Rate: 3.125e-05
2022-06-12-02_47_17  Epoch: 51, Training Step: 2800, Loss: 0.7097079753875732, Learning Rate: 3.125e-05
2022-06-12-02_47_44  Epoch: 51, Training Step: 2900, Loss: 0.8758884072303772, Learning Rate: 3.125e-05
2022-06-12-02_48_12  Epoch: 51, Training Step: 3000, Loss: 0.8597903251647949, Learning Rate: 3.125e-05
2022-06-12-02_48_39  Epoch: 51, Training Step: 3100, Loss: 0.8831528425216675, Learning Rate: 3.125e-05
2022-06-12-02_49_06  Epoch: 51, Training Step: 3200, Loss: 0.65350341796875, Learning Rate: 3.125e-05
2022-06-12-02_52_08  Epoch: 52, Training Step: 0, Loss: 0.7697130441665649, Learning Rate: 3.125e-05
2022-06-12-02_52_36  Epoch: 52, Training Step: 100, Loss: 0.8752033710479736, Learning Rate: 3.125e-05
2022-06-12-02_53_03  Epoch: 52, Training Step: 200, Loss: 0.911034345626831, Learning Rate: 3.125e-05
2022-06-12-02_53_30  Epoch: 52, Training Step: 300, Loss: 0.6866030693054199, Learning Rate: 3.125e-05
2022-06-12-02_53_58  Epoch: 52, Training Step: 400, Loss: 0.8944894671440125, Learning Rate: 3.125e-05
2022-06-12-02_54_25  Epoch: 52, Training Step: 500, Loss: 0.7983411550521851, Learning Rate: 3.125e-05
2022-06-12-02_54_52  Epoch: 52, Training Step: 600, Loss: 0.9753042459487915, Learning Rate: 3.125e-05
2022-06-12-02_55_19  Epoch: 52, Training Step: 700, Loss: 0.8875019550323486, Learning Rate: 3.125e-05
2022-06-12-02_55_46  Epoch: 52, Training Step: 800, Loss: 0.8598896265029907, Learning Rate: 3.125e-05
2022-06-12-02_56_13  Epoch: 52, Training Step: 900, Loss: 0.8985344767570496, Learning Rate: 3.125e-05
2022-06-12-02_56_40  Epoch: 52, Training Step: 1000, Loss: 0.8195194005966187, Learning Rate: 3.125e-05
2022-06-12-02_57_08  Epoch: 52, Training Step: 1100, Loss: 0.7910993695259094, Learning Rate: 3.125e-05
2022-06-12-02_57_35  Epoch: 52, Training Step: 1200, Loss: 0.7138088941574097, Learning Rate: 3.125e-05
2022-06-12-02_58_03  Epoch: 52, Training Step: 1300, Loss: 0.8317563533782959, Learning Rate: 3.125e-05
2022-06-12-02_58_30  Epoch: 52, Training Step: 1400, Loss: 0.9017891883850098, Learning Rate: 3.125e-05
2022-06-12-02_58_57  Epoch: 52, Training Step: 1500, Loss: 0.8116636872291565, Learning Rate: 3.125e-05
2022-06-12-02_59_24  Epoch: 52, Training Step: 1600, Loss: 0.7296410799026489, Learning Rate: 3.125e-05
2022-06-12-02_59_52  Epoch: 52, Training Step: 1700, Loss: 0.7337546348571777, Learning Rate: 3.125e-05
2022-06-12-03_00_19  Epoch: 52, Training Step: 1800, Loss: 0.8880199193954468, Learning Rate: 3.125e-05
2022-06-12-03_00_46  Epoch: 52, Training Step: 1900, Loss: 0.7786902189254761, Learning Rate: 3.125e-05
2022-06-12-03_01_13  Epoch: 52, Training Step: 2000, Loss: 0.9141768217086792, Learning Rate: 3.125e-05
2022-06-12-03_01_40  Epoch: 52, Training Step: 2100, Loss: 0.9093358516693115, Learning Rate: 3.125e-05
2022-06-12-03_02_07  Epoch: 52, Training Step: 2200, Loss: 0.8304712772369385, Learning Rate: 3.125e-05
2022-06-12-03_02_34  Epoch: 52, Training Step: 2300, Loss: 0.7609024047851562, Learning Rate: 3.125e-05
2022-06-12-03_03_02  Epoch: 52, Training Step: 2400, Loss: 0.8394744396209717, Learning Rate: 3.125e-05
2022-06-12-03_03_29  Epoch: 52, Training Step: 2500, Loss: 0.928152322769165, Learning Rate: 3.125e-05
2022-06-12-03_03_56  Epoch: 52, Training Step: 2600, Loss: 0.8519047498703003, Learning Rate: 3.125e-05
2022-06-12-03_04_23  Epoch: 52, Training Step: 2700, Loss: 0.9419159889221191, Learning Rate: 3.125e-05
2022-06-12-03_04_51  Epoch: 52, Training Step: 2800, Loss: 0.8640783429145813, Learning Rate: 3.125e-05
2022-06-12-03_05_18  Epoch: 52, Training Step: 2900, Loss: 0.7868790030479431, Learning Rate: 3.125e-05
2022-06-12-03_05_45  Epoch: 52, Training Step: 3000, Loss: 0.8963490724563599, Learning Rate: 3.125e-05
2022-06-12-03_06_12  Epoch: 52, Training Step: 3100, Loss: 1.2381378412246704, Learning Rate: 3.125e-05
2022-06-12-03_06_39  Epoch: 52, Training Step: 3200, Loss: 1.267693281173706, Learning Rate: 3.125e-05
2022-06-12-03_09_45  Epoch: 53, Training Step: 0, Loss: 0.9253920316696167, Learning Rate: 3.125e-05
2022-06-12-03_10_13  Epoch: 53, Training Step: 100, Loss: 0.6487966179847717, Learning Rate: 3.125e-05
2022-06-12-03_10_40  Epoch: 53, Training Step: 200, Loss: 0.7564984560012817, Learning Rate: 3.125e-05
2022-06-12-03_11_07  Epoch: 53, Training Step: 300, Loss: 0.7701423168182373, Learning Rate: 3.125e-05
2022-06-12-03_11_34  Epoch: 53, Training Step: 400, Loss: 0.8023847937583923, Learning Rate: 3.125e-05
2022-06-12-03_12_02  Epoch: 53, Training Step: 500, Loss: 0.9947489500045776, Learning Rate: 3.125e-05
2022-06-12-03_12_29  Epoch: 53, Training Step: 600, Loss: 0.7137875556945801, Learning Rate: 3.125e-05
2022-06-12-03_12_56  Epoch: 53, Training Step: 700, Loss: 0.7398415803909302, Learning Rate: 3.125e-05
2022-06-12-03_13_23  Epoch: 53, Training Step: 800, Loss: 0.8008722066879272, Learning Rate: 3.125e-05
2022-06-12-03_13_51  Epoch: 53, Training Step: 900, Loss: 0.8908768892288208, Learning Rate: 3.125e-05
2022-06-12-03_14_18  Epoch: 53, Training Step: 1000, Loss: 0.7949254512786865, Learning Rate: 3.125e-05
2022-06-12-03_14_46  Epoch: 53, Training Step: 1100, Loss: 0.8460192084312439, Learning Rate: 3.125e-05
2022-06-12-03_15_13  Epoch: 53, Training Step: 1200, Loss: 0.9004659056663513, Learning Rate: 3.125e-05
2022-06-12-03_15_40  Epoch: 53, Training Step: 1300, Loss: 0.820772647857666, Learning Rate: 3.125e-05
2022-06-12-03_16_07  Epoch: 53, Training Step: 1400, Loss: 0.9610921144485474, Learning Rate: 3.125e-05
2022-06-12-03_16_34  Epoch: 53, Training Step: 1500, Loss: 0.9154301881790161, Learning Rate: 3.125e-05
2022-06-12-03_17_01  Epoch: 53, Training Step: 1600, Loss: 0.8105512857437134, Learning Rate: 3.125e-05
2022-06-12-03_17_28  Epoch: 53, Training Step: 1700, Loss: 0.7833428382873535, Learning Rate: 3.125e-05
2022-06-12-03_17_56  Epoch: 53, Training Step: 1800, Loss: 0.8788543939590454, Learning Rate: 3.125e-05
2022-06-12-03_18_23  Epoch: 53, Training Step: 1900, Loss: 0.9663441777229309, Learning Rate: 3.125e-05
2022-06-12-03_18_50  Epoch: 53, Training Step: 2000, Loss: 0.794952392578125, Learning Rate: 3.125e-05
2022-06-12-03_19_17  Epoch: 53, Training Step: 2100, Loss: 0.7351171970367432, Learning Rate: 3.125e-05
2022-06-12-03_19_45  Epoch: 53, Training Step: 2200, Loss: 0.9045091271400452, Learning Rate: 3.125e-05
2022-06-12-03_20_12  Epoch: 53, Training Step: 2300, Loss: 0.9476151466369629, Learning Rate: 3.125e-05
2022-06-12-03_20_39  Epoch: 53, Training Step: 2400, Loss: 0.8596920967102051, Learning Rate: 3.125e-05
2022-06-12-03_21_06  Epoch: 53, Training Step: 2500, Loss: 0.8700562715530396, Learning Rate: 3.125e-05
2022-06-12-03_21_33  Epoch: 53, Training Step: 2600, Loss: 0.706065833568573, Learning Rate: 3.125e-05
2022-06-12-03_22_00  Epoch: 53, Training Step: 2700, Loss: 0.7755224108695984, Learning Rate: 3.125e-05
2022-06-12-03_22_26  Epoch: 53, Training Step: 2800, Loss: 0.9364246129989624, Learning Rate: 3.125e-05
2022-06-12-03_22_54  Epoch: 53, Training Step: 2900, Loss: 0.8734027743339539, Learning Rate: 3.125e-05
2022-06-12-03_23_22  Epoch: 53, Training Step: 3000, Loss: 0.8180973529815674, Learning Rate: 3.125e-05
2022-06-12-03_23_49  Epoch: 53, Training Step: 3100, Loss: 0.7479488253593445, Learning Rate: 3.125e-05
2022-06-12-03_24_16  Epoch: 53, Training Step: 3200, Loss: 1.12680983543396, Learning Rate: 3.125e-05
2022-06-12-03_27_17  Epoch: 54, Training Step: 0, Loss: 1.1229099035263062, Learning Rate: 3.125e-05
2022-06-12-03_27_44  Epoch: 54, Training Step: 100, Loss: 0.8644013404846191, Learning Rate: 3.125e-05
2022-06-12-03_28_11  Epoch: 54, Training Step: 200, Loss: 0.8328933715820312, Learning Rate: 3.125e-05
2022-06-12-03_28_37  Epoch: 54, Training Step: 300, Loss: 0.7822129726409912, Learning Rate: 3.125e-05
2022-06-12-03_29_04  Epoch: 54, Training Step: 400, Loss: 0.8756536245346069, Learning Rate: 3.125e-05
2022-06-12-03_29_32  Epoch: 54, Training Step: 500, Loss: 0.8383933305740356, Learning Rate: 3.125e-05
2022-06-12-03_29_59  Epoch: 54, Training Step: 600, Loss: 0.7288156151771545, Learning Rate: 3.125e-05
2022-06-12-03_30_26  Epoch: 54, Training Step: 700, Loss: 0.918182373046875, Learning Rate: 3.125e-05
2022-06-12-03_30_53  Epoch: 54, Training Step: 800, Loss: 0.8835113048553467, Learning Rate: 3.125e-05
2022-06-12-03_31_21  Epoch: 54, Training Step: 900, Loss: 0.8101320266723633, Learning Rate: 3.125e-05
2022-06-12-03_31_47  Epoch: 54, Training Step: 1000, Loss: 0.9344344139099121, Learning Rate: 3.125e-05
2022-06-12-03_32_15  Epoch: 54, Training Step: 1100, Loss: 0.7445141077041626, Learning Rate: 3.125e-05
2022-06-12-03_32_43  Epoch: 54, Training Step: 1200, Loss: 0.8590660691261292, Learning Rate: 3.125e-05
2022-06-12-03_33_09  Epoch: 54, Training Step: 1300, Loss: 0.8122129440307617, Learning Rate: 3.125e-05
2022-06-12-03_33_36  Epoch: 54, Training Step: 1400, Loss: 1.2239125967025757, Learning Rate: 3.125e-05
2022-06-12-03_34_03  Epoch: 54, Training Step: 1500, Loss: 0.9752950668334961, Learning Rate: 3.125e-05
2022-06-12-03_34_30  Epoch: 54, Training Step: 1600, Loss: 0.74564129114151, Learning Rate: 3.125e-05
2022-06-12-03_34_57  Epoch: 54, Training Step: 1700, Loss: 0.7551059126853943, Learning Rate: 3.125e-05
2022-06-12-03_35_24  Epoch: 54, Training Step: 1800, Loss: 0.6998769640922546, Learning Rate: 3.125e-05
2022-06-12-03_35_51  Epoch: 54, Training Step: 1900, Loss: 0.8150448799133301, Learning Rate: 3.125e-05
2022-06-12-03_36_18  Epoch: 54, Training Step: 2000, Loss: 0.7590517997741699, Learning Rate: 3.125e-05
2022-06-12-03_36_45  Epoch: 54, Training Step: 2100, Loss: 0.892455518245697, Learning Rate: 3.125e-05
2022-06-12-03_37_12  Epoch: 54, Training Step: 2200, Loss: 0.798254132270813, Learning Rate: 3.125e-05
2022-06-12-03_37_39  Epoch: 54, Training Step: 2300, Loss: 0.6179952621459961, Learning Rate: 3.125e-05
2022-06-12-03_38_06  Epoch: 54, Training Step: 2400, Loss: 0.9369913935661316, Learning Rate: 3.125e-05
2022-06-12-03_38_34  Epoch: 54, Training Step: 2500, Loss: 1.1054719686508179, Learning Rate: 3.125e-05
2022-06-12-03_39_01  Epoch: 54, Training Step: 2600, Loss: 0.8081456422805786, Learning Rate: 3.125e-05
2022-06-12-03_39_29  Epoch: 54, Training Step: 2700, Loss: 0.9591298699378967, Learning Rate: 3.125e-05
2022-06-12-03_39_56  Epoch: 54, Training Step: 2800, Loss: 0.7899026870727539, Learning Rate: 3.125e-05
2022-06-12-03_40_23  Epoch: 54, Training Step: 2900, Loss: 0.6969180107116699, Learning Rate: 3.125e-05
2022-06-12-03_40_50  Epoch: 54, Training Step: 3000, Loss: 1.163254976272583, Learning Rate: 3.125e-05
2022-06-12-03_41_17  Epoch: 54, Training Step: 3100, Loss: 0.7409217357635498, Learning Rate: 3.125e-05
2022-06-12-03_41_44  Epoch: 54, Training Step: 3200, Loss: 0.9334665536880493, Learning Rate: 3.125e-05
2022-06-12-03_44_44  Epoch: 55, Training Step: 0, Loss: 0.9108354449272156, Learning Rate: 3.125e-05
2022-06-12-03_45_11  Epoch: 55, Training Step: 100, Loss: 0.7771881818771362, Learning Rate: 3.125e-05
2022-06-12-03_45_38  Epoch: 55, Training Step: 200, Loss: 0.9816198348999023, Learning Rate: 3.125e-05
2022-06-12-03_46_05  Epoch: 55, Training Step: 300, Loss: 0.8455504179000854, Learning Rate: 3.125e-05
2022-06-12-03_46_32  Epoch: 55, Training Step: 400, Loss: 0.8280744552612305, Learning Rate: 3.125e-05
2022-06-12-03_46_59  Epoch: 55, Training Step: 500, Loss: 1.0096118450164795, Learning Rate: 3.125e-05
2022-06-12-03_47_26  Epoch: 55, Training Step: 600, Loss: 0.8363953828811646, Learning Rate: 3.125e-05
2022-06-12-03_47_53  Epoch: 55, Training Step: 700, Loss: 0.7405948638916016, Learning Rate: 3.125e-05
2022-06-12-03_48_20  Epoch: 55, Training Step: 800, Loss: 0.9043482542037964, Learning Rate: 3.125e-05
2022-06-12-03_48_47  Epoch: 55, Training Step: 900, Loss: 0.7533754110336304, Learning Rate: 3.125e-05
2022-06-12-03_49_15  Epoch: 55, Training Step: 1000, Loss: 0.9117702841758728, Learning Rate: 3.125e-05
2022-06-12-03_49_42  Epoch: 55, Training Step: 1100, Loss: 0.9119434356689453, Learning Rate: 3.125e-05
2022-06-12-03_50_09  Epoch: 55, Training Step: 1200, Loss: 0.897792398929596, Learning Rate: 3.125e-05
2022-06-12-03_50_36  Epoch: 55, Training Step: 1300, Loss: 0.948077917098999, Learning Rate: 3.125e-05
2022-06-12-03_51_02  Epoch: 55, Training Step: 1400, Loss: 0.7219387888908386, Learning Rate: 3.125e-05
2022-06-12-03_51_29  Epoch: 55, Training Step: 1500, Loss: 0.9060912132263184, Learning Rate: 3.125e-05
2022-06-12-03_51_56  Epoch: 55, Training Step: 1600, Loss: 0.8585762977600098, Learning Rate: 3.125e-05
2022-06-12-03_52_23  Epoch: 55, Training Step: 1700, Loss: 0.7907241582870483, Learning Rate: 3.125e-05
2022-06-12-03_52_50  Epoch: 55, Training Step: 1800, Loss: 0.8571016788482666, Learning Rate: 3.125e-05
2022-06-12-03_53_16  Epoch: 55, Training Step: 1900, Loss: 0.6950381994247437, Learning Rate: 3.125e-05
2022-06-12-03_53_43  Epoch: 55, Training Step: 2000, Loss: 1.0073633193969727, Learning Rate: 3.125e-05
2022-06-12-03_54_10  Epoch: 55, Training Step: 2100, Loss: 0.8789310455322266, Learning Rate: 3.125e-05
2022-06-12-03_54_37  Epoch: 55, Training Step: 2200, Loss: 0.8360062837600708, Learning Rate: 3.125e-05
2022-06-12-03_55_04  Epoch: 55, Training Step: 2300, Loss: 0.8150338530540466, Learning Rate: 3.125e-05
2022-06-12-03_55_31  Epoch: 55, Training Step: 2400, Loss: 0.7047686576843262, Learning Rate: 3.125e-05
2022-06-12-03_55_58  Epoch: 55, Training Step: 2500, Loss: 1.0976862907409668, Learning Rate: 3.125e-05
2022-06-12-03_56_25  Epoch: 55, Training Step: 2600, Loss: 0.9380730986595154, Learning Rate: 3.125e-05
2022-06-12-03_56_52  Epoch: 55, Training Step: 2700, Loss: 0.7857598066329956, Learning Rate: 3.125e-05
2022-06-12-03_57_20  Epoch: 55, Training Step: 2800, Loss: 0.8927379846572876, Learning Rate: 3.125e-05
2022-06-12-03_57_46  Epoch: 55, Training Step: 2900, Loss: 0.7615393400192261, Learning Rate: 3.125e-05
2022-06-12-03_58_13  Epoch: 55, Training Step: 3000, Loss: 1.0753802061080933, Learning Rate: 3.125e-05
2022-06-12-03_58_40  Epoch: 55, Training Step: 3100, Loss: 0.7819347977638245, Learning Rate: 3.125e-05
2022-06-12-03_59_07  Epoch: 55, Training Step: 3200, Loss: 0.6931024789810181, Learning Rate: 3.125e-05
2022-06-12-04_02_09  Epoch: 56, Training Step: 0, Loss: 0.7569016218185425, Learning Rate: 3.125e-05
2022-06-12-04_02_36  Epoch: 56, Training Step: 100, Loss: 0.8440420627593994, Learning Rate: 3.125e-05
2022-06-12-04_03_03  Epoch: 56, Training Step: 200, Loss: 0.7049352526664734, Learning Rate: 3.125e-05
2022-06-12-04_03_30  Epoch: 56, Training Step: 300, Loss: 0.916131317615509, Learning Rate: 3.125e-05
2022-06-12-04_03_57  Epoch: 56, Training Step: 400, Loss: 0.7511582374572754, Learning Rate: 3.125e-05
2022-06-12-04_04_25  Epoch: 56, Training Step: 500, Loss: 0.9132840633392334, Learning Rate: 3.125e-05
2022-06-12-04_04_53  Epoch: 56, Training Step: 600, Loss: 0.848202109336853, Learning Rate: 3.125e-05
2022-06-12-04_05_20  Epoch: 56, Training Step: 700, Loss: 0.7663434147834778, Learning Rate: 3.125e-05
2022-06-12-04_05_47  Epoch: 56, Training Step: 800, Loss: 0.9263197183609009, Learning Rate: 3.125e-05
2022-06-12-04_06_14  Epoch: 56, Training Step: 900, Loss: 0.8013623356819153, Learning Rate: 3.125e-05
2022-06-12-04_06_41  Epoch: 56, Training Step: 1000, Loss: 1.0559964179992676, Learning Rate: 3.125e-05
2022-06-12-04_07_08  Epoch: 56, Training Step: 1100, Loss: 0.6469507813453674, Learning Rate: 3.125e-05
2022-06-12-04_07_35  Epoch: 56, Training Step: 1200, Loss: 1.00612473487854, Learning Rate: 3.125e-05
2022-06-12-04_08_02  Epoch: 56, Training Step: 1300, Loss: 0.8307136297225952, Learning Rate: 3.125e-05
2022-06-12-04_08_29  Epoch: 56, Training Step: 1400, Loss: 0.8054862022399902, Learning Rate: 3.125e-05
2022-06-12-04_08_56  Epoch: 56, Training Step: 1500, Loss: 0.7615671157836914, Learning Rate: 3.125e-05
2022-06-12-04_09_23  Epoch: 56, Training Step: 1600, Loss: 0.774592399597168, Learning Rate: 3.125e-05
2022-06-12-04_09_50  Epoch: 56, Training Step: 1700, Loss: 0.800966739654541, Learning Rate: 3.125e-05
2022-06-12-04_10_17  Epoch: 56, Training Step: 1800, Loss: 0.8962557315826416, Learning Rate: 3.125e-05
2022-06-12-04_10_44  Epoch: 56, Training Step: 1900, Loss: 0.7893810272216797, Learning Rate: 3.125e-05
2022-06-12-04_11_11  Epoch: 56, Training Step: 2000, Loss: 0.8294878005981445, Learning Rate: 3.125e-05
2022-06-12-04_11_37  Epoch: 56, Training Step: 2100, Loss: 0.7999135255813599, Learning Rate: 3.125e-05
2022-06-12-04_12_05  Epoch: 56, Training Step: 2200, Loss: 0.8504588603973389, Learning Rate: 3.125e-05
2022-06-12-04_12_32  Epoch: 56, Training Step: 2300, Loss: 0.9026090502738953, Learning Rate: 3.125e-05
2022-06-12-04_13_00  Epoch: 56, Training Step: 2400, Loss: 0.8111852407455444, Learning Rate: 3.125e-05
2022-06-12-04_13_27  Epoch: 56, Training Step: 2500, Loss: 1.0205509662628174, Learning Rate: 3.125e-05
2022-06-12-04_13_54  Epoch: 56, Training Step: 2600, Loss: 1.1797525882720947, Learning Rate: 3.125e-05
2022-06-12-04_14_21  Epoch: 56, Training Step: 2700, Loss: 0.8498134613037109, Learning Rate: 3.125e-05
2022-06-12-04_14_48  Epoch: 56, Training Step: 2800, Loss: 0.7823572158813477, Learning Rate: 3.125e-05
2022-06-12-04_15_15  Epoch: 56, Training Step: 2900, Loss: 0.756202220916748, Learning Rate: 3.125e-05
2022-06-12-04_15_41  Epoch: 56, Training Step: 3000, Loss: 0.8155447244644165, Learning Rate: 3.125e-05
2022-06-12-04_16_09  Epoch: 56, Training Step: 3100, Loss: 1.0446009635925293, Learning Rate: 3.125e-05
2022-06-12-04_16_36  Epoch: 56, Training Step: 3200, Loss: 0.7752591371536255, Learning Rate: 3.125e-05
2022-06-12-04_19_38  Epoch: 57, Training Step: 0, Loss: 0.8063778877258301, Learning Rate: 3.125e-05
2022-06-12-04_20_05  Epoch: 57, Training Step: 100, Loss: 0.9767208099365234, Learning Rate: 3.125e-05
2022-06-12-04_20_33  Epoch: 57, Training Step: 200, Loss: 0.8167113065719604, Learning Rate: 3.125e-05
2022-06-12-04_21_00  Epoch: 57, Training Step: 300, Loss: 0.7413280606269836, Learning Rate: 3.125e-05
2022-06-12-04_21_26  Epoch: 57, Training Step: 400, Loss: 0.8181840777397156, Learning Rate: 3.125e-05
2022-06-12-04_21_53  Epoch: 57, Training Step: 500, Loss: 0.8881067037582397, Learning Rate: 3.125e-05
2022-06-12-04_22_20  Epoch: 57, Training Step: 600, Loss: 0.8565452098846436, Learning Rate: 3.125e-05
2022-06-12-04_22_47  Epoch: 57, Training Step: 700, Loss: 0.7854323387145996, Learning Rate: 3.125e-05
2022-06-12-04_23_15  Epoch: 57, Training Step: 800, Loss: 0.7183805704116821, Learning Rate: 3.125e-05
2022-06-12-04_23_42  Epoch: 57, Training Step: 900, Loss: 0.7812486290931702, Learning Rate: 3.125e-05
2022-06-12-04_24_10  Epoch: 57, Training Step: 1000, Loss: 0.8182753920555115, Learning Rate: 3.125e-05
2022-06-12-04_24_37  Epoch: 57, Training Step: 1100, Loss: 0.8460795879364014, Learning Rate: 3.125e-05
2022-06-12-04_25_04  Epoch: 57, Training Step: 1200, Loss: 0.882033109664917, Learning Rate: 3.125e-05
2022-06-12-04_25_31  Epoch: 57, Training Step: 1300, Loss: 0.8379760384559631, Learning Rate: 3.125e-05
2022-06-12-04_25_58  Epoch: 57, Training Step: 1400, Loss: 0.8680427670478821, Learning Rate: 3.125e-05
2022-06-12-04_26_24  Epoch: 57, Training Step: 1500, Loss: 0.8087767958641052, Learning Rate: 3.125e-05
2022-06-12-04_26_51  Epoch: 57, Training Step: 1600, Loss: 0.8957027196884155, Learning Rate: 3.125e-05
2022-06-12-04_27_18  Epoch: 57, Training Step: 1700, Loss: 0.7999799251556396, Learning Rate: 3.125e-05
2022-06-12-04_27_44  Epoch: 57, Training Step: 1800, Loss: 0.8716565370559692, Learning Rate: 3.125e-05
2022-06-12-04_28_11  Epoch: 57, Training Step: 1900, Loss: 0.8726087808609009, Learning Rate: 3.125e-05
2022-06-12-04_28_38  Epoch: 57, Training Step: 2000, Loss: 1.043175458908081, Learning Rate: 3.125e-05
2022-06-12-04_29_05  Epoch: 57, Training Step: 2100, Loss: 0.884932816028595, Learning Rate: 3.125e-05
2022-06-12-04_29_32  Epoch: 57, Training Step: 2200, Loss: 0.7550771236419678, Learning Rate: 3.125e-05
2022-06-12-04_29_59  Epoch: 57, Training Step: 2300, Loss: 0.8886849880218506, Learning Rate: 3.125e-05
2022-06-12-04_30_27  Epoch: 57, Training Step: 2400, Loss: 0.9711747765541077, Learning Rate: 3.125e-05
2022-06-12-04_30_54  Epoch: 57, Training Step: 2500, Loss: 0.7528075575828552, Learning Rate: 3.125e-05
2022-06-12-04_31_22  Epoch: 57, Training Step: 2600, Loss: 0.8061645030975342, Learning Rate: 3.125e-05
2022-06-12-04_31_50  Epoch: 57, Training Step: 2700, Loss: 1.0701543092727661, Learning Rate: 3.125e-05
2022-06-12-04_32_17  Epoch: 57, Training Step: 2800, Loss: 0.9130004644393921, Learning Rate: 3.125e-05
2022-06-12-04_32_44  Epoch: 57, Training Step: 2900, Loss: 1.0894643068313599, Learning Rate: 3.125e-05
2022-06-12-04_33_11  Epoch: 57, Training Step: 3000, Loss: 0.9462981224060059, Learning Rate: 3.125e-05
2022-06-12-04_33_39  Epoch: 57, Training Step: 3100, Loss: 0.8624568581581116, Learning Rate: 3.125e-05
2022-06-12-04_34_06  Epoch: 57, Training Step: 3200, Loss: 0.7376609444618225, Learning Rate: 3.125e-05
2022-06-12-04_37_08  Epoch: 58, Training Step: 0, Loss: 0.7697113752365112, Learning Rate: 3.125e-05
2022-06-12-04_37_35  Epoch: 58, Training Step: 100, Loss: 0.8175856471061707, Learning Rate: 3.125e-05
2022-06-12-04_38_02  Epoch: 58, Training Step: 200, Loss: 1.0504250526428223, Learning Rate: 3.125e-05
2022-06-12-04_38_29  Epoch: 58, Training Step: 300, Loss: 0.9673678874969482, Learning Rate: 3.125e-05
2022-06-12-04_38_57  Epoch: 58, Training Step: 400, Loss: 0.7193611264228821, Learning Rate: 3.125e-05
2022-06-12-04_39_25  Epoch: 58, Training Step: 500, Loss: 1.0181236267089844, Learning Rate: 3.125e-05
2022-06-12-04_39_52  Epoch: 58, Training Step: 600, Loss: 0.8591852188110352, Learning Rate: 3.125e-05
2022-06-12-04_40_19  Epoch: 58, Training Step: 700, Loss: 0.6494854688644409, Learning Rate: 3.125e-05
2022-06-12-04_40_47  Epoch: 58, Training Step: 800, Loss: 0.8477765917778015, Learning Rate: 3.125e-05
2022-06-12-04_41_14  Epoch: 58, Training Step: 900, Loss: 0.998166024684906, Learning Rate: 3.125e-05
2022-06-12-04_41_41  Epoch: 58, Training Step: 1000, Loss: 1.0815833806991577, Learning Rate: 3.125e-05
2022-06-12-04_42_08  Epoch: 58, Training Step: 1100, Loss: 0.99455726146698, Learning Rate: 3.125e-05
2022-06-12-04_42_35  Epoch: 58, Training Step: 1200, Loss: 0.8629683256149292, Learning Rate: 3.125e-05
2022-06-12-04_43_02  Epoch: 58, Training Step: 1300, Loss: 0.8005950450897217, Learning Rate: 3.125e-05
2022-06-12-04_43_29  Epoch: 58, Training Step: 1400, Loss: 0.8868064880371094, Learning Rate: 3.125e-05
2022-06-12-04_43_56  Epoch: 58, Training Step: 1500, Loss: 0.9096498489379883, Learning Rate: 3.125e-05
2022-06-12-04_44_23  Epoch: 58, Training Step: 1600, Loss: 0.8013378977775574, Learning Rate: 3.125e-05
2022-06-12-04_44_51  Epoch: 58, Training Step: 1700, Loss: 0.7748461961746216, Learning Rate: 3.125e-05
2022-06-12-04_45_18  Epoch: 58, Training Step: 1800, Loss: 0.7558482885360718, Learning Rate: 3.125e-05
2022-06-12-04_45_45  Epoch: 58, Training Step: 1900, Loss: 0.9542794227600098, Learning Rate: 3.125e-05
2022-06-12-04_46_12  Epoch: 58, Training Step: 2000, Loss: 0.8398993015289307, Learning Rate: 3.125e-05
2022-06-12-04_46_39  Epoch: 58, Training Step: 2100, Loss: 0.8938883543014526, Learning Rate: 3.125e-05
2022-06-12-04_47_07  Epoch: 58, Training Step: 2200, Loss: 0.8762141466140747, Learning Rate: 3.125e-05
2022-06-12-04_47_33  Epoch: 58, Training Step: 2300, Loss: 0.8514907360076904, Learning Rate: 3.125e-05
2022-06-12-04_48_00  Epoch: 58, Training Step: 2400, Loss: 0.9822299480438232, Learning Rate: 3.125e-05
2022-06-12-04_48_28  Epoch: 58, Training Step: 2500, Loss: 0.8061398267745972, Learning Rate: 3.125e-05
2022-06-12-04_48_55  Epoch: 58, Training Step: 2600, Loss: 0.731873095035553, Learning Rate: 3.125e-05
2022-06-12-04_49_22  Epoch: 58, Training Step: 2700, Loss: 1.0087348222732544, Learning Rate: 3.125e-05
2022-06-12-04_49_49  Epoch: 58, Training Step: 2800, Loss: 0.7543122172355652, Learning Rate: 3.125e-05
2022-06-12-04_50_16  Epoch: 58, Training Step: 2900, Loss: 0.8223227262496948, Learning Rate: 3.125e-05
2022-06-12-04_50_44  Epoch: 58, Training Step: 3000, Loss: 0.8306690454483032, Learning Rate: 3.125e-05
2022-06-12-04_51_10  Epoch: 58, Training Step: 3100, Loss: 0.6868180632591248, Learning Rate: 3.125e-05
2022-06-12-04_51_37  Epoch: 58, Training Step: 3200, Loss: 0.7560591101646423, Learning Rate: 3.125e-05
2022-06-12-04_54_36  Epoch: 59, Training Step: 0, Loss: 0.8873250484466553, Learning Rate: 3.125e-05
2022-06-12-04_55_03  Epoch: 59, Training Step: 100, Loss: 0.8768872022628784, Learning Rate: 3.125e-05
2022-06-12-04_55_30  Epoch: 59, Training Step: 200, Loss: 0.8762089014053345, Learning Rate: 3.125e-05
2022-06-12-04_55_58  Epoch: 59, Training Step: 300, Loss: 1.063049077987671, Learning Rate: 3.125e-05
2022-06-12-04_56_26  Epoch: 59, Training Step: 400, Loss: 0.8975608348846436, Learning Rate: 3.125e-05
2022-06-12-04_56_53  Epoch: 59, Training Step: 500, Loss: 0.8878695964813232, Learning Rate: 3.125e-05
2022-06-12-04_57_20  Epoch: 59, Training Step: 600, Loss: 0.8767393827438354, Learning Rate: 3.125e-05
2022-06-12-04_57_47  Epoch: 59, Training Step: 700, Loss: 0.8639944791793823, Learning Rate: 3.125e-05
2022-06-12-04_58_14  Epoch: 59, Training Step: 800, Loss: 0.786797285079956, Learning Rate: 3.125e-05
2022-06-12-04_58_41  Epoch: 59, Training Step: 900, Loss: 0.7690532207489014, Learning Rate: 3.125e-05
2022-06-12-04_59_08  Epoch: 59, Training Step: 1000, Loss: 0.8518949747085571, Learning Rate: 3.125e-05
2022-06-12-04_59_36  Epoch: 59, Training Step: 1100, Loss: 0.8624351024627686, Learning Rate: 3.125e-05
2022-06-12-05_00_03  Epoch: 59, Training Step: 1200, Loss: 0.8519009351730347, Learning Rate: 3.125e-05
2022-06-12-05_00_29  Epoch: 59, Training Step: 1300, Loss: 0.8179346919059753, Learning Rate: 3.125e-05
2022-06-12-05_00_56  Epoch: 59, Training Step: 1400, Loss: 0.7936036586761475, Learning Rate: 3.125e-05
2022-06-12-05_01_24  Epoch: 59, Training Step: 1500, Loss: 0.6025384664535522, Learning Rate: 3.125e-05
2022-06-12-05_01_51  Epoch: 59, Training Step: 1600, Loss: 1.0634804964065552, Learning Rate: 3.125e-05
2022-06-12-05_02_18  Epoch: 59, Training Step: 1700, Loss: 0.8604882955551147, Learning Rate: 3.125e-05
2022-06-12-05_02_46  Epoch: 59, Training Step: 1800, Loss: 0.8967689871788025, Learning Rate: 3.125e-05
2022-06-12-05_03_13  Epoch: 59, Training Step: 1900, Loss: 0.781653881072998, Learning Rate: 3.125e-05
2022-06-12-05_03_41  Epoch: 59, Training Step: 2000, Loss: 0.7174362540245056, Learning Rate: 3.125e-05
2022-06-12-05_04_08  Epoch: 59, Training Step: 2100, Loss: 0.8723393678665161, Learning Rate: 3.125e-05
2022-06-12-05_04_36  Epoch: 59, Training Step: 2200, Loss: 0.8318443298339844, Learning Rate: 3.125e-05
2022-06-12-05_05_03  Epoch: 59, Training Step: 2300, Loss: 0.9204177856445312, Learning Rate: 3.125e-05
2022-06-12-05_05_29  Epoch: 59, Training Step: 2400, Loss: 0.8402780294418335, Learning Rate: 3.125e-05
2022-06-12-05_05_56  Epoch: 59, Training Step: 2500, Loss: 1.0945534706115723, Learning Rate: 3.125e-05
2022-06-12-05_06_23  Epoch: 59, Training Step: 2600, Loss: 0.8079790472984314, Learning Rate: 3.125e-05
2022-06-12-05_06_50  Epoch: 59, Training Step: 2700, Loss: 0.7573431730270386, Learning Rate: 3.125e-05
2022-06-12-05_07_17  Epoch: 59, Training Step: 2800, Loss: 0.8896142244338989, Learning Rate: 3.125e-05
2022-06-12-05_07_44  Epoch: 59, Training Step: 2900, Loss: 1.0903955698013306, Learning Rate: 3.125e-05
2022-06-12-05_08_12  Epoch: 59, Training Step: 3000, Loss: 0.7120950818061829, Learning Rate: 3.125e-05
2022-06-12-05_08_39  Epoch: 59, Training Step: 3100, Loss: 0.7441190481185913, Learning Rate: 3.125e-05
2022-06-12-05_09_06  Epoch: 59, Training Step: 3200, Loss: 0.8822687864303589, Learning Rate: 3.125e-05
